<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://nasirlukman.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nasirlukman.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-29T16:01:18+00:00</updated><id>https://nasirlukman.github.io/feed.xml</id><title type="html">Earth.etc</title><subtitle></subtitle><entry><title type="html">Revisiting NDFI: A Flexible Index for Forest Monitoring and Beyond</title><link href="https://nasirlukman.github.io/blog/2025/ndfi/" rel="alternate" type="text/html" title="Revisiting NDFI: A Flexible Index for Forest Monitoring and Beyond"/><published>2025-06-28T23:36:10+00:00</published><updated>2025-06-28T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/ndfi</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/ndfi/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>The <a href="https://registry.verra.org/app/projectDetail/VCS/5085">Tond Tenga Project</a> in Burkina Faso was the <a href="https://esgnews.com/verra-registers-first-carbon-project-under-icvcm-approved-methodology/">first</a> Verified Carbon Standard (VCS) project. As part of their biomass stocking index methodology, they use the Normalized Difference Fraction Index (NDFI), calculated from Landsat 8 and 9 Operational Land Imager (OLI) scenes. This catch my interest and motivated me to revisit the method. In this blog, I’ll write down my notes and key takeaways, both for my own reference and for others who want to understand the core ideas behind the NDFI.</p> <p>At first glance, the name sounds similar to other well-known remote sensing indices like NDVI or NDWI. But unlike those indices, NDFI isn’t a simple equation applied to standard satellite bands. In fact, I think NDFI adaptation in remote sensing should be seen more as a general concept or approach in feature engineering, rather than a fixed index. Let’s unpack that in more detail.</p> <h1 id="a-quick-look-at-spectral-mixture-analysis-sma">A Quick Look at Spectral Mixture Analysis (SMA)</h1> <p>NDFI was originally developed to map forest canopy damage caused by selective logging and fires in the Amazon, introduced by <a href="https://www.sciencedirect.com/science/article/abs/pii/S0034425705002385">Souza et al. (2005)</a>. It’s based on a method called spectral mixture analysis (SMA), or spectral unmixing. It is something I’ve write multiple time in this blog before. But for completeness, let’s go over a quick refresher.</p> <p>SMA starts from a classic remote sensing problem: a single pixel often contains multiple objects. For example, take the pixel shown in the image below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_12_mixture_example-480.webp 480w,/assets/img/post_12_mixture_example-800.webp 800w,/assets/img/post_12_mixture_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_12_mixture_example.png" class="img-fluid rounded" width="100%" height="auto" alt="Ilustration of how inside one pixel can consist of multiple different object of interest. And how the light reflection signal taht is captured by the satellite sensor is a mixed of each individual object reflectance." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Ilustration of how one pixel can consist of multiple object of interest and what the satelite captured is actually a mixed reflectance signal of each individual object. </div> <p>Within that one 10 x 10 m pixel, we have two tree crowns, some grassy ground, and part of a dirt road. In SMA, these individual components are called endmembers. From spectroscopy, we know that different materials reflect and absorb light in different ways, this behavior across wavelengths is what we call a spectral signature.</p> <p>Trees, grass, and soil each have their own characteristic spectral signatures. In multispectral or hyperspectral images, these differences let us distinguish one material from another. But when several materials are mixed within a single pixel, the resulting spectral signal is a blend, and that makes it harder to classify the pixel using a simple “match-the-spectrum” approach.</p> <p>SMA becomes useful for two main reasons. First, because a mixed pixel hides the original spectral signature of each object, it becomes hard to classify each pixel directly using traditional approaches. SMA helps us make sense of that mix. Second, sometimes we want to get more detailed information than what the resolution of the image allows. For example, we might want to estimate the tree canopy cover inside a single pixel, even if that pixel covers 10 or 30 meters on the ground. SMA lets us break down that pixel and estimate the proportion of each material inside it.</p> <p>SMA typically assumes a linear mixing model, where each endmember’s spectral signature is multiplied by its area fraction, and then summed. In matrix notation we can write it as:</p> \[\mathbf{y} = \mathbf{E} \mathbf{a}\] <p>Where \(\mathbf{y}\) is the mixed spectra that the sensor capture, \(\mathbf{E}\) is the endmember spectra matrix where each vertical component represent a single endmemebr spectra, and \(\mathbf{a}\) is the area fraction vector which is summed to one.</p> <p>In most SMA workflows, we assume that the endmembers spectra \(\mathbf{E}\) is known. We won’t go into how to extract the endmembers here, but common approaches include using spectral libraries, manually selecting the purest pixels, or applying automated methods like NFINDR, which I’ve explained in more detail <a href="https://nasirlukman.github.io/blog/2024/nfindr/">here</a>.</p> <p>The main goal is to solve for the vector \(\mathbf{a}\), which gives us the area fraction of each material inside the pixel. This is usually done by solving a constrained optimization problem (non-negative, sum-to-one constraints). You can refer to the equation I used in my earlier post <a href="https://nasirlukman.github.io/blog/2024/distance/">here</a>.</p> <p>Now, is the linear mixing assumption reasonable? This assumption holds true if we assume a completely flat and smooth surface as ilustrated in the image below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_12_simple_mixture-480.webp 480w,/assets/img/post_12_simple_mixture-800.webp 800w,/assets/img/post_12_simple_mixture-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_12_simple_mixture.png" class="img-fluid rounded" width="100%" height="auto" alt="Ilustration of the surface assumption where linear mixing model is true. In a completely flat and smooth surface, each light rays will only hit each object exactly once before it reflected and captured by the sensor. hence what the sensor capture is simply a linear combination of each object spectral signatured weighted by its area proportion." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Illustration of flat and smooth surface conditions where linear mixing holds true. </div> <p>In this scenario, each light ray from the sun (\(\mathbf{R}_0\)) interacts with only one object before reflecting into the sensor. In this case both \(\mathbf{R}_1\) and \(\mathbf{R}_2\) are pure reflectance (endmember’s spectral signature) of object 1 and object 2, respectively. What the sensor receives is simply a linear combination of these reflectances weighted by their respective area fractions.</p> <p>However, real-world surfaces are obviously more complex. For example, consider the next image, which better reflects a realistic, vegetated surface:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_12_complex_mixture-480.webp 480w,/assets/img/post_12_complex_mixture-800.webp 800w,/assets/img/post_12_complex_mixture-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_12_complex_mixture.png" class="img-fluid rounded" width="100%" height="auto" alt="More realistic surface condition of vegetated earth surface. In this case each light ray hit multiple object before reflected out to the sensor. This complex interaction between light and multiple object casuing the mixture to be defiated from the linear model." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. A more realistic illustration of a vegetated earth surface </div> <p>Due to the complex condition of the real surface, light doesn’t just bounce off one object. It often reflects multiple times between different objects before reaching the sensor. For instance, in the image above, \(\mathbf{R}_1\) is the normal reflectance from the ground, this will be equal to the ground spectral signature. Then we have \(\mathbf{R}_2\), which is the reflectance from the tree trunk. But here, the light hitting the trunk isn’t direct sunlight anymore, it is already been reflected off the ground. So if we have a reference endmember spectrum for tree bark, it will not be equal to \(\mathbf{R}_2\), because endmember spectrum was measured assuming direct sunlight as the source. Finally, \(\mathbf{R}_3\) becomes even more complex, as it involves multiple reflections of already light that already reflected multiple times. These multi-bounce interactions are why the signal the sensor receives doesn’t follow a simple linear mixture of the endmember spectra. The assumption breaks down when multiple scattering effects become significant.</p> <p>I bring this up because I think it is important to be aware of the limitation of this approach and to acknowledge that there are methods that try to model this more realistically. For example, <a href="https://link.springer.com/chapter/10.1007/978-3-319-04126-1_19">bilinear mixing models</a> have been shown to perform better in vegetated areas. I also discussed a more physics-based nonlinear model in my earlier research on <a href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/">mineral mixtures</a>.</p> <p>That said, modeling the precise interaction of light and matter on Earth’s surface is, for most practical purposes, nearly impossible. And once you go down that path, it’s easy to over-engineer the problem and fall into a rabbit hole: adding tons of complexity for only marginal performance gains.</p> <p>It helps to remember that each time light reflects, it loses intensity. So usually, the strongest contribution to the final signal is from the first object the light hits. For a lot of real-world remote sensing tasks, the linear model gives a good enough approximation. If it doesn’t, then it’s time to explore something more complex.</p> <h1 id="ndfi">NDFI</h1> <p>After a long (but necessary) introduction about SMA, now it’s time to talk about NDFI itself.</p> <p>In the original paper, the authors used Green Vegetation (GV), Non-Photosynthetic Vegetation (NPV), Soil, and Shadow as their endmembers. Since their goal was to detect selectively logged and burned forest, these were the classes they considered useful. The underlying idea is that undisturbed forest has a high proportion of GV, while disturbed forest has more NPV and Soil. So in the original implementation, NDFI grouped all green vegetation into a single GV class.</p> <p>However, when we apply regular spectral unmixing in forested areas, we run into a common problem: shadows. Forest canopies often cast strong shadows, which can dominate parts of the spectral signal and throw off the GV proportion. To correct for this, the original method normalized the GV fraction by the proportion of non-shadow in the pixel:</p> \[GV_{\text{Shade}} = \frac{GV}{1 - \text{Shade}}\] <p>After this correction, they calculated the normalized difference between the corrected GV and the combined NPV + Soil fraction using this equation:</p> \[\text{NDFI} = \frac{GV_{\text{shade}} - (NPV + Soil)}{GV_{\text{shade}} + NPV + Soil}\] <p>This simple adjustment makes a big difference. By correcting GV with shadow and structuring the index around the key land cover fractions, NDFI performs very well for what it was originally designed to do.</p> <p>However, if we want to use NDFI for a different purpose, for example as a predictor for above-ground biomass (ABG), then a critical adaptation of the index may be useful. Intuitively, I think separating trees from grass or shrubs would be helpful, since they have very different biomass, even though both are green vegetation.</p> <p>The main concept of NDFI still holds. What changes is the definition of the endmembers and how we combine them in the index. For instance, in a biomass mapping application, we may want to compute the proportion of tree cover relative to all other land cover types (grass, shrub, NPV, soil, etc). That way, NDFI becomes more aligned with the information we care about.</p> <p>And of course, endmember selection is flexible. Different ecoregions may require different class definitions depending on which surface types are important—or which ones can be safely ignored.</p> <h1 id="example-ndfi-in-tropical-forest-using-sentinel-2">Example: NDFI in Tropical Forest Using Sentinel-2</h1> <p>Let’s use Sentinel-2 imagery to look at a tropical rainforest area in Borneo as an example. Below is the RGB image of the area, along with the NDFI result. The NDFI here is computed using Tree, Grass, Soil, and Shadow as the endmembers. The endmember spectra were extracted manually from the image.</p> <p>There are some buildings visible, but I didn’t include them as endmembers since they’re irrelevant for this analysis. I also couldn’t find a convincing candidate for NPV in this area, so I excluded it. Therefore, the NDFI in this example is calculated by comparing the shadow-corrected Tree fraction with the sum of Grass and Soil fractions.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_12_rgb_and_ndfi-480.webp 480w,/assets/img/post_12_rgb_and_ndfi-800.webp 800w,/assets/img/post_12_rgb_and_ndfi-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_12_rgb_and_ndfi.png" class="img-fluid rounded" width="100%" height="auto" alt="Iamge show the RGB Composite of Sentinel 1 Imagery in a Tropical Forest of Borneo on the left, and the NDFI result showing fraction of shadow corrected tree cover compared to soil and grass on the right" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Sentinel RGB Image on the left, and the NDFI result on the right. </div> <p>A high NDFI value (shown in red) indicates a higher proportion of tree canopy inside a pixel, which usually suggests denser forest. Areas in yellow or orange still have tree canopy dominance, but are less dense. Regions in green to blue have minimal or no tree cover.</p> <p>Even visually, we can already see that this image helps distinguish dense forest, which likely has higher AGB, from sparser or degraded forest. In the context of a stocking index, the next step would be to explore the relationship between this NDFI output and AGB modeled from field measurements.</p> <p>It’s also important to point out that generating NDFI requires us to first compute the fractional abundance of each endmember from the spectral unmixing. This intermediate result can be useful on its own. For instance, the Soil fraction alone is quite effective at highlighting small roads, which can be a valuable input layer for downstream tasks like road detection using deep learning.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_12_soil_fractions-480.webp 480w,/assets/img/post_12_soil_fractions-800.webp 800w,/assets/img/post_12_soil_fractions-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_12_soil_fractions.png" class="img-fluid rounded" width="100%" height="auto" alt="Spectral unmixing result showing the fraction of soil area inside every pixel of the image, this is very usefull for example for input for road detection model using deep learning." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Soil fraction as an intermediate result in the NDFI computation. This image is also useful if the goal is to detect small dirt roads, for example. Notice the small dirt road to the west of the main road, previously hardly visible in the original RGB image. </div> <p>And for standard visualization purposes, it’s also useful to combine the fraction layers into a false color composite to visualize how different land cover types are distributed spatially.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_12_false_color-480.webp 480w,/assets/img/post_12_false_color-800.webp 800w,/assets/img/post_12_false_color-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_12_false_color.png" class="img-fluid rounded" width="100%" height="auto" alt="More realistic surface condition of vegetated earth surface. In this case each light ray hit multiple object before reflected out to the sensor. This complex interaction between light and multiple object casuing the mixture to be defiated from the linear model." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. False color composite combining the soil, tree, and grass fractions. This visualization helps make the spatial distribution of land cover types easier to interpret for human analysis. </div> <h1 id="my-takeaway">My Takeaway</h1> <p>I was working on a small research project about above-ground biomass when I stumbled back upon this method. While thinking more carefully about it, and while writing this post, I realized a few important general takeaways about doing remote sensing analysis.</p> <p>First, it’s tempting to just take some well-known equation, apply it to our data, and call it a day. On the other extreme, we might overthink the physics and math behind the problem, end up overengineering the solution, and spend a lot of time, effort, and money, only to gain marginal improvements in the final result.</p> <p>Ideally, we should aim for something in between. We invest time early on to build a solid understanding of the fundamentals, clarify the real goal of the analysis, and consider the available resources. Then we design a solution that balances practicality, accuracy, and efficiency.</p> <p>In the end, good remote sensing work is not just about applying the right method, but about applying the right level of thinking about the goal, the problem, the solution, and the constraint.</p>]]></content><author><name></name></author><category term="remote_sensing,"/><category term="spectral_unmixing,"/><category term="biomass,"/><category term="forest,"/><category term="environment,"/><category term="multispectral"/><summary type="html"><![CDATA[A practical dive into the Normalized Difference Fraction Index (NDFI), its origins in forest degradation monitoring, a deeper understanding on its foundation, and how we can adapt it for different goals like above-ground biomass estimation.]]></summary></entry><entry><title type="html">Testing Sentinel-2 Super Resolution Using S2DR3</title><link href="https://nasirlukman.github.io/blog/2025/s2dr3/" rel="alternate" type="text/html" title="Testing Sentinel-2 Super Resolution Using S2DR3"/><published>2025-05-09T23:36:10+00:00</published><updated>2025-05-09T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/s2dr3</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/s2dr3/"><![CDATA[<p>Super-resolution generally refers to methods that increase the spatial resolution of an image using lower-resolution input. In other words, it’s trying to make the pixels smaller so the image looks sharper and more detailed. I’ve always been skeptical with such approach. Even with more conservative approaches like pan-sharpening, you often end up with spectral distortions, especially in longer wavelengths like NIR or SWIR.</p> <p>When deep learning-based methods started showing up a few years ago, I was even more doubtful with the practical application of these approach. The idea of forcing a computer to “hallucinate” an object otherwise invisible by the sensor didn’t sit well with me. Maybe it’s because I come from a spectral geology background, and I’m used to working with data where spectral integrity really matters. I prefer images to stay as unaltered as possible so they can be analyzed properly.</p> <p>Lately, I saw a lot of people talking about a new super-resolution model called <a href="https://medium.com/@ya_71389/sentinel-2-deep-resolution-3-0-c71a601a2253">S2DR3</a>. It seems to get a good response from the remote sensing community. Probably because recently I started to work with a less niche application of remote sensing, I start to be more open minded and curious to test what this model can actually do ande decided to give it a try.</p> <p>The model essentially is a CNN-based deep learning model trained on artificial/synthetic high-resolution multispectral data (not entirely sure how that part was done, and it’s not fully disclosed as far as I can tell). The model takes Sentinel-2 images that have been resampled to 10 meters and produces output with 1 meter resolution. So, basically it turns each pixel into 100 new pixels per band.</p> <p>I tested it in various locations across Indonesia covering scenes realted with mining, agricultu, and urban areas. I wanted to run a quick test on its spatial and spectral integrity by doing visual comparisons with very high resolution WorldView images and also sampling random points to compare spectra and compute RMSE.</p> <h2 id="spatial-integrity-by-visual-comparison">Spatial Integrity by Visual Comparison</h2> <p>Below are a few example scenes: in various different locations. Senitnel-2 image have 10 meters spatial resolution, S2DR3 result have 1 meters spatial resolution, and WorldView image have 30 centimeters spatial reoslution.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_11_asgm-480.webp 480w,/assets/img/post_11_asgm-800.webp 800w,/assets/img/post_11_asgm-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_11_asgm.png" class="img-fluid rounded" width="100%" height="auto" alt="Satellite view of illegal artisanal small-scale gold mining area in Central Borneo using Sentinel-2 super-resolution model S2DR3, showing improved spatial details like mining pools and bare land patches" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Illegal artisinal small scale gold mining area in Central Borneo </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_11_asgm_zoom-480.webp 480w,/assets/img/post_11_asgm_zoom-800.webp 800w,/assets/img/post_11_asgm_zoom-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_11_asgm_zoom.png" class="img-fluid rounded" width="100%" height="auto" alt="Zoomed-in satellite image of illegal gold mining site in Central Borneo highlighting narrow partition between water-filled mining pits, showing S2DR3 model's capability to distinguish fine spatial features from Sentinel-2 data" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Zoomed in version of Image 1 </div> <p>Image 1 and Image 2 shows an illegal gold mining in Central Borneo at different scale. Being able to detect each small pool is important, both for monitoring and for any restoration effort. Spectral information could also help differentiate pools with different physical and chemical properties. I find in this case that S2DR3 provides an excelent result which are able to reasonably match the very high resolution WordlView image. In Image 2, the red box highlights a narrow partition (less than 5 meters) between pools, which the model captures quite accurately.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_11_coal_mine-480.webp 480w,/assets/img/post_11_coal_mine-800.webp 800w,/assets/img/post_11_coal_mine-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_11_coal_mine.png" class="img-fluid rounded" width="100%" height="auto" alt="Super-resolved satellite image of an active coal mine in East Borneo using S2DR3 model, enhancing visibility of haul roads and mine infrastructure compared to original Sentinel-2 image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Active coal mine in Eastern Borneo </div> <p>Image 3 shows an active coal mine in East Borneo. The original Sentinel-2 barely shows the mining roads, but in the S2DR3 result, two main roads become clearly visible. Very useful detail which quite amazingly captured by the model.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_11_rice_field-480.webp 480w,/assets/img/post_11_rice_field-800.webp 800w,/assets/img/post_11_rice_field-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_11_rice_field.png" class="img-fluid rounded" width="100%" height="auto" alt="High-resolution satellite image of rice field partitions in Sembalun, Lombok generated using Sentinel-2 and S2DR3 deep learning super-resolution model, showing clear delineation of agricultural plots" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Rice fields in Sembalun, Lombok </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_11_palm_plantation-480.webp 480w,/assets/img/post_11_palm_plantation-800.webp 800w,/assets/img/post_11_palm_plantation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_11_palm_plantation.png" class="img-fluid rounded" width="100%" height="auto" alt="Palm oil plantation in South Sumatra enhanced with S2DR3 model showing individual palm tree canopies, demonstrating the model’s effectiveness in detecting vegetation structure from Sentinel-2 data" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Palm plantation in South Sumatera </div> <p>Image 4 and 5 shows examples related with agricultural field. Image 4 shows rice fields in Sembalun where S2DR3 can separate each individual partitions of the rice filed really well. Image 5 shwos an even impressive performance where individual palm canopies in palm plantation in Souhth Sumatera are predicted with good accuracy.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_11_urban-480.webp 480w,/assets/img/post_11_urban-800.webp 800w,/assets/img/post_11_urban-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_11_urban.png" class="img-fluid rounded" width="100%" height="auto" alt="Dense urban area in Yogyakarta visualized using S2DR3 super-resolution model on Sentinel-2 imagery, revealing roads and building outlines while showing limitations in distinguishing adjacent rooftops with similar materials" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Dense buildup are in Yogyakarta </div> <p>Image 6 shows a dense urban are in the heart of Yogyakarta. This one is more challenging. If you zoom in, S2DR3 tends to merge adjacent buildings with the same roof material. However, bigger building, roads, and small building with different roof material with its surroundings are still reconstructed with shapes close to the original condition.</p> <h2 id="spectral-integrity-by-random-sample-comparison">Spectral Integrity by Random Sample Comparison</h2> <p>To check spectral performance, I sampled points from each image and compared the original Sentinel-2 spectra with the S2DR3 result. The RMSE plots (Image 7) show that RGB bands hold up better than the longer wavelengths. Probably has to do with how the synthetic high resolution training data was generated. Still, even in the longer wavelengths, the errors aren’t too bad. For many use cases, the results might be good enough.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_11_spectra_rmse-480.webp 480w,/assets/img/post_11_spectra_rmse-800.webp 800w,/assets/img/post_11_spectra_rmse-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_11_spectra_rmse.png" class="img-fluid rounded" width="100%" height="auto" alt="Scatter plot showing RMSE of reflectance values across Sentinel-2 spectral bands comparing original and S2DR3 output, indicating better spectral fidelity in RGB bands and moderate errors in NIR and SWIR wavelengths" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Reflectance value comparion of each band of Sentinel-2 vs S2DR3 result. </div> <h2 id="final-thoughts">Final Thoughts</h2> <p>Honestly I am really impressed. This feels like magic, or cheating reality. In any case, when using this model, it is important not to confuse the result with real 1-meter data. Think of it more like an <em>intelligent interpolation</em>. The model has learned spatial and spectral patterns from a massive dataset and able to execute something like a context aware non-linear interpolation of the input data with acceptable error. So far I haven’t seen anything that looks like an absurd hallucination out of the model, but we should stay cautious and interpret the results critically, especially if we’re using them for any decision-making.</p> <p>I am quite optimistic that this is a useful model for a range of agricultural and environmental applications. Tasks like detecting small ponds, informal roads, crop plots, or even estimating canopy cover could benefit from the extra spatial detail. I wonder how far we are until we get the same model for hyperspectral images 👀.</p> <p>If you’re working with Sentinel-2 images, I strongly recommend checking out more <a href="https://storage.googleapis.com/0x7ff601307fa2/s2dr3menu2.html">examples</a> and one of the authors’ <a href="https://medium.com/@ya_71389/sentinel-2-deep-resolution-3-0-c71a601a2253">articles</a>. Try the model yourself and see how it performs in your use case.</p>]]></content><author><name></name></author><category term="remote_sensing,"/><category term="monitoring,"/><category term="data_science,"/><category term="multispectral,"/><category term="environment,"/><category term="mining,"/><category term="urban"/><summary type="html"><![CDATA[Quick look at spatial and spectral integrity of S2DR3 Model in mining, agricultur, and urban related scene]]></summary></entry><entry><title type="html">Mapping Lithium Bearing Mineral in Granite Core Sample with Hyperspectral Imaging</title><link href="https://nasirlukman.github.io/blog/2025/hyperspectral-lithium-granite-core/" rel="alternate" type="text/html" title="Mapping Lithium Bearing Mineral in Granite Core Sample with Hyperspectral Imaging"/><published>2025-05-03T23:36:10+00:00</published><updated>2025-05-03T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/hyperspectral-lithium-granite-core</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/hyperspectral-lithium-granite-core/"><![CDATA[<p>Detecting lithium in rocks is a known challenge. Standard tools like handheld or desktop XRF can’t pick it up due to lithium’s low atomic number (Z=3). Advanced techniques such as ICP-MS, LA-ICP-MS, and LIBS can measure lithium, but they come with trade-offs: they’re expensive, time-consuming, and at least mildly destructive.</p> <p>At exploration stage, the focus tend to shift to lithium host minerals rahter than the lithium itself, especially spodumene (pyroxene group), lepidolite (mica group), and cookeite (chlorite group). These minerals are more practical to detect using common analytical tools such as XRD, Raman spectroscopy, or reflectance spectroscopy like ASD and Hyperspectral Imaging (HSI). While XRD and Raman have their strengths, HSI offers unique advantages: it’s non-destructive, spatially continuous (100–500 μm resolution), and scalable—from thin sections to core samples, outcrops, and even satellite scenes.</p> <p>In this post, I’ll show a case study using hyperspectral imaging on a small section of a lithium-bearing granite core sample from Devon, UK.</p> <h2 id="spectral-signatures">Spectral Signatures</h2> <p>distinguish between different white mica species, as only lepidolite contains lithium. White micas exhibit absorption features near 1400 nm, 1900 nm, and especially around 2200 nm due to OH vibrational overtones. Differentiating between species requires detecting subtle shifts in the ~2200 nm feature.</p> <p>Muscovite, which contains Al-OH bonds, shows an absorption feature near 2206 nm. When Al is substituted by other cations like Fe, Mg, or Li, the position of this feature shifts. Specifically, Fe- and Mg-rich white micas such as phengite shift the feature to longer wavelengths (~2230 nm), while Li-rich micas like lepidolite shift it to shorter wavelengths (~2195 nm). In this rock sample, we observe this feature ranging from ~2195 nm to ~2208 nm, indicating a compositional transition from lepidolite to muscovite.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_10_lepidolite_muscovite_spectra-480.webp 480w,/assets/img/post_10_lepidolite_muscovite_spectra-800.webp 800w,/assets/img/post_10_lepidolite_muscovite_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_10_lepidolite_muscovite_spectra.png" class="img-fluid rounded" width="100%" height="auto" alt="Spectral signature comparison between lepidolite and muscovite in a lithium-rich granite sample. The plot highlights the subtle shift in the 2200 nm absorption feature, with lepidolite showing a feature near 2195 nm (shorter wavelength) and muscovite at 2206 nm (longer wavelength). This shift is key to differentiating lithium-bearing minerals from other white mica species using hyperspectral imaging." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Difference between lepidolite and muscovite spectra. </div> <h2 id="minimum-wavelength-mapping">Minimum Wavelength Mapping</h2> <p>To visualize subtle shifts in absorption features, we use Minimum Wavelength Mapper. Generally this method can be devided into four steps.</p> <ol> <li>Detect the deepest absorption feature within a chosen wavelength range.</li> <li>Fit a 2nd-order polynomial around the feature to interpolate the true minimum (often sub-band resolution).</li> <li>Extract the interpolated wavelength position and absorption depth.</li> <li>Map them using hue (wavelength) and brightness (depth).</li> </ol> <p>For this analysis I am using an open source software called <a href="https://zenodo.org/records/14335092">Hyppy</a> which are developed by the ITC Earth Science Labs in University of Twente. The result are shown in the image below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_10_minimum_wavelength_mapper-480.webp 480w,/assets/img/post_10_minimum_wavelength_mapper-800.webp 800w,/assets/img/post_10_minimum_wavelength_mapper-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_10_minimum_wavelength_mapper.png" class="img-fluid rounded" width="100%" height="auto" alt="Minimum Wavelength Map of a lithium-bearing granite core sample showing the spatial distribution of the deepest absorption feature around 2200 nm. The image is color-coded to represent wavelength position, with blue indicating shorter wavelengths and purple for longer wavelengths. The brightness indicates absorption depth, with dark pixels showing absence of white mica minerals and lighter pixels representing areas where they are present. The map shows a transition from muscovite at the margins of the granite to lepidolite in the core." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Minimum Wavelenth Map of the rock sample showing the gradual change from lepidolite to muscovite. </div> <p>In this image, the wavelength position of the deepest absorption feature is represented by hue, where the color blue indicating shorter wavelengths and purple indicating longer wavelengths. The depth of the feature is shown as brightness. Dark or black pixels correspond to areas where the OH feature is absent, meaning no white mica minerals are present. Several important observations can be made from this visualization. First, the occurrence of white mica minerals appears to be confined to the main body of the granite, and they are largely absent in both the surrounding veins and the host rock. Second, there is a clear spatial gradient in the wavelength position of the deepest absorption feature, shifting from longer wavelengths near the contact zone between the granite and the host rock, to shorter wavelengths deeper within the granite body. This pattern reflects a compositional transition in the white mica group, from muscovite at the margins to lepidolite in the granite core. This suggests that the original granite magma was already enriched in lithium, and interaction with the surrounding sedimentary rocks likely introduced additional aluminum—and possibly iron and magnesium—substituting for lithium in the octahedral sheets of the mica structure.</p> <h2 id="classification">Classification</h2> <p>While minimum wavelength mapping offers rich insight, classifications help simplify the output. I applied a decision tree classifier to assign each pixel to one of 10 classes based on the absorption wavelength and depth values.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_10_image_classification-480.webp 480w,/assets/img/post_10_image_classification-800.webp 800w,/assets/img/post_10_image_classification-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_10_image_classification.png" class="img-fluid rounded" width="100%" height="auto" alt="Decision Tree Classifier result for the lithium-bearing granite core sample, showing 10 different mineral groups based on absorption wavelength and depth values. The classification identifies various minerals, including different species of white mica, based on the spectral features detected by hyperspectral imaging. This map helps visualize the mineral zoning within the granite, highlighting areas rich in lithium-bearing minerals like lepidolite." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Decision Tree Classifier result of the rock sample showing 10 different mineral group in the rock sample. </div> <p>This case study highlights how HSI is a powerful tool for identifying lithium-bearing minerals through subtle spectral variations. By focusing on the spectral behavior of white micas, particularly shifts in the ~2200 nm absorption feature, we can non-destructively infer mineralogical variations linked to lithium content. The spatial resolution and continuous coverage offered by hyperspectral data enable detailed mapping of mineral zoning within core samples, providing valuable insight into the geological processes at play.</p> <p>The spatial distribution of white mica species is valuable beyond lithium exploration, as different white micas can be associated with distinct temperature and geochemical conditions in hydrothermal systems, making them effective vectors toward ore bodies. One of the key advantages of HSI is its scalability: the same spectral analysis applied to core samples can be extended to outcrops and even regional scales using airborne or satellite platforms.</p>]]></content><author><name></name></author><category term="spectral_geology,"/><category term="mineral,"/><category term="data_science,"/><category term="geology,"/><category term="hyperspectral,"/><category term="core_scanning"/><summary type="html"><![CDATA[Using Minimum Wavelength Mapper and Decision Tree Classifier to analyze hyperspectral image of lithium bearing granite core sample.]]></summary></entry><entry><title type="html">Multi Sensor Object Based Image Classification for Land Use/Land Cover Analysis</title><link href="https://nasirlukman.github.io/blog/2025/OBIA-LULC/" rel="alternate" type="text/html" title="Multi Sensor Object Based Image Classification for Land Use/Land Cover Analysis"/><published>2025-04-08T23:36:10+00:00</published><updated>2025-04-08T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/OBIA-LULC</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/OBIA-LULC/"><![CDATA[<p>In this post, I will share a Land Use Land Cover (LULC) project I did combining multiple sensors. To tackle the common problem of the salt and pepper effect in pixel-based image classification, an object-based approach was chosen for this task. The steps generally involved stacking images from multiple sensors, performing image segmentation using SNIC, taking the mean value of each band from each segment, and running supervised classification using Random Forest.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_classification%20steps-480.webp 480w,/assets/img/post_9_classification%20steps-800.webp 800w,/assets/img/post_9_classification%20steps-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_classification%20steps.gif" class="img-fluid rounded" width="100%" height="auto" alt="Classification steps showing the process from image stacking, segmentation with SNIC, feature extraction, and supervised classification with Random Forest." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Classification steps. </div> <h2 id="methods">Methods</h2> <p>The land cover classes consist of categories such as forest, shrubs, mangroves, bare land, built-up areas, water, and plantations. Optical and radar images are known to have effective discriminating ability among those classes, which is why we used Landsat-8 and Sentinel-1 sensors. The VIIRS night-time light sensor captures light emissions on the Earth’s surface, which is useful to detect built-up areas. At this stage, we also included elevation data from SRTM, since it was available.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_raw_data-480.webp 480w,/assets/img/post_9_raw_data-800.webp 800w,/assets/img/post_9_raw_data-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_raw_data.png" class="img-fluid rounded" width="100%" height="auto" alt="Raw satellite images from Landsat-8, Sentinel-1, VIIRS NTL, and SRTM elevation data, serving as inputs for land use classification." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Raw satellites images input. </div> <p>The next step was to extract additional features from the raw data. From the Landsat image, we calculated several spectral indices to highlight different features of the land surface. We also calculated GLCM features to extract textural information. Additionally, we computed band ratios from Sentinel-1 imagery, and we calculated slope from the SRTM elevation data. In total, 27 bands were obtained and prepared as inputs for the classification.</p> <p>Not all of those bands are useful for the classification purpose, so the next step was feature selection to pick only the most important bands for the final classification. Permutation importance was used for this, which also considers simple correlation between bands. Eight bands were selected for the final classification:</p> <ol> <li>Modified Normalized Difference Water Index (MNDWI)</li> <li>VV/VH Sentinel 1 Ratio</li> <li>GLCM Textural Contrast</li> <li>Normalized Difference Vegetation Index (NDVI)</li> <li>VIIRS Night Light Radiance</li> <li>Landsat Band 1</li> <li>Build up Index (BI)</li> </ol> <h2 id="results-and-insight">Results and Insight</h2> <p>The final result is an annual LULC map of the area. Overall accuracy is around 96%, with most of the errors coming from false positives in palm oil plantations. The palm oil plantations in this region are quite heterogeneous in which some areas are densely planted, while others are more spacious. The more spacious ones often appear similar to shrubs or low canopy forests, which causes confusion.</p> <p>The model can then be generalized to different timestamps with roughly the same accuracy (94–96%).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_results_3_year-480.webp 480w,/assets/img/post_9_results_3_year-800.webp 800w,/assets/img/post_9_results_3_year-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_results_3_year.gif" class="img-fluid rounded" width="100%" height="auto" alt="Final land use/land cover classification result from 2017 to 2024 showing the area’s land cover change." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Classification Results </div> <p>If we look at the results from 2017 to 2024, we can see some interesting trends:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_LULC_graph-480.webp 480w,/assets/img/post_9_LULC_graph-800.webp 800w,/assets/img/post_9_LULC_graph-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_LULC_graph.png" class="img-fluid rounded" width="100%" height="auto" alt="Time series graph of land use/land cover changes, highlighting trends in various land cover classes from 2017 to 2024." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Time series graph of few LULC class </div> <p>First, there’s a sharp decline in high-density forest from 2017 to 2019, which then stabilizes. We can also see a slow and steady decline in mangroves. Interestingly, for both of these classes, the land cover changes aren’t shifting toward human-made landscapes like built-up areas, plantations, or even bare land. Most of the changes are into shrubs. This might be related to more indirect effects of human activity on the environment rather than direct conversion.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_LULC_mangrove-480.webp 480w,/assets/img/post_9_LULC_mangrove-800.webp 800w,/assets/img/post_9_LULC_mangrove-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_LULC_mangrove.png" class="img-fluid rounded" width="100%" height="auto" alt="LULC change showing the slow decrease of mangrove cover from 2017 to 2024." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. LULC change showing slow decrease of mangrove cover from 2017 to 2024. </div> <p>Second, there’s a quite remarkable increase in low canopy forest. Most of the low canopy forest areas appear to have changed from shrubs. The most significant increase happened between 2019 and 2024, which is the same period when the decline of high canopy forest slowed down or stopped. Both of these phenomena are likely the result of conservation and restoration efforts that are currently ongoing in the region.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_LULC_forest-480.webp 480w,/assets/img/post_9_LULC_forest-800.webp 800w,/assets/img/post_9_LULC_forest-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_LULC_forest.png" class="img-fluid rounded" width="100%" height="auto" alt="LULC change showing the increase of low canopy forest cover from 2017 to 2024, highlighting changes from shrubs." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. LULC change showing increase of low canopy forest cover from 2017 to 2024. </div> <p>The final thing that stands out is the slow and steady increase in built-up areas. Most of the new built-up areas seem related to local community settlements in small towns or villages near riverbanks, and some appear to be plantation housing and factory sites.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_LULC_buildup-480.webp 480w,/assets/img/post_9_LULC_buildup-800.webp 800w,/assets/img/post_9_LULC_buildup-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_LULC_buildup.png" class="img-fluid rounded" width="100%" height="auto" alt="LULC change showing the slow increase of built-up areas from 2017 to 2024, indicating urban development in riverbank settlements." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. LULC change showing slow increase of build up area from 2017 to 2024. </div> <hr/> <p>This project shows how combining different sensors and using an object-based approach can produce accurate and insightful land cover maps. Beyond just the numbers, the patterns we see from year to year tell a deeper story about environmental change, pressure from human activity, and efforts to restore and protect our landscapes.</p>]]></content><author><name></name></author><category term="remote_sensing,"/><category term="monitoring,"/><category term="environment,"/><category term="forest,"/><category term="data_science,"/><category term="machine_learning,"/><category term="radar,"/><category term="multispectral"/><summary type="html"><![CDATA[Combinining Landsat-8, Sentinel-1, VIIRS NTL, and SRTM for object based image classification using SNIC and Random Forest]]></summary></entry><entry><title type="html">Spatio-Temporal Analysis of Industrial and Artisinal Offshore Tin Mining Vessel</title><link href="https://nasirlukman.github.io/blog/2025/mining-vessel/" rel="alternate" type="text/html" title="Spatio-Temporal Analysis of Industrial and Artisinal Offshore Tin Mining Vessel"/><published>2025-04-04T23:36:10+00:00</published><updated>2025-04-04T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/mining-vessel</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/mining-vessel/"><![CDATA[<p>Most of the tin sold on the international market comes from a small island in Indonesia called Bangka. What’s less known is that a significant amount of that tin is mined offshore. There are two types of vessels commonly involved in this activity. Large dredger vessels, typically 50 to 120 meters in length, are operated by formal mining companies at industrial scale. At the same time, there are smaller artisanal boats—usually no more than 10 meters long—using simple suction pumps handled by divers and connected to traditional sluice boxes onboard. The later are typically related with illegal mining activities.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_vessel_example-480.webp 480w,/assets/img/post_8_vessel_example-800.webp 800w,/assets/img/post_8_vessel_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_vessel_example.png" class="img-fluid rounded" width="100%" height="auto" alt="Two types of offshore mining vessels: large dredger vessels (metal-bodied, 50-120 meters) and smaller artisanal vessels (wooden, under 10 meters)." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Two types of offshore mining vessels. </div> <h2 id="ship-detection-and-classification">Ship Detection and Classification</h2> <p>To better understand how offshore mining activity changes over time, I’ve been developing a ship detection algorithm tailored to this region. I use Sentinel-1 SAR data, which is particularly suitable for this task. Not only can it see through the frequent cloud cover over the shores of Bangka, but it also does a good job of capturing the contrast between open water and floating objects—even relatively small ones.</p> <p>For this study, I focused on the eastern part of Bangka Island.</p> <p>Before doing any detection, I needed a good quality ‘ground truth’ data. In this case that meant finding scenes where Sentinel-1 and Sentinel-2 images—or ideally very high-resolution optical images—were available on the same date. This allows for visual confirmation of vessel types and ensures that the training data is as accurate as possible.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_small_vessel_example-480.webp 480w,/assets/img/post_8_small_vessel_example-800.webp 800w,/assets/img/post_8_small_vessel_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_small_vessel_example.png" class="img-fluid rounded" width="100%" height="auto" alt="Worldview, Sentinel-2, and Sentinel-1 imagery taken at the same location with only a few hours apart showing a small artisanal mining vessel" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Worldview, Sentinel-2, and Sentinel-1 imagery taken at the same spot with only few hours apart showing small/artisinal mining vessel. </div> <p>After collecting a good number of examples, I started looking into how the SAR sensor responds to the different types of vessels. It turns out that their radar signatures are quite distinct, especially when you compare the VV and VH polarizations of Sentinel-1.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_training_data_distribution-480.webp 480w,/assets/img/post_8_training_data_distribution-800.webp 800w,/assets/img/post_8_training_data_distribution-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_training_data_distribution.png" class="img-fluid rounded" width="100%" height="auto" alt="Sentinel-1 sensor responses of large (metal) and small (wooden) vessels in both VV and VH polarizations, showing distinct radar signatures." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Sentinel-1 sensor responses of the large and small vessels. </div> <p>The differences in backscatter likely relate to both the size of the vessels and the materials they’re made of. while large mining vessel are made out of metals, the smaller artisinal mining vessel are made out of wood.</p> <p>For classification, I used an object-based approach. First, I segmented the image, and then applied a support vector machine (SVM) to classify the segmented objects. The training result was promising: a validation accuracy of about 98%.</p> <h2 id="results-and-analysis">Results and Analysis</h2> <p>I deployed the trained model across a time series of Sentinel-1 imagery, covering the period from early 2017 to early 2025. The result is a spatial and temporal map of detected vessels.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_result_stacked-480.webp 480w,/assets/img/post_8_result_stacked-800.webp 800w,/assets/img/post_8_result_stacked-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_result_stacked.png" class="img-fluid rounded" width="100%" height="auto" alt="Object-based classification result showing the detection of large and small mining vessels in the study area." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Object based classification result example. </div> <p>To make sense of these results, I created a time series map animatioin showing the density of both large and small vessels over time.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_vessel_density_timelapse-480.webp 480w,/assets/img/post_8_vessel_density_timelapse-800.webp 800w,/assets/img/post_8_vessel_density_timelapse-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_vessel_density_timelapse.gif" class="img-fluid rounded" width="100%" height="auto" alt="Time series animation showing the density of large and small vessels over time, illustrating the changes in offshore mining activity." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Timseries animation of the large and small vessels density. </div> <p>And add a plot to tracks the number of vessels by type at each timestamp.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_timeseries_plot-480.webp 480w,/assets/img/post_8_timeseries_plot-800.webp 800w,/assets/img/post_8_timeseries_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_timeseries_plot.png" class="img-fluid rounded" width="100%" height="auto" alt="Timeseries plot showing the count of large and small vessels detected at each timestamp, indicating fluctuations in mining activity." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Timeserise plot of ship counts for each class. </div> <p>Since it is quite difficult to extract meaningful infomration from this plot alone, I used seasonal decomposition to separate long-term trends from seasonal cycles.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_seasonal_decomposition-480.webp 480w,/assets/img/post_8_seasonal_decomposition-800.webp 800w,/assets/img/post_8_seasonal_decomposition-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_seasonal_decomposition.png" class="img-fluid rounded" width="100%" height="auto" alt="Seasonal decomposition of the time series result, separating long-term trends and seasonal cycles in mining vessel activity" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Seasonal decomposition of the timeseris result </div> <p>Both vessel types show the same general long term trends, and both have a sharp drop in activity around late 2020—most likely a result of the COVID-19 outbreak. The seasonal patterns are also quite interesting. Smaller vessels tend to be most active between January and March, with a noticeable peak in January. Larger vessels, on the other hand, see more activity in March to May and again in October and November.</p> <h2 id="notes-and-consideration">Notes and Consideration</h2> <p>Since this is a mining area, most of the ships present are a mining vessel. However, other ship types are present as well, i.e. cargo ships and fishing boats. Cargo vessels tend to be large and metal-bodied, which makes them look similar to large mining dredgers in SAR imagery. On the other hand, traditional fishing boats are smaller and usually built from wood, making them potential look-alikes for artisanal mining vessels.</p> <p>Ideally, these look-alike vessels would be included in the training data to reduce false positives. However, collecting reliable ground truth for them is difficult—especially because identifying vessel types often relies on cloud-free optical imagery taken at the same time as the Sentinel-1 scenes. This overlap is rare, making it harder to build a well-labeled dataset and limiting the number of high-quality training samples available for the model.</p> <p>One interesting observation is that mining vessels often operate in clusters. This spatial pattern could be a useful cue for distinguishing them from other types of vessels—especially when radar backscatter alone isn’t enough.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_hot_spots-480.webp 480w,/assets/img/post_8_hot_spots-800.webp 800w,/assets/img/post_8_hot_spots-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_hot_spots.png" class="img-fluid rounded" width="100%" height="auto" alt="All ships detected in the study area, with green boxes highlighting hotspots where mining vessels typically operate in clusters." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. all ships detected in the study area. Green box highlight hot-spots for ships which is a typical pattern for mining vessels. </div> <h2 id="to-wrap-up">To Wrap Up</h2> <p>Offshore tin mining around Bangka is a complex activity, spanning from industrial-scale operations to small artisanal efforts. Continuous monitoring of these activities could helps bring transparency to an industry that often operates in remote and loosely regulated areas. Using freely available satellite data, especially Sentinel-1 SAR, offers a promising way to monitor these activities systematically over time. While there are still challenges such as distinguishing mining vessels from other ships or dealing with limited training data, the initial results shows a strong potential to reveal a meaningful patterns.</p>]]></content><author><name></name></author><category term="remote_sensing,"/><category term="monitoring,"/><category term="mining,"/><category term="security,"/><category term="data_science,"/><category term="machine_learning,"/><category term="radar,"/><category term="GIS"/><summary type="html"><![CDATA[Object-based image classification of mining vessels using Sentinel-1 timeseries.]]></summary></entry><entry><title type="html">Sentinel 1 Change Detection for Forest Monitoring</title><link href="https://nasirlukman.github.io/blog/2025/sentinel1-change-detection/" rel="alternate" type="text/html" title="Sentinel 1 Change Detection for Forest Monitoring"/><published>2025-03-30T23:36:10+00:00</published><updated>2025-03-30T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/sentinel1-change-detection</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/sentinel1-change-detection/"><![CDATA[<p>Last week, I was trying to build a forest monitoring system using Sentinel-1 data. The idea of using radar data instead of optical data is that the climate of most tropical forest areas in the world is characterized by frequent and persistent rainfall, so the cloud cover tends to be high throughout the year. For example, the <a href="https://glad.earthengine.app/view/global-forest-change">Hansen deforestation dataset</a> is a very good-quality global deforestation dataset built using Landsat optical satellite data. The dataset is annual from 2000 to 2023 (last time I checked). I can imagine it would be very hard, and even impossible in some parts of the world, to build a monthly deforestation layer using the same approach due to cloud cover. Unlike optical sensor, radar signal have the ability to penetrate colud cover, making it a more reliable for monitoring in high cloud cover areas.</p> <p>The Sentinel-1 forest monitoring system I built is based on change detection at its core. It simply involves subtracting images from \(\mathbf{t_1}\) and \(\mathbf{t_2}\). However, due to the high noise of radar images and the different atmospheric conditions in \(\mathbf{t_1}\) and \(\mathbf{t_2}\), some care needs to be taken when pre-processing each image. That, and some additional image analysis tricks and magic!</p> <p>Generally, the steps are as follows:</p> <ol> <li> <p><em>Filtering Sentinel-1 Metadata</em>: We filter the metadata to only get images with identical orbital passes and numbers. Radar images are especially sensitive to viewing geometry, so we need to make sure that the viewing geometry of each image is as similar as possible.</p> </li> <li> <p><em>Speckle Filtering</em>: We use both spatial and temporal axes to do speckle filtering using a three-dimensional kernel.</p> </li> <li> <p><em>Additional Normalization and Time-Series Aggregation</em>: These steps help minimize changes that are not related to forest cover change.</p> </li> <li> <p><em>Forest Mask</em> (ideally): We also need to incorporate a forest mask to remove any changes that are not related to the forest (which I didn’t include this time).</p> </li> <li> <p><em>Change Detection</em>: Subtracting images in concecutive time periods and applying threshold value to filter out minor changes due to noises.</p> </li> </ol> <p>Below are examples of the results of this method compared to the Hansen layer for some forest areas in Borneo, which have been converted into palm oil plantations.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_7_result_comparison-480.webp 480w,/assets/img/post_7_result_comparison-800.webp 800w,/assets/img/post_7_result_comparison-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_7_result_comparison.png" class="img-fluid rounded" width="100%" height="auto" alt="Side-by-side comparison between the Hansen deforestation layer (annual) and the Sentinel-1 change detection layer (monthly) for a forest area in Borneo, showing a large deforestation patch in 2024 not recorded in the Hansen dataset." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Result comparison between Hansen deforestation layer and Sentinel 1 change detection layer on the same area in Borneo. </div> <p>The main difference between the two results is the big patch of deforestation in the top-right layer, which was not recorded in the Hansen layer. The Hansen dataset I acquired from Earth Engine only goes up to 2023, and those deforestations are happening in 2024. The most important difference, of course, is the time frequency. My approach records monthly changes, so if we zoom into the top-left patch of the image as an example, we can see the detail of the deforestation progression throughout the months of the year. In this particular case, the palm oil plantation seems to expanded towards the north with pace of 50 Ha/month for a time period of 22 months from June 2018 until March 2020. This example shows the potential of using this type of monthly information to build an early warning system to monitor forest area throughout the globe.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_7_zoomed_in-480.webp 480w,/assets/img/post_7_zoomed_in-800.webp 800w,/assets/img/post_7_zoomed_in-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_7_zoomed_in.png" class="img-fluid rounded" width="100%" height="auto" alt="Zoomed-in view of the top-left deforested area in the Sentinel-1 change detection result, highlighting the detailed progression of deforestation in a palm oil plantation from June 2018 to March 2020, with an expansion rate of 50 hectares per month." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Zoomed in result at the top-left deforested patch of the image. </div> <p>Another potential issue (or maybe a potential feature) of this approach is that, our measurement is essentially a proxy for forest canopy density change. This means it is not only sensitive to deforestation but also to disturbance. Unfortunately, without ground truth, it is difficult to make sure whether these patches are indeed related to actual disturbance events or an artifact of sensor noise. My best bet is that it is currently the combination of both. If we want to exclude these small changese patches we can adjust the threshold, and add aditional post-processing step such as majority kernel. It is very difficult to find an optimum threshold for a very large area (i.e. the whole planet) so some trade-off decision need to be made.</p> <p>Note: There are similar datasets that also use Sentinel-1 to monitor forest changes monthly, such as <a href="https://data.globalforestwatch.org/datasets/gfw::deforestation-alerts-radd/about">RADD Alerts</a>. I compared my result with RADD Alerts, and it produced almost identical results. The advantage of using your own method instead of relying on an existing global dataset is the flexibility to adjust parameters if necessary.</p>]]></content><author><name></name></author><category term="remote_sensing,"/><category term="monitoring,"/><category term="data_science,"/><category term="radar,"/><category term="environment,"/><category term="forest"/><summary type="html"><![CDATA[Using Sentinel-1 data to detect monthly disturbance of forest canopy]]></summary></entry><entry><title type="html">Sentinel-2 Bare Earth Mosaics</title><link href="https://nasirlukman.github.io/blog/2025/bare-earth/" rel="alternate" type="text/html" title="Sentinel-2 Bare Earth Mosaics"/><published>2025-02-19T23:36:10+00:00</published><updated>2025-02-19T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/bare-earth</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/bare-earth/"><![CDATA[<p>As a tropical country, Indonesia faces challenges in using optical remote sensing data for soil and geological analysis due to extensive vegetation cover. According to the Indonesia Land Use/Land Cover (LULC) Map of 2019, only 1.8% of the land is classified as bare land. However, a significant portion of vegetated area (38.2%) consists of agricultural land. During land use changes, particularly in the early stages of agricultural development, land clearing exposes the bare soil. Additionally, many agricultural areas follow cultivation cycles, periodically revealing the soil beneath.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_6_landuse_chart-480.webp 480w,/assets/img/post_6_landuse_chart-800.webp 800w,/assets/img/post_6_landuse_chart-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_6_landuse_chart.png" class="img-fluid rounded" width="100%" height="auto" alt="Donut chart showing the percentage of land use types in Indonesia, reclassified from the Indonesia Land Use/Land Cover (LULC) Map 2019, highlighting bare land, agriculture, forest, and other land cover categories." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Indonesia Land Use percetage, reclassified from Indonesia LULC Map 2019. </div> <p>By leveraging dense time-series satellite images, we can generate a bare earth mosaic, which combines pixels from different acquisition times to maximize the exposure of the ground surface. <a href="https://www.eftf.ga.gov.au/case-study/sentinel-2-reveals-barest-earth">Geoscience Australia</a> has created such maps for the entire continent using Landsat and Sentinel-2 images. Inspired by this, I recently experimented with a method to build a bare earth mosaic for Indonesia using Google Earth Engine.</p> <h2 id="approach">Approach</h2> <p>This approach selects only the driest, non-vegetated pixels from the time-series collection while masking out permanently vegetated, wet, and built-up areas. The process involves:</p> <ol> <li> <p>Cloud Masking: Cloudmasking using <a href="https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless">s2Cloudless</a></p> </li> <li> <p>Pixel Filtering: Using various spectral indices for vegetation, water, and soil to exclude unwanted pixels.</p> </li> <li> <p>Geometric Median Computation: Calculating the geometric median of the remaining pixels to minimize noise and cloud contamination.</p> </li> <li> <p>Final Masking: Removing residual built-up areas using LULC maps.</p> </li> </ol> <p>The resulting image is a bare earth mosaic, highlighting exposed soil and geological features. For visualization purpose, masked vegetation, water, and built-up pixels can be reintroduced.</p> <h2 id="comparison-with-standard-cloudless-mosaics">Comparison with Standard Cloudless Mosaics</h2> <p>The images below compare a standard cloudless mosaic with a bare earth mosaic derived from Sentinel-2 images. The latter effectively selects the barest pixels within agricultural areas and built-up zones.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_6_agriculture-480.webp 480w,/assets/img/post_6_agriculture-800.webp 800w,/assets/img/post_6_agriculture-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_6_agriculture.png" class="img-fluid rounded" width="100%" height="auto" alt="Side-by-side comparison of a standard cloudless mosaic and a bare earth mosaic over agricultural land, showcasing how the bare earth mosaic better highlights exposed soil within agricultural areas." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Comparison between cloudless mosaic and bare earth mosaic in agriculural land. </div> <p>This method also reveals earth surfaces in permanently forested areas, such as landslide-exposed soil and sandbars in rivers during droughts or after heavy rainfall, when sediment is deposited.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_6_river_and_landslide-480.webp 480w,/assets/img/post_6_river_and_landslide-800.webp 800w,/assets/img/post_6_river_and_landslide-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_6_river_and_landslide.png" class="img-fluid rounded" width="100%" height="auto" alt="Side-by-side comparison of a cloudless mosaic and a bare earth mosaic, showing additional features like exposed riverbeds and soil in landslide areas, visible in the bare earth mosaic." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Comparison between cloudless mosaic and bare earth mosaic showing additional in river and landslide. </div> <h2 id="applications-and-challenges">Applications and Challenges</h2> <p>For further geological and soil analysis, it is best to use the masked image. For example in the image below, a simple false color-composite already show:</p> <ol> <li> <p>Soil composition variations in southern hills (greensih color), with some material transported north via river systems.</p> </li> <li> <p>Differences between eastern (yellowish) and western plains (orange).</p> </li> <li> <p>Distinct compositions within mining pits (very bright color).</p> </li> </ol> <p>This color composite highlight the potential of bare earth moscais for geological/soil analysis.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_6_false_color-480.webp 480w,/assets/img/post_6_false_color-800.webp 800w,/assets/img/post_6_false_color-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_6_false_color.png" class="img-fluid rounded" width="100%" height="auto" alt="Comparison of a cloudless mosaic, bare earth mosaic, and false color composite of the masked bare earth mosaic, with a focus on identifying soil composition variations, river sediment transport, and distinct material compositions within mining pits." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Cloudless composite, and bare earth composite, and false color of masked bare earth composite for analysis and interpretation. </div> <p>The main challenge in generating a nationwide bare earth composite for Indonesia is scalability. My current approach exceeds Google Earth Engine’s computational limits when applied at scale. To overcome this, I need to optimize the process or split the computation into hundreds of smaller patches.</p> <p>This is an ongoing experiment, and I hope to refine the method further. If you have suggestions or insights, please feel free to share!</p>]]></content><author><name></name></author><category term="remote_sensing,"/><category term="soil,"/><category term="geology,"/><category term="data_science,"/><category term="multispectral"/><summary type="html"><![CDATA[First trial to build Sentinel-2 bare earth mosaics for Indonesia in Earth Engine]]></summary></entry><entry><title type="html">Illegal Mining From Space</title><link href="https://nasirlukman.github.io/blog/2025/illegal-mining/" rel="alternate" type="text/html" title="Illegal Mining From Space"/><published>2025-02-09T23:36:10+00:00</published><updated>2025-02-09T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/illegal-mining</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/illegal-mining/"><![CDATA[<p>High-resolution satellite imagery provides us with global time-series data, which can be applied to various interesting applications. One such application is monitoring mining activities. There are literally thousands of mining sites across the globe, which are inherently dynamic (i.e., they undergo rapid changes over time) and often located in remote areas. This creates significant challenges for effective monitoring.</p> <p>Any serious attempt at a global-scale analysis of these activities requires the use of satellite imagery in some form. Information such as the extent of mining activity, the mining methods used, and the commodities being extracted can be interpreted from satellite data. Additionally, parameters like land-use changes, soil contamination, and surface water pollution can also be analyzed using satellite imagery.</p> <p>Of course, when discussing illegal mining specifically, satellite data alone may not be sufficient to characterize it fully. This is because the legal frameworks governing mining activities are often complex and vary from country to country. However, there are certain indicators that can help identify potential illegal activities. By incorporating additional layers of geospatial data, stronger evidence of illegal mining can be extracted.</p> <h2 id="very-high-resolution-images">Very High-Resolution Images</h2> <p>A wealth of information related to mining activities can be obtained from very high-resolution satellite images. The most obvious is the delineation of mining area boundaries. With time-series images, we can observe the development of mining activities and the areas they impact. Less obvious but equally important information includes the type of commodity being mined and the methods used. For those familiar with the mining industry, such details can often be inferred from satellite imagery alone. For example, coal mining can be identified by the black color of coal at the mining front or in stockpiles. Similarly, nickel and bauxite lateritic deposits often have distinct visual characteristics that are easily recognizable from space.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_vhr_example-480.webp 480w,/assets/img/post_5_vhr_example-800.webp 800w,/assets/img/post_5_vhr_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_vhr_example.png" class="img-fluid rounded" width="100%" height="auto" alt="Satellite imagery from WorldView showing various mining activities in Indonesia, including distinct alluvial gold and tin mining operations that appear informal and lack structured infrastructure." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Different type of mining activity in Indonesia from WorldView imagery. </div> <p>One key indicator of illegal mining that can be extracted from satellite data is the mining method. Mining activities are often categorized as formal or informal. Formal mining is conducted using appropriate tools and is planned and executed by certified engineers, resulting in well-structured mining pits and infrastructure that are clearly visible from space. In contrast, informal mining is often chaotic and sporadic, lacking proper planning and adherence to good mining practices. The latter type is frequently associated with illegal mining activity, although this is not always the case.</p> <p>In Image 1 above, we can clearly see that the alluvial gold and tin mining example can be classified as informal mining. There are no visible mining infrastructures in the area, and the mining pit appears sporadic and abandoned, resembling a pond.</p> <p>While proven to be very useful, a significant drawback of very high-resolution images is that they are mostly not open data, making access to large spatial and temporal-scale datasets prohibitively expensive. For this reason, large-scale studies often rely more on high-resolution images, using only scarce and limited amounts of very high-resolution data for creating training datasets and/or validation.</p> <h2 id="automated-approach">Automated Approach</h2> <p>Given the large spatial and temporal scales involved, especially for time-series analysis on a regional or global level, an automated approach to mining area delineation and classification is essential. As previously mentioned, human experts interpret mining areas based on visual aspects rather than spectral characteristics (though hyperspectral imagery can improve accuracy). These mining areas are primarily recognized by their spatial patterns. Until recently, deep learning models have proven to be the most effective solution for this type of problem.</p> <p>I develop a small scale deep learning model to automate delinitation of artisinal/small-scale gold mining (ASGM) in some portecteed forest area in Indonesia. I used coarser-resolution NICFI satellite data with a pixel size of 5 meters, which is still sufficient for this purpose. Even lower-resolution satellite images, such as those from Sentinel-2 or Landsat, can produce good results for delineation. The training labels for ASGM boundary were manually delineated from very high-resolution WorldView images, which were then transferred to NICFI images from the same month. The model used was a U-Net architecture, trained on 39 tiles of 256x256 pixels, augmented to 195 images through flipping and rotation. Despite the relatively small training dataset, the model performed well in tracking the development of illegal alluvial gold mining in a protected forest in Indonesia.</p> <p>Below are the accuracy assessments from the validation images. The overall accuracy are 98%. Here, I only show a few validation images containing difficult scenery and look-alike features, such as large active channel bars, formal coal mining areas, and deforestation for agriculture. The model correctly labeled most of these as non-artisanal and small-scale gold mining (ASGM). Some notable false positives were detected in the ponds of formal coal mining areas. It is important to note that the current training data contain no examples of other mining types besides ASGM. Given this limitation, the fact that the model does not classify the entire area of coal mining as ASGM is already a strong result. Incorporating additional, more diverse training data would likely improve the model’s accuracy further.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_unet_validation-480.webp 480w,/assets/img/post_5_unet_validation-800.webp 800w,/assets/img/post_5_unet_validation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_unet_validation.png" class="img-fluid rounded" width="100%" height="auto" alt="Visual comparison between manually labeled validation data and the model’s predictions for artisanal/small-scale gold mining (ASGM) areas, highlighting the model's ability to differentiate between ASGM and other mining types like formal coal mining." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Visual comparison between the validation data labels and the model prediction. </div> <p>After the model get a good accuracy in the testing stage, the model are deployed for a time series analysis in the subset of the study area:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_timeseries_result-480.webp 480w,/assets/img/post_5_timeseries_result-800.webp 800w,/assets/img/post_5_timeseries_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_timeseries_result.gif" class="img-fluid rounded" width="100%" height="auto" alt="Time-series classification animation of artisanal/small-scale gold mining (ASGM) areas, roads, and huts, as delineated by the deep learning model, visualizing the development of mining activities over time." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Timeseries classification result of ASGM areas, roads, and huts. </div> <p>Since this project also aimed to test early detection approach of mining activity, we included labels for hauling roads and mining huts, which often appear before intense mining activity begins. The model also able to deliniate huts and hauling roads as long as it is visible in the imagery by human eyes.</p> <h2 id="environmental-impact">Environmental Impact</h2> <p>As mentioned earlier, satellite imagery can also provide insights into various environmental impacts. Below, we show an empirical model of turbidity levels in rivers downstream of the previously modeled alluvial gold mining sites from Sentinel 2 imagery. By comparing the graph of mining activity with turbidity levels, we can observe a temporary pause in mining activity from late 2019 to 2021, likely due to the COVID-19 pandemic. During the same period, we also observed a decrease in river turbidity, suggesting a direct link between mining activity and river pollution.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_turbidity-480.webp 480w,/assets/img/post_5_turbidity-800.webp 800w,/assets/img/post_5_turbidity-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_turbidity.gif" class="img-fluid rounded" width="100%" height="auto" alt="Turbidity levels animation in rivers downstream of alluvial gold mining sites, observed through Sentinel-2 imagery, showing a decrease in turbidity levels following a pause in mining activity during the COVID-19 pandemic." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Turbidity level downstream of the mining area. </div> <h2 id="further-analysis-with-additional-geospatial-data-layers">Further Analysis with Additional Geospatial Data Layers</h2> <p>For legal and compliance analysis, a reasonable first step is to overlay the generated mining area outlines with other geospatial data layers linked to regulations governing mining activities in a specific country. For example, in Indonesia, we can use mining concession boundaries to determine whether mining activities are conducted within valid permit areas. We can also add data layers related to environmentally restricted areas, such as conservation zones, protected forests, and riparian zones, where mining is prohibited. This is a first-order approach to analyzing compliance levels. As previously stated, the complete regulatory framework for mining is complex, and further detailed analysis is needed for conclusive statements. However, this level of analysis is often sufficient to assess and estimate compliance at a national level.</p> <p>Below is an example of the national level overlay results in Indonesia using data from 2019. Note that the data used in this example are not official and may be incorrect, false, or inaccurate. Nevertheless, the purpose of this post is to demonstrate how compliance levels of mining activities can be assessed using remote sensing and basic geospatial analysis.The results of this data overlay include the percentage of mining areas inside and outside concession boundaries, as well as the percentage of mining areas within environmentally restricted zones.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_donut_chart-480.webp 480w,/assets/img/post_5_donut_chart-800.webp 800w,/assets/img/post_5_donut_chart-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_donut_chart.png" class="img-fluid rounded" width="100%" height="auto" alt="Donut chart displaying the percentage of mining areas located inside and outside of mining concession boundaries and environmentally restricted areas in Indonesia, based on data from 2019." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Donut chart of the mining are classified by its location relative to concession area and environmentally restricted area. </div> <h2 id="complience-analysis">Complience Analysis</h2> <p>To better understand the overlay results, we need to consider relevant regulations. In this study, we incorporated data layers related to mining permits and land-use-based environmental restrictions. These layers help analyze the compliance of mining activities with legal and environmental regulations. Below are the key regulatory frameworks considered:</p> <ol> <li>According to <em>UU No. 4 Tahun 2009</em>, mining activities outside of their designated exploitation concession boundaries are strictly prohibited.</li> <li>According to <em>UU No. 41 Tahun 1999</em>, any land-use activity, including mining, is prohibited within conservation areas.</li> <li>According to <em>UU No. 41 Tahun 1999</em>, surface mining in protected forests is prohibited. Underground mining activity. However, underground mining may be allowed under specific conditions.</li> <li>According to <em>UU No. 41 Tahun 1999</em>, surface mining in production forests is prohibited. Nevertheless, special licenses may be granted to permit mining activities under additional requirements.</li> <li>According to <em>PP No. 38 Tahun 2011</em>, any land-use activity, including mining, is prohibited within riparian zones. However, special licenses may be issued to allow the redirection of river flows and riparian zones under certain conditions.</li> </ol> <p>based on these we will classify mining activity activity into three different complience category:</p> <ol> <li><strong>Category 1: High Compliance</strong> This is the highest compliance class. Mining areas in this category are located: <ul> <li>Within exploitation concession boundaries, and</li> <li>Outside any land-use-based environmental restriction areas.</li> </ul> </li> <li><strong>Category 2: Conditional Compliance</strong> Mining areas in this category are: <ul> <li>Within exploitation concession boundaries, but</li> <li>Located within production forests or riparian zones.</li> <li>If these mining activities have obtained the necessary additional permits to operate in production forests and/or redirect rivers, their compliance status aligns with Category 1.</li> </ul> </li> <li><strong>Category 3: Low Compliance</strong> This is the least compliance class in this analysis. The mining area are This is the least compliant category. Mining areas in this class are either: <ul> <li>Located within exploitation concession boundaries but also in protected forests or conservation areas, where mining is strictly prohibited, or</li> <li>Situated outside any concession boundaries, regardless of other restrictions.</li> </ul> </li> </ol> <p>The chart below visualize the categorization of the mining areas:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_classification_diagram-480.webp 480w,/assets/img/post_5_classification_diagram-800.webp 800w,/assets/img/post_5_classification_diagram-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_classification_diagram.gif" class="img-fluid rounded" width="100%" height="auto" alt="Diagram illustrating the classification of mining areas into three compliance categories: High Compliance, Conditional Compliance, and Low Compliance, based on the overlay of mining areas with concession boundaries and environmental restrictions." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Complience category based on overlay results </div> <p>The result can also be visualized on province basis using pie chart map as shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_category_pie_chart-480.webp 480w,/assets/img/post_5_category_pie_chart-800.webp 800w,/assets/img/post_5_category_pie_chart-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_category_pie_chart.png" class="img-fluid rounded" width="100%" height="auto" alt="Pie chart showing the percentage of mining areas within each compliance category across different provinces, providing a visual representation of compliance levels." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Pie chart showing the percentage area of each category for every province. </div> <h2 id="further-analysis">Further analysis</h2> <p>I also think it would be interesting to combine this dataset with detailed census data. For example, I attempted to combine it with the WorldPop gridded population dataset to estimate the number of people living within a 10 km buffer of mining areas. This helps identify the potential population directly impacted by mining activities. Further analysis of health, education, and income data for this population could be valuable for future research.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_pop-480.webp 480w,/assets/img/post_5_pop-800.webp 800w,/assets/img/post_5_pop-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_pop.png" class="img-fluid rounded" width="100%" height="auto" alt="Map showing the total population living within a 10 km buffer zone around mining areas, using the WorldPop gridded population dataset to assess potential impacts on local communities. " onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. Total population living within 10 km buffer of mining areas </div> <h2 id="conclussion">Conclussion</h2> <p>Satellite imagery provides extensive spatial and temporal coverage, making it a valuable tool for large-scale monitoring of terrestrial activities, including illegal mining. Using satellite data alone, we can extract information such as mining boundaries over time, mining methods, commodities, and environmental impacts. In our small-scale test, we demonstrated how deep learning can automate the mining boundary delineation process with good accuracy. To assess the compliance status of mining activities, additional geospatial data layers are required. In this example, we used unofficial mining concession boundaries and environmentally restricted area boundaries as an example. This simple yet effective approach enables high-scale monitoring to identify trends in mining activities and their compliance with regulations.</p>]]></content><author><name></name></author><category term="remote_sensing,"/><category term="monitoring,"/><category term="mining,"/><category term="security,"/><category term="data_science,"/><category term="machine_learning,"/><category term="deep_learning,"/><category term="multispectral,"/><category term="radar,"/><category term="GIS,"/><category term="environment"/><summary type="html"><![CDATA[Using satellite imagery to monitor illegal mining]]></summary></entry><entry><title type="html">Exploratory Data Analysis (EDA) for Hyperspectral Imagery</title><link href="https://nasirlukman.github.io/blog/2024/EDA/" rel="alternate" type="text/html" title="Exploratory Data Analysis (EDA) for Hyperspectral Imagery"/><published>2024-12-09T23:36:10+00:00</published><updated>2024-12-09T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/EDA</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/EDA/"><![CDATA[<p>One of the main characteristics of hyperspectral imagery is its high-dimensional data (i.e., a high number of spectral bands). This type of data, while providing a higher level of detail in the spectral characteristics of the material we observe, also raises challenges in handling the data effectively. Higher dimensional data means it becomes more challenging to extract meaningful information for analysis. These challenges are often referred to as <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">the curse of dimensionality</a>.</p> <p>In this post, I will show my approach in conducting exploratory data analysis (EDA) on a hyperspectral imagery with the goal of deriving meaningful geological information from the data. In this post, we will assume no geological prior knowledge of the region (although nowadays that is hardly the case, especially for Earth’s surface). We will rely solely on the hyperspectral data itself and some basic spectrometry and geology knowledge.</p> <p>We will use an airborne hyperspectral image covering the shortwave infrared range (SWIR) from ~2000 nm to ~2400 nm over an area of about 10 km² in an arid region. All of the analysis performed in this post is done using standard scientific libraries in the Python environment and an open-source software called <a href="http://hyppy.is-great.org/?i=1">Hyppy</a> developed at the University of Twente.</p> <h2 id="1-basic-visualization">1. Basic visualization</h2> <p>The obvious first step in EDA of hyperspectral imagery is to visualize the image. We can choose to visualize the image in grayscale for selected wavelength bands of interest and create false color composites to observe the main structural characteristics of the region.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_composite-480.webp 480w,/assets/img/post_4_composite-800.webp 800w,/assets/img/post_4_composite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_composite.png" class="img-fluid rounded" width="100%" height="auto" alt="False color composite image of an arid terrain generated using three SWIR bands (Red: 2088 nm, Green: 2199 nm, Blue: 2328 nm). The image highlights geological features such as lineaments and varying lithologies. The composite enhances mineralogical and structural differences, useful for initial remote sensing interpretation." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. False color composite image (R: 2088 nm; G: 2199 nm; B: 2328 nm) </div> <p>My initial interpretation of the region is that it is most likely mainly composed of sedimentary bedding influenced by a fault with apparent left-lateral movement, based on the drag fold formed along the fault lines.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_basic_interpretation-480.webp 480w,/assets/img/post_4_basic_interpretation-800.webp 800w,/assets/img/post_4_basic_interpretation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_basic_interpretation.png" class="img-fluid rounded" width="100%" height="auto" alt="Image of annotated version of the false color composite showing interpreted geological features. Sedimentary bedding patterns are outlined, and a major left-lateral fault is identified with drag folds on both sides, suggesting tectonic deformation. Overlaid labels or arrows highlight bedding orientations and fault trace." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Basic geological feature initial interpretation from the image </div> <p>When it comes to mineralogical/geological interpretations, I find it helpful to begin with a very broad interpretation. Knowing that the region is likely predominantly composed of sedimentary rocks already provides significant constraints for further interpretation, which may be very useful in the next phase. We may revisit this interpretation later if further analysis or data does not support it.</p> <h2 id="2-getting-to-know-the-data">2. Getting to know the data</h2> <p>It is very important to familiarize ourselves with the data we are working with. At this stage, I typically inspect the spectra of some pixels that stand out in the visualization and get a sense of the variation in spectral responses present in the image. For this, I often use specialized software such as <a href="https://www.nv5geospatialsoftware.com/Products/ENVI">ENVI</a>, <a href="https://plugins.qgis.org/plugins/temporalprofiletool/">QGIS with Spectral Profile Plugin</a>, or <a href="http://hyppy.is-great.org/?i=1">Hyppy</a>. The later two is an open source program which are available for free.</p> <p>At this stage, we can also plot a histogram of the mean reflectance values of the image to see how many visible clusters are present across the spectral bands. Note that the reflectance value are in the sacale of 10,000.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_mean_histogram-480.webp 480w,/assets/img/post_4_mean_histogram-800.webp 800w,/assets/img/post_4_mean_histogram-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_mean_histogram.png" class="img-fluid rounded" width="100%" height="auto" alt="Image of histogram displaying the mean reflectance value of each pixel in the hyperspectral image. The horizontal axis shows reflectance (in scale of 10,000), and the vertical axis shows frequency of occurrence. Two distinct peaks indicate two main pixel groups, corresponding to low- and high-albedo surface materials." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Histogram of mean albedo of each pixel in the image showing two main albedo class. </div> <p>From the histogram, we can decide on a threshold to classify our pixels based on their average albedo. This is generally equivalent to classifying the image into bright-colored minerals and dark-colored minerals (albeit in the shortwave infrared range, not in the visible range). Typically, low-albedo minerals in SWIR also appear dark in visible light. Our first classification results are shown below which shows the most basic classification of the image we have: reflective vs absortive minerals.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_albedo_class-480.webp 480w,/assets/img/post_4_albedo_class-800.webp 800w,/assets/img/post_4_albedo_class-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_albedo_class.png" class="img-fluid rounded" width="100%" height="auto" alt="This image shows binary classification map derived from average reflectance values in the SWIR range. Pixels are classified into two groups: high-albedo (bright minerals) and low-albedo (dark minerals), each shown in contrasting colors across the terrain. This reflects basic spectral segmentation for further analysis." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Map showing the distribution of two albedo class. </div> <h2 id="3-pca-and-k-means-clustering">3. PCA and K-Means Clustering</h2> <p>Since the number of pixels and spectral bands is often too high to handle for meaningful interpretation, dimensional reduction and data clustering methods can be useful for grouping data into clusters of spectra based on their spectral similarity which can make further analysis to be easier. While we can directly apply K-Means clustering to the data, this is not usually recommended. Each dimension of our data carries varying levels of information and noise. For high-dimensional data, only a few dimensions typically contain significant information, while others only add noise to the algorithm.</p> <p>PCA is a dimensionality reduction method that organizes data based on its variability in the data space, corresponding to its information content. It identifies the directions (principal components) where the data varies the most and projects the data onto these axes in descending order of variance. The downside is that the data is transformed into an orthogonal space where the units lose their original physical meaning. In this example, we visualize the first 10 principal components and observe that by the 10th component, there is minimal discriminatory power. Therefore, we reduce the dimensionality from 55 to 10 principal components, preserving the most significant information, and use this result as the input for K-Means clustering.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_PCA-480.webp 480w,/assets/img/post_4_PCA-800.webp 800w,/assets/img/post_4_PCA-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_PCA.png" class="img-fluid rounded" width="100%" height="auto" alt="Image of the grid layout showing the first 10 principal component images extracted from the hyperspectral dataset. Each panel represents a PC image where pixel intensity corresponds to the spectral variance captured in that component. The first few PCs show significant structure and contrast, while later PCs appear increasingly noisy and less informative." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. First 10 PCA images. </div> <p>The K-Means algorithm clusters data points based on their similarities. It assigns each point to one of K clusters based on its proximity to the cluster centroids, iterating to minimize variance within clusters. Similarities are computed using Euclidean distance, which I explained in a <a href="https://nasirlukman.github.io/blog/2024/distance/">previous post</a>.</p> <p>K-Means requires the user to define the number of clusters (\(K\) ). The elbow method can help determine this, by plotting the within-cluster sum of squares (WCSS) for various K values. The optimal number of clusters is where the WCSS curve starts to saturate, resembling an elbow. For this dataset, the optimal number of clusters is 3, as shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_WCSS-480.webp 480w,/assets/img/post_4_WCSS-800.webp 800w,/assets/img/post_4_WCSS-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_WCSS.png" class="img-fluid rounded" width="100%" height="auto" alt="Image of the line plot showing the elbow method applied to determine the optimal number of clusters for K-Means. The x-axis shows the number of clusters (K) from 1 to 11, and the y-axis shows the within-cluster sum of squares (WCSS). A noticeable bend at K=3 indicates the optimal number of clusters for this dataset." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. WCSS result for cluster values ranging from 1 to 11. </div> <p>Using \(K=3\) , we perform clustering, with the results shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_cluster_map-480.webp 480w,/assets/img/post_4_cluster_map-800.webp 800w,/assets/img/post_4_cluster_map-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_cluster_map.png" class="img-fluid rounded" width="100%" height="auto" alt="Map displaying K-Means clustering results on PCA-reduced hyperspectral data. Each pixel is colored according to its assigned spectral cluster (total of 3). The resulting clusters reflect differences in mineralogical composition or surface properties inferred from spectral similarities." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. K-Mean clustering result from the first 10 principle component of our hyperspectral images. </div> <p>We then can transform the pixels back from PCA space to the original data space to examine the average mean spectra of each cluster:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_cluster_spectra-480.webp 480w,/assets/img/post_4_cluster_spectra-800.webp 800w,/assets/img/post_4_cluster_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_cluster_spectra.png" class="img-fluid rounded" width="100%" height="auto" alt="Line graph showing average reflectance spectra for each of the three K-Means clusters. The x-axis represents wavelength in nanometers (2000–2400 nm), and the y-axis shows normalized reflectance values. The curves reveal distinct spectral features among the clusters, helping to distinguish different material types present in the area." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. Average spectra of each cluster. </div> <p>Compared to our initial simple classification by mean albedo, this approach offers more nuance. For instance, the high-albedo reflectance now separates into two distinct spectral shapes, while the low-albedo minerals remain a single cluster. To further refine the low-albedo cluster, we could mask the high-albedo pixels and repeat the process. However, for this example, I am satisfied with these results. At this stage, I observe that the low-albedo cluster has largely featureless spectra (likely consisting of minerals without distinct features in the SWIR range), making further attempt for meaningful subdivision challenging.</p> <h2 id="4-endmember-extraction-and-linear-spectreal-unmixing">4. Endmember Extraction and Linear Spectreal Unmixing</h2> <p>Since our average spectra likely represent complex mixtures, it is useful to extract their possible pure spectral shapes. At this stage, we have decided to categorize our image into three distinct classes. We will use the <a href="">N-FINDR</a> algorithm with \(n=3\) to extract the three purest endmembers from our image. The data distribution in 2D PCA space and the extracted endmember pixels are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_nfindr_plot-480.webp 480w,/assets/img/post_4_nfindr_plot-800.webp 800w,/assets/img/post_4_nfindr_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_nfindr_plot.png" class="img-fluid rounded" width="100%" height="auto" alt="2D PCA scatter plot showing a triangular distribution of hyperspectral data with three red stars at the vertices, indicating the locations of the purest endmember pixels." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 9. Data shape in reduced 2 PCA dimension showing clear linear relationship between three endmembers. Red star is the vertex of the triangle which corespond to the purest pixel on the image. </div> <p>This is an excellent 2D PCA representation. The 2D simplex (triangle) is almost perfectly formed, indicating that our entire dataset can be described as a linear combination of three endmember spectra. These endmembers therefore must be the pixel that correspond to the vertices of the triangle. After transforming the extracted endmembers back into the original data space, we observe their pure spectral signatures:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_endmember_spectra-480.webp 480w,/assets/img/post_4_endmember_spectra-800.webp 800w,/assets/img/post_4_endmember_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_endmember_spectra.png" class="img-fluid rounded" width="100%" height="auto" alt="Line graph showing the spectral signatures of three extracted endmembers across the SWIR wavelength range, each representing distinct mineral groups (mica, quartz, and carbonates)." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 10. Spectra of the purest pixels (endmembers). </div> <p>This is a good point to start naming our classes properly. You could match the spectra to a spectral library using a feature-matching algorithm to identify the mineral spectra most similar to the extracted endmembers. For simplicity, I use broad categorizations. I define the first spectrum as the <strong>Low-Albedo Mineral Group,</strong> likely dominated by plagioclase or mafic minerals, interpreted as part of a volcanic rock complex. The second spectrum corresponds to the <strong>Hydroxyl Mineral Group</strong>, based on its \(AlOH\) feature around 2200 nm, likely related to the occurance of white micas or clays, interpreted as part of siliciclastic rocks such as arkose. The third spectrum represents the <strong>Carbonate Mineral Group</strong>, with a \(CO_3\) feature near 2300 nm, likely from calcareous sedimentary rocks like limestone or calcareous sandstone/siltstone.</p> <p>With our pure endmembers identified, we can perform linear spectral unmixing to estimate their relative abundances. At this stage of analysis, I prefer to not constrain the unmixing result to be strictly sum-to-one since there are still many unknowns. These abundance results are interpreted as <em>unconstrained abundances</em>, distinct from <em>absolute abundances</em>, which have more physical meaning. Below are the unconstrained abundance maps for each endmember:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_unmixing_result-480.webp 480w,/assets/img/post_4_unmixing_result-800.webp 800w,/assets/img/post_4_unmixing_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_unmixing_result.png" class="img-fluid rounded" width="100%" height="auto" alt="Three grayscale maps showing the unconstrained abundance distributions of each endmember across the study area, one map per endmember." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 11. Unconstrained abundance of the three endmembers. </div> <p>Since we are dealing with only three mineral groups, we can assign each abundance to an RGB channel to produce a ternary representation of the unconstrained abundances:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_unmixing_result_ternary_with_legend-480.webp 480w,/assets/img/post_4_unmixing_result_ternary_with_legend-800.webp 800w,/assets/img/post_4_unmixing_result_ternary_with_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_unmixing_result_ternary_with_legend.png" class="img-fluid rounded" width="100%" height="auto" alt="Ternary abundance map combining the three endmembers into RGB channels, with a color legend showing how color blends represent relative mineral mixtures." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 12. Ternary map of the unconstrained abundance of the three endmembers. </div> <p>It is important to note that this ternary representation is purely for visualization and does not strictly correspond to the absolute abundance of each endmember.</p> <h2 id="5-minimum-wavelength-mapping">5. Minimum Wavelength Mapping</h2> <p>Many distinct hyroxyl and carboante minerals can be distinguished based on the subtle difference in the wavelength position of their deepest absorption feature. Using a method called minimum wavelength mapping, we can detect these subtle shifts and potentially refine our classification to include specific members of the carbonate and hydroxyl mineral groups. The first step is to detect the wavelength of the deepest absorption feature across the entire spectral range.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_minwav-480.webp 480w,/assets/img/post_4_minwav-800.webp 800w,/assets/img/post_4_minwav-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_minwav.png" class="img-fluid rounded" width="100%" height="auto" alt="Histogram displaying the distribution of minimum absorption wavelengths across the full spectral range, highlighting multiple peaks for AlOH and CO₃ features." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 13. Minimum wavelength position histogram for the whole spectral range. </div> <p>We observe at least three distinct distributions of \(AlOH\) absorption features and five distributions of \(CO_3\) absorption features. For the \(AlOH\) group, the lowest feature observed at 2195 nm likely corresponds to lithium-rich white mica, such as lepidolite. The other two \(AlOH\) features, around 2210 nm and 2220 nm, likely correspond to \(Al\)-rich white mica, such as muscovite, with minor geochemical differences attributed to variations of geochemistry and temperature of the mineral formation.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_AlOH_minwav_legend-480.webp 480w,/assets/img/post_4_AlOH_minwav_legend-800.webp 800w,/assets/img/post_4_AlOH_minwav_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_AlOH_minwav_legend.png" class="img-fluid rounded" width="100%" height="auto" alt="Spatial map of minimum wavelength positions for AlOH absorption features, color-coded to distinguish at least three hydroxyl-bearing mineral subgroups." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 14. Minimum wavelength map of hydroxile features. </div> <p>For the \(CO_3\) group, there is significant variation in the deepest feature wavelengths. Although identifying specific minerals at this stage is challenging, the observed ranges suggest these features are unlikely to correspond to calcite, the most common carbonate mineral. For instance, features around 2335 nm are commonly associated with siderite, 2320 nm with dolomite, and 2305 nm with magnesite.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_CO3_minwav_legend-480.webp 480w,/assets/img/post_4_CO3_minwav_legend-800.webp 800w,/assets/img/post_4_CO3_minwav_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_CO3_minwav_legend.png" class="img-fluid rounded" width="100%" height="auto" alt="Spatial map of minimum wavelength positions for CO₃ absorption features, with color coding representing possible variations in carbonate mineral types." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 15. Minimum wavelength map of carbonate features. </div> <p>It is essential to note that pinpointing specific minerals requires further analysis. While we cannot yet confirm the mineral species, the variations in these wavelength ranges are likely related to mineralogical differences. Therefore, the spatial distribution of these distinct groups remains valid, even when we are still uncertain with the definitive mineral identifications.</p> <h2 id="6-further-comments">6. Further comments</h2> <p>In this post, I demonstrated some typical EDA steps for hyperspectral analysis for geological investigations in an unfamiliar region. These EDA steps serve to familiarize us with the data and provide a solid foundation for further investigation.</p> <p>Here we see that SWIR hyperspectral data alone can reveal a wealth of information, even without incorporating additional datasets, prior knowledge of the region, or advanced analysis techniques. However, complementary datasets, such as VNIR and LWIR spectral data, could significantly enhance geological and mineralogical interpretation of the region. Additionally, methods beyond infrared spectrometry, such as gamma-ray spectrometry, offer valuable tools for geological mapping.</p> <p>In practice, prior knowledge of the study area—such as geological maps or models—is often available and can effectively guide the analysis. More importantly, incorporating fieldwork data, even from sparse sampling points, is crucial for validating and refining the results.</p>]]></content><author><name></name></author><category term="spectral_geology,"/><category term="mineral,"/><category term="data_science,"/><category term="geology,"/><category term="hyperspectral,"/><category term="remote_sensing"/><summary type="html"><![CDATA[My typical approach on EDA for a new hyperspectral projects for geological investigations. Includes method such as PCA, K-Means, N-FINDR, Linear Spectral Unmixing, and Minimum Wavelength Mapping.]]></summary></entry><entry><title type="html">Endmember Extraction from Hyperspectral Imagery Using N-FINDR</title><link href="https://nasirlukman.github.io/blog/2024/nfindr/" rel="alternate" type="text/html" title="Endmember Extraction from Hyperspectral Imagery Using N-FINDR"/><published>2024-11-27T23:36:10+00:00</published><updated>2024-11-27T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/nfindr</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/nfindr/"><![CDATA[<p>Hyperspectral imagery often contains mixed pixels—pixels that represent areas with more than one class of interest. Given the complexity of the scenes, and the rigid structure of images, it is unrealistic to assume every pixel to correspond to a single class. These classes could include features like water, trees, shrubs, grass, soil, or roads when performing land cover classification using satellite or airborne imagery. In earth science, the class of interest often is minerals that forms rocks. In any way, trying to find the purest pixels , or <em>endmembers</em>, of each class in our image is something that often useful for further analysis.</p> <p>In this post, I’ll provide a brief overview of one endmember extraction algorithm reffered to as <em>N-FINDR</em>. But, before diving into the details of the algorithm, it is important to acknowledge the general limitations of endmember extraction algorithms:</p> <ol> <li><strong>Purity is not guaranteed</strong>: These algorithms don’t guarantee that the extracted spectra represent a pure spectra of specific class of interest. Instead, they identify the purest spectra present in the image.</li> <li><strong>Known number of endmembers</strong>: The number of endmembers in the image must be known beforehand. This can be estimated using domain expertise, auxiliary measurements, other algorithms, or trial and error.</li> <li><strong>Linear mixture model assumption</strong>: Most endmember extraction algorithms, including N-FINDR, assume a linear mixture model.</li> </ol> <h2 id="how-n-findr-works">How N-FINDR Works</h2> <p>The core idea of N-FINDR is simple yet clever: it identifies the vertices of the simplex formed by the data distribution in reduced dimensions. These vertices are the purest spectra present in the dataset. The general steps of the algorithm is as follows:</p> <ol> <li><strong>Reprojection</strong>: Reproject all pixels into a lower-dimensional space using an orthogonal transformation like Principle Component Analysis (PCA) or Minimum Noise Fraction (MNF). MNF is often preferred because it minimizes the influence of noise.</li> <li><strong>Dimensionality reduction</strong>: Reduce the dimensionality to the first \((n−1)\) components, where \(n\) is the number of endmembers. At this stage, the data points should lie inside an \((n-1)\) dimensional simplex.</li> <li><strong>Iterative vertex selection</strong>: <ul> <li>Randomly select \(n\) points and calculate the simplex’s volume (or area in 2D).</li> <li>Iteratively replace one vertex with another pixel. If the new simplex’s volume is larger, accept the replacement. Otherwise, reject it and try again.</li> </ul> </li> <li><strong>Termination</strong>: After a fixed number of iterations without improvement, the algorithm terminates, and the final set of pixels is taken as the endmembers.</li> <li><strong>Reprojection back</strong>: Reproject the selected pixels into the original dimensional space to obtain the endmember spectra.</li> </ol> <h2 id="synthetic-data-example">Synthetic Data Example</h2> <p>To illustrate, let’s consider an idealized case of 1,000 synthetic mixed pixels generated from three endmembers. Since we’re dealing with three endmembers, we reproject the data into its first two principal components. In this reduced space, the data points lie perfectly on a 2D simplex—a triangle as shown in the image below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_synthetic_mixture_MNF-480.webp 480w,/assets/img/post_3_synthetic_mixture_MNF-800.webp 800w,/assets/img/post_3_synthetic_mixture_MNF-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_synthetic_mixture_MNF.png" class="img-fluid rounded" width="100%" height="auto" alt="THis image shows principal component analysis (PCA) of a synthetic mixture of three endmembers, where the data points form a 2D simplex, represented as a triangle." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. First two principal components of the synthetic mixture of three endmembers </div> <p>If each data point is a linear mixture of three pure endmembers, the endmembers will be located at the vertices of a triangular region, commonly referred to as a simplex. In this 2D example, identifying the simplex is relatively straightforward through visual inspection. However, as the number of endmembers increases, the dimensionality of the principal component representation also grows, making it increasingly difficult to determine the simplex visually. To overcome this challenge, we employ an iterative simplex-finding algorithm, which can be generalized to handle higher-dimensional data. The animation below illustrates the iterative process of refining the simplex:</p> <div style="display: flex; justify-content: center;"> <img src="/assets/img/post_3_nfindr_iterative.gif" alt="Animation illustrating the iterative process of the N-FINDR algorithm, refining the simplex to identify the purest endmember spectra in the data."/> </div> <div class="caption"> Image 2. Ilustration of NFINDR algorithm in action </div> <h2 id="real-data-example">Real Data Example</h2> <p>In real-world scenarios, hyperspectral data is rarely as ideal as synthetic examples. Complex noise, non-linearities, and other factors often result in an imperfectly formed simplex. Nevertheless, algorithms like N-FINDR can still provide valuable output.</p> <p>For this example, we examine laboratory-acquired hyperspectral imagery of a sandstone sample. Below is a false-color composite image of the sample:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_rock_image-480.webp 480w,/assets/img/post_3_rock_image-800.webp 800w,/assets/img/post_3_rock_image-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_rock_image.png" class="img-fluid rounded" width="100%" height="auto" alt="This image shows false-color composite hyperspectral image of a sandstone rock sample, illustrating the varied mineral composition of the sample." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. False color composite hyperspectral iamge of a sandstone sample </div> <p>A quick inspection of the rock suggests that it is predominantly composed of three minerals. Thus, we assign \(n=3\) for this analysis. The results of the MNF transformation and the selected simplex vertices by N-FINDR are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_real_mixture_MNF-480.webp 480w,/assets/img/post_3_real_mixture_MNF-800.webp 800w,/assets/img/post_3_real_mixture_MNF-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_real_mixture_MNF.png" class="img-fluid rounded" width="100%" height="auto" alt="Image of the first two principal components (MNF) of the sandstone rock sample, showing the identified simplex vertices (purest spectra) marked in red by the N-FINDR algorithm." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. First two principal components of the sandstone rock sample. The red do represent the selected purest spectra by N-FINDR algorithm. </div> <p>Notice that the simplex is not perfectly formed, and the triangular structure appears slightly distorted. This suggests minor non-linear behavior in the actual mixtures. Additionally, some outliers lie outside the simplex, possibly influenced by accessory minerals. Such minerals, often present in small amounts, are common in natural rock samples and can affect the spectra of certain pixels. These influences may not be fully captured in a 2D representation.</p> <p>We can examine the spectra of the selected purest pixels by transforming them back to their original dimensions. Below are the resulting spectra for the three identified endmembers:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_pure_endmember_result-480.webp 480w,/assets/img/post_3_pure_endmember_result-800.webp 800w,/assets/img/post_3_pure_endmember_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_pure_endmember_result.png" class="img-fluid rounded" width="100%" height="auto" alt="Image of spectra of the three identified endmembers from the N-FINDR algorithm, showing distinct absorption features related to minerals such as white mica/clay, carbonate, and quartz." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Resulting spectra of the three endmember from N-FINDR algorithm </div> <p>If you know your mineralogy and infrared spectroscopy you can immedietly recognize these minerals. The red spectra have a strong absorption feature in ~2200 nm region which related the \(Al-OH\) bonds of white mica/clay mienrals. The blue spectra have an absroption feature in ~2330 nm region related to \(CO_3\) bonds of carbonate minerals. The green and bright spectra represent quartz mineral. we still can see a very weak feature in ~2200 nm sugest that it is not 100% pure spectra and there is still a small influence of clay minerals.</p> <p>While these spectra are not perfectly pure, they are sufficiently representative to be useful for further analysis. For instance, as shown in our <a href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/">previous post</a>, we used these endmember spectra for spectral unmixing and achieved excellent results, with an RMSE of only 0.0186.</p> <p>To understand the spatial context, we can reshape the extracted data back into its original image structure to visualize the locations of the purest pixels:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_rock_image_with_pure_pixel-480.webp 480w,/assets/img/post_3_rock_image_with_pure_pixel-800.webp 800w,/assets/img/post_3_rock_image_with_pure_pixel-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_rock_image_with_pure_pixel.png" class="img-fluid rounded" width="100%" height="auto" alt="Image of false-color composite hyperspectral image of a sandstone sample, with the locations of the purest pixels identified by the N-FINDR algorithm marked in the image." onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. False color composite hyperspectral image of a sandstone sample along with its purest pixel location. </div> <p>This example shows that N-FINDR is a powerful and intuitive algorithm for endmember extraction. Despite its limitations, such as the need for prior knowledge of the number of endmembers and the assumption of a linear mixture model, it often still provides a usefull results.</p>]]></content><author><name></name></author><category term="spectral_geology,"/><category term="mineral,"/><category term="data_science,"/><category term="geology,"/><category term="hyperspectral,"/><category term="core_scanning"/><summary type="html"><![CDATA[A brief overview, ilustration and case example of N-FINDR algorithm to extract mineral endmembers in hyperspectral imagery.]]></summary></entry></feed>