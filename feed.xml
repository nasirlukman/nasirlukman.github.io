<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://nasirlukman.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nasirlukman.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-04T03:35:07+00:00</updated><id>https://nasirlukman.github.io/feed.xml</id><title type="html">Earth.etc</title><subtitle></subtitle><entry><title type="html">Multi Sensor Object Based Image Classification for Land Use/Land Cover Analysis</title><link href="https://nasirlukman.github.io/blog/2025/OBIA-LULC/" rel="alternate" type="text/html" title="Multi Sensor Object Based Image Classification for Land Use/Land Cover Analysis"/><published>2025-04-08T23:36:10+00:00</published><updated>2025-04-08T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/OBIA-LULC</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/OBIA-LULC/"><![CDATA[<p>In this post, I will share a Land Use Land Cover (LULC) project I did combining multiple sensors. To tackle the common problem of the salt and pepper effect in pixel-based image classification, an object-based approach was chosen for this task. The steps generally involved stacking images from multiple sensors, performing image segmentation using SNIC, taking the mean value of each band from each segment, and running supervised classification using Random Forest.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_classification%20steps-480.webp 480w,/assets/img/post_9_classification%20steps-800.webp 800w,/assets/img/post_9_classification%20steps-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_classification%20steps.gif" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Classification steps. </div> <h2 id="methods">Methods</h2> <p>The land cover classes consist of categories such as forest, shrubs, mangroves, bare land, built-up areas, water, and plantations. Optical and radar images are known to have effective discriminating ability among those classes, which is why we used Landsat-8 and Sentinel-1 sensors. The VIIRS night-time light sensor captures light emissions on the Earth’s surface, which is useful to detect built-up areas. At this stage, we also included elevation data from SRTM, since it was available.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_raw_data-480.webp 480w,/assets/img/post_9_raw_data-800.webp 800w,/assets/img/post_9_raw_data-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_raw_data.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Raw satellites images input. </div> <p>The next step was to extract additional features from the raw data. From the Landsat image, we calculated several spectral indices to highlight different features of the land surface. We also calculated GLCM features to extract textural information. Additionally, we computed band ratios from Sentinel-1 imagery, and we calculated slope from the SRTM elevation data. In total, 27 bands were obtained and prepared as inputs for the classification.</p> <p>Not all of those bands are useful for the classification purpose, so the next step was feature selection to pick only the most important bands for the final classification. Permutation importance was used for this, which also considers simple correlation between bands. Eight bands were selected for the final classification:</p> <ol> <li>Modified Normalized Difference Water Index (MNDWI)</li> <li>VV/VH Sentinel 1 Ratio</li> <li>GLCM Textural Contrast</li> <li>Normalized Difference Vegetation Index (NDVI)</li> <li>VIIRS Night Light Radiance</li> <li>Landsat Band 1</li> <li>Build up Index (BI)</li> </ol> <h2 id="results-and-insight">Results and Insight</h2> <p>The final result is an annual LULC map of the area. Overall accuracy is around 96%, with most of the errors coming from false positives in palm oil plantations. The palm oil plantations in this region are quite heterogeneous in which some areas are densely planted, while others are more spacious. The more spacious ones often appear similar to shrubs or low canopy forests, which causes confusion.</p> <p>The model can then be generalized to different timestamps with roughly the same accuracy (94–96%).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_results_3_year-480.webp 480w,/assets/img/post_9_results_3_year-800.webp 800w,/assets/img/post_9_results_3_year-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_results_3_year.gif" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Classification Results </div> <p>If we look at the results from 2017 to 2024, we can see some interesting trends:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_LULC_graph-480.webp 480w,/assets/img/post_9_LULC_graph-800.webp 800w,/assets/img/post_9_LULC_graph-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_LULC_graph.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Time series graph of few LULC class </div> <p>First, there’s a sharp decline in high-density forest from 2017 to 2019, which then stabilizes. We can also see a slow and steady decline in mangroves. Interestingly, for both of these classes, the land cover changes aren’t shifting toward human-made landscapes like built-up areas, plantations, or even bare land. Most of the changes are into shrubs. This might be related to more indirect effects of human activity on the environment rather than direct conversion.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_LULC_mangrove-480.webp 480w,/assets/img/post_9_LULC_mangrove-800.webp 800w,/assets/img/post_9_LULC_mangrove-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_LULC_mangrove.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. LULC change showing slow decrease of mangrove cover from 2017 to 2024. </div> <p>Second, there’s a quite remarkable increase in low canopy forest. Most of the low canopy forest areas appear to have changed from shrubs. The most significant increase happened between 2019 and 2024, which is the same period when the decline of high canopy forest slowed down or stopped. Both of these phenomena are likely the result of conservation and restoration efforts that are currently ongoing in the region.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_LULC_forest-480.webp 480w,/assets/img/post_9_LULC_forest-800.webp 800w,/assets/img/post_9_LULC_forest-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_LULC_forest.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. LULC change showing increase of low canopy forest cover from 2017 to 2024. </div> <p>The final thing that stands out is the slow and steady increase in built-up areas. Most of the new built-up areas seem related to local community settlements in small towns or villages near riverbanks, and some appear to be plantation housing and factory sites.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_9_LULC_buildup-480.webp 480w,/assets/img/post_9_LULC_buildup-800.webp 800w,/assets/img/post_9_LULC_buildup-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_9_LULC_buildup.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. LULC change showing slow increase of build up area from 2017 to 2024. </div> <hr/> <p>This project shows how combining different sensors and using an object-based approach can produce accurate and insightful land cover maps. Beyond just the numbers, the patterns we see from year to year tell a deeper story about environmental change, pressure from human activity, and efforts to restore and protect our landscapes.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Combinining Landsat-8, Sentinel-1, VIIRS NTL, and SRTM for object based image classification using SNIC and Random Forest]]></summary></entry><entry><title type="html">Spatio-Temporal Analysis of Industrial and Artisinal Offshore Tin Mining Vessel</title><link href="https://nasirlukman.github.io/blog/2025/mining-vessel/" rel="alternate" type="text/html" title="Spatio-Temporal Analysis of Industrial and Artisinal Offshore Tin Mining Vessel"/><published>2025-04-04T23:36:10+00:00</published><updated>2025-04-04T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/mining-vessel</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/mining-vessel/"><![CDATA[<p>Most of the tin sold on the international market comes from a small island in Indonesia called Bangka. What’s less known is that a significant amount of that tin is mined offshore. There are two types of vessels commonly involved in this activity. Large dredger vessels, typically 50 to 120 meters in length, are operated by formal mining companies at industrial scale. At the same time, there are smaller artisanal boats—usually no more than 10 meters long—using simple suction pumps handled by divers and connected to traditional sluice boxes onboard. The later are typically related with illegal mining activities.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_vessel_example-480.webp 480w,/assets/img/post_8_vessel_example-800.webp 800w,/assets/img/post_8_vessel_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_vessel_example.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Two types of offshore mining vessels. </div> <h2 id="ship-detection-and-classification">Ship Detection and Classification</h2> <p>To better understand how offshore mining activity changes over time, I’ve been developing a ship detection algorithm tailored to this region. I use Sentinel-1 SAR data, which is particularly suitable for this task. Not only can it see through the frequent cloud cover over the shores of Bangka, but it also does a good job of capturing the contrast between open water and floating objects—even relatively small ones.</p> <p>For this study, I focused on the eastern part of Bangka Island.</p> <p>Before doing any detection, I needed a good quality ‘ground truth’ data. In this case that meant finding scenes where Sentinel-1 and Sentinel-2 images—or ideally very high-resolution optical images—were available on the same date. This allows for visual confirmation of vessel types and ensures that the training data is as accurate as possible.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_small_vessel_example-480.webp 480w,/assets/img/post_8_small_vessel_example-800.webp 800w,/assets/img/post_8_small_vessel_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_small_vessel_example.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Worldview, Sentinel-2, and Sentinel-1 imagery taken at the same spot with only few hours apart showing small/artisinal mining vessel. </div> <p>After collecting a good number of examples, I started looking into how the SAR sensor responds to the different types of vessels. It turns out that their radar signatures are quite distinct, especially when you compare the VV and VH polarizations of Sentinel-1.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_training_data_distribution-480.webp 480w,/assets/img/post_8_training_data_distribution-800.webp 800w,/assets/img/post_8_training_data_distribution-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_training_data_distribution.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Sentinel-1 sensor responses of the large and small vessels. </div> <p>The differences in backscatter likely relate to both the size of the vessels and the materials they’re made of. while large mining vessel are made out of metals, the smaller artisinal mining vessel are made out of wood.</p> <p>For classification, I used an object-based approach. First, I segmented the image, and then applied a support vector machine (SVM) to classify the segmented objects. The training result was promising: a validation accuracy of about 98%.</p> <h2 id="results-and-analysis">Results and Analysis</h2> <p>I deployed the trained model across a time series of Sentinel-1 imagery, covering the period from early 2017 to early 2025. The result is a spatial and temporal map of detected vessels.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_result_stacked-480.webp 480w,/assets/img/post_8_result_stacked-800.webp 800w,/assets/img/post_8_result_stacked-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_result_stacked.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Object based classification result example. </div> <p>To make sense of these results, I created a time series map animatioin showing the density of both large and small vessels over time.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_vessel_density_timelapse-480.webp 480w,/assets/img/post_8_vessel_density_timelapse-800.webp 800w,/assets/img/post_8_vessel_density_timelapse-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_vessel_density_timelapse.gif" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Timseries animation of the large and small vessels density. </div> <p>And add a plot to tracks the number of vessels by type at each timestamp.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_timeseries_plot-480.webp 480w,/assets/img/post_8_timeseries_plot-800.webp 800w,/assets/img/post_8_timeseries_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_timeseries_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Timeserise plot of ship counts for each class. </div> <p>Since it is quite difficult to extract meaningful infomration from this plot alone, I used seasonal decomposition to separate long-term trends from seasonal cycles.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_seasonal_decomposition-480.webp 480w,/assets/img/post_8_seasonal_decomposition-800.webp 800w,/assets/img/post_8_seasonal_decomposition-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_seasonal_decomposition.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Seasonal decomposition of the timeseris result </div> <p>Both vessel types show the same general long term trends, and both have a sharp drop in activity around late 2020—most likely a result of the COVID-19 outbreak. The seasonal patterns are also quite interesting. Smaller vessels tend to be most active between January and March, with a noticeable peak in January. Larger vessels, on the other hand, see more activity in March to May and again in October and November.</p> <h2 id="notes-and-consideration">Notes and Consideration</h2> <p>Since this is a mining area, most of the ships present are a mining vessel. However, other ship types are present as well, i.e. cargo ships and fishing boats. Cargo vessels tend to be large and metal-bodied, which makes them look similar to large mining dredgers in SAR imagery. On the other hand, traditional fishing boats are smaller and usually built from wood, making them potential look-alikes for artisanal mining vessels.</p> <p>Ideally, these look-alike vessels would be included in the training data to reduce false positives. However, collecting reliable ground truth for them is difficult—especially because identifying vessel types often relies on cloud-free optical imagery taken at the same time as the Sentinel-1 scenes. This overlap is rare, making it harder to build a well-labeled dataset and limiting the number of high-quality training samples available for the model.</p> <p>One interesting observation is that mining vessels often operate in clusters. This spatial pattern could be a useful cue for distinguishing them from other types of vessels—especially when radar backscatter alone isn’t enough.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_8_hot_spots-480.webp 480w,/assets/img/post_8_hot_spots-800.webp 800w,/assets/img/post_8_hot_spots-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_8_hot_spots.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. all ships detected in the study area. Green box highlight hot-spots for ships which is a typical pattern for mining vessels. </div> <h2 id="to-wrap-up">To Wrap Up</h2> <p>Offshore tin mining around Bangka is a complex activity, spanning from industrial-scale operations to small artisanal efforts. Continuous monitoring of these activities could helps bring transparency to an industry that often operates in remote and loosely regulated areas. Using freely available satellite data, especially Sentinel-1 SAR, offers a promising way to monitor these activities systematically over time. While there are still challenges such as distinguishing mining vessels from other ships or dealing with limited training data, the initial results shows a strong potential to reveal a meaningful patterns.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Object-based image classification of mining vessels using Sentinel-1 timeseries.]]></summary></entry><entry><title type="html">Sentinel 1 Change Detection for Forest Monitoring</title><link href="https://nasirlukman.github.io/blog/2025/sentinel1-change-detection/" rel="alternate" type="text/html" title="Sentinel 1 Change Detection for Forest Monitoring"/><published>2025-03-30T23:36:10+00:00</published><updated>2025-03-30T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/sentinel1-change-detection</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/sentinel1-change-detection/"><![CDATA[<p>Last week, I was trying to build a forest monitoring system using Sentinel-1 data. The idea of using radar data instead of optical data is that the climate of most tropical forest areas in the world is characterized by frequent and persistent rainfall, so the cloud cover tends to be high throughout the year. For example, the <a href="https://glad.earthengine.app/view/global-forest-change">Hansen deforestation dataset</a> is a very good-quality global deforestation dataset built using Landsat optical satellite data. The dataset is annual from 2000 to 2023 (last time I checked). I can imagine it would be very hard, and even impossible in some parts of the world, to build a monthly deforestation layer using the same approach due to cloud cover. Unlike optical sensor, radar signal have the ability to penetrate colud cover, making it a more reliable for monitoring in high cloud cover areas.</p> <p>The Sentinel-1 forest monitoring system I built is based on change detection at its core. It simply involves subtracting images from \(\mathbf{t_1}\) and \(\mathbf{t_2}\). However, due to the high noise of radar images and the different atmospheric conditions in \(\mathbf{t_1}\) and \(\mathbf{t_2}\), some care needs to be taken when pre-processing each image. That, and some additional image analysis tricks and magic!</p> <p>Generally, the steps are as follows:</p> <ol> <li> <p><em>Filtering Sentinel-1 Metadata</em>: We filter the metadata to only get images with identical orbital passes and numbers. Radar images are especially sensitive to viewing geometry, so we need to make sure that the viewing geometry of each image is as similar as possible.</p> </li> <li> <p><em>Speckle Filtering</em>: We use both spatial and temporal axes to do speckle filtering using a three-dimensional kernel.</p> </li> <li> <p><em>Additional Normalization and Time-Series Aggregation</em>: These steps help minimize changes that are not related to forest cover change.</p> </li> <li> <p><em>Forest Mask</em> (ideally): We also need to incorporate a forest mask to remove any changes that are not related to the forest (which I didn’t include this time).</p> </li> <li> <p><em>Change Detection</em>: Subtracting images in concecutive time periods and applying threshold value to filter out minor changes due to noises.</p> </li> </ol> <p>Below are examples of the results of this method compared to the Hansen layer for some forest areas in Borneo, which have been converted into palm oil plantations.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_7_result_comparison-480.webp 480w,/assets/img/post_7_result_comparison-800.webp 800w,/assets/img/post_7_result_comparison-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_7_result_comparison.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Result comparison between Hansen deforestation layer and Sentinel 1 change detection layer on the same area in Borneo. </div> <p>The main difference between the two results is the big patch of deforestation in the top-right layer, which was not recorded in the Hansen layer. The Hansen dataset I acquired from Earth Engine only goes up to 2023, and those deforestations are happening in 2024. The most important difference, of course, is the time frequency. My approach records monthly changes, so if we zoom into the top-left patch of the image as an example, we can see the detail of the deforestation progression throughout the months of the year. In this particular case, the palm oil plantation seems to expanded towards the north with pace of 50 Ha/month for a time period of 22 months from June 2018 until March 2020. This example shows the potential of using this type of monthly information to build an early warning system to monitor forest area throughout the globe.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_7_zoomed_in-480.webp 480w,/assets/img/post_7_zoomed_in-800.webp 800w,/assets/img/post_7_zoomed_in-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_7_zoomed_in.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Zoomed in result at the top-left deforested patch of the image. </div> <p>Another potential issue (or maybe a potential feature) of this approach is that, our measurement is essentially a proxy for forest canopy density change. This means it is not only sensitive to deforestation but also to disturbance. Unfortunately, without ground truth, it is difficult to make sure whether these patches are indeed related to actual disturbance events or an artifact of sensor noise. My best bet is that it is currently the combination of both. If we want to exclude these small changese patches we can adjust the threshold, and add aditional post-processing step such as majority kernel. It is very difficult to find an optimum threshold for a very large area (i.e. the whole planet) so some trade-off decision need to be made.</p> <p>Note: There are similar datasets that also use Sentinel-1 to monitor forest changes monthly, such as <a href="https://data.globalforestwatch.org/datasets/gfw::deforestation-alerts-radd/about">RADD Alerts</a>. I compared my result with RADD Alerts, and it produced almost identical results. The advantage of using your own method instead of relying on an existing global dataset is the flexibility to adjust parameters if necessary.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Using Sentinel-1 data to detect monthly disturbance of forest canopy]]></summary></entry><entry><title type="html">Sentinel-2 Bare Earth Mosaics</title><link href="https://nasirlukman.github.io/blog/2025/bare-earth/" rel="alternate" type="text/html" title="Sentinel-2 Bare Earth Mosaics"/><published>2025-02-19T23:36:10+00:00</published><updated>2025-02-19T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/bare-earth</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/bare-earth/"><![CDATA[<p>As a tropical country, Indonesia faces challenges in using optical remote sensing data for soil and geological analysis due to extensive vegetation cover. According to the Indonesia Land Use/Land Cover (LULC) Map of 2019, only 1.8% of the land is classified as bare land. However, a significant portion of vegetated area (38.2%) consists of agricultural land. During land use changes, particularly in the early stages of agricultural development, land clearing exposes the bare soil. Additionally, many agricultural areas follow cultivation cycles, periodically revealing the soil beneath.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_6_landuse_chart-480.webp 480w,/assets/img/post_6_landuse_chart-800.webp 800w,/assets/img/post_6_landuse_chart-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_6_landuse_chart.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Indonesia Land Use percetage, reclassified from Indonesia LULC Map 2019. </div> <p>By leveraging dense time-series satellite images, we can generate a bare earth mosaic, which combines pixels from different acquisition times to maximize the exposure of the ground surface. <a href="https://www.eftf.ga.gov.au/case-study/sentinel-2-reveals-barest-earth">Geoscience Australia</a> has created such maps for the entire continent using Landsat and Sentinel-2 images. Inspired by this, I recently experimented with a method to build a bare earth mosaic for Indonesia using Google Earth Engine.</p> <h2 id="approach">Approach</h2> <p>This approach selects only the driest, non-vegetated pixels from the time-series collection while masking out permanently vegetated, wet, and built-up areas. The process involves:</p> <ol> <li> <p>Cloud Masking: Cloudmasking using <a href="https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless">s2Cloudless</a></p> </li> <li> <p>Pixel Filtering: Using various spectral indices for vegetation, water, and soil to exclude unwanted pixels.</p> </li> <li> <p>Geometric Median Computation: Calculating the geometric median of the remaining pixels to minimize noise and cloud contamination.</p> </li> <li> <p>Final Masking: Removing residual built-up areas using LULC maps.</p> </li> </ol> <p>The resulting image is a bare earth mosaic, highlighting exposed soil and geological features. For visualization purpose, masked vegetation, water, and built-up pixels can be reintroduced.</p> <h2 id="comparison-with-standard-cloudless-mosaics">Comparison with Standard Cloudless Mosaics</h2> <p>The images below compare a standard cloudless mosaic with a bare earth mosaic derived from Sentinel-2 images. The latter effectively selects the barest pixels within agricultural areas and built-up zones.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_6_agriculture-480.webp 480w,/assets/img/post_6_agriculture-800.webp 800w,/assets/img/post_6_agriculture-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_6_agriculture.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Comparison between cloudless mosaic and bare earth mosaic in agriculural land. </div> <p>This method also reveals earth surfaces in permanently forested areas, such as landslide-exposed soil and sandbars in rivers during droughts or after heavy rainfall, when sediment is deposited.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_6_river_and_landslide-480.webp 480w,/assets/img/post_6_river_and_landslide-800.webp 800w,/assets/img/post_6_river_and_landslide-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_6_river_and_landslide.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Comparison between cloudless mosaic and bare earth mosaic showing additional in river and landslide. </div> <h2 id="applications-and-challenges">Applications and Challenges</h2> <p>For further geological and soil analysis, it is best to use the masked image. For example in the image below, a simple false color-composite already show:</p> <ol> <li> <p>Soil composition variations in southern hills (greensih color), with some material transported north via river systems.</p> </li> <li> <p>Differences between eastern (yellowish) and western plains (orange).</p> </li> <li> <p>Distinct compositions within mining pits (very bright color).</p> </li> </ol> <p>This color composite highlight the potential of bare earth moscais for geological/soil analysis.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_6_false_color-480.webp 480w,/assets/img/post_6_false_color-800.webp 800w,/assets/img/post_6_false_color-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_6_false_color.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Cloudless composite, and bare earth composite, and false color of masked bare earth composite for analysis and interpretation. </div> <p>The main challenge in generating a nationwide bare earth composite for Indonesia is scalability. My current approach exceeds Google Earth Engine’s computational limits when applied at scale. To overcome this, I need to optimize the process or split the computation into hundreds of smaller patches.</p> <p>This is an ongoing experiment, and I hope to refine the method further. If you have suggestions or insights, please feel free to share!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[First trial to build Sentinel-2 bare earth mosaics for Indonesia in Earth Engine]]></summary></entry><entry><title type="html">Illegal Mining From Space</title><link href="https://nasirlukman.github.io/blog/2025/illegal-mining/" rel="alternate" type="text/html" title="Illegal Mining From Space"/><published>2025-02-09T23:36:10+00:00</published><updated>2025-02-09T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2025/illegal-mining</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2025/illegal-mining/"><![CDATA[<p>High-resolution satellite imagery provides us with global time-series data, which can be applied to various interesting applications. One such application is monitoring mining activities. There are literally thousands of mining sites across the globe, which are inherently dynamic (i.e., they undergo rapid changes over time) and often located in remote areas. This creates significant challenges for effective monitoring.</p> <p>Any serious attempt at a global-scale analysis of these activities requires the use of satellite imagery in some form. Information such as the extent of mining activity, the mining methods used, and the commodities being extracted can be interpreted from satellite data. Additionally, parameters like land-use changes, soil contamination, and surface water pollution can also be analyzed using satellite imagery.</p> <p>Of course, when discussing illegal mining specifically, satellite data alone may not be sufficient to characterize it fully. This is because the legal frameworks governing mining activities are often complex and vary from country to country. However, there are certain indicators that can help identify potential illegal activities. By incorporating additional layers of geospatial data, stronger evidence of illegal mining can be extracted.</p> <h2 id="very-high-resolution-images">Very High-Resolution Images</h2> <p>A wealth of information related to mining activities can be obtained from very high-resolution satellite images. The most obvious is the delineation of mining area boundaries. With time-series images, we can observe the development of mining activities and the areas they impact. Less obvious but equally important information includes the type of commodity being mined and the methods used. For those familiar with the mining industry, such details can often be inferred from satellite imagery alone. For example, coal mining can be identified by the black color of coal at the mining front or in stockpiles. Similarly, nickel and bauxite lateritic deposits often have distinct visual characteristics that are easily recognizable from space.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_vhr_example-480.webp 480w,/assets/img/post_5_vhr_example-800.webp 800w,/assets/img/post_5_vhr_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_vhr_example.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Different type of mining activity in Indonesia from WorldView imagery. </div> <p>One key indicator of illegal mining that can be extracted from satellite data is the mining method. Mining activities are often categorized as formal or informal. Formal mining is conducted using appropriate tools and is planned and executed by certified engineers, resulting in well-structured mining pits and infrastructure that are clearly visible from space. In contrast, informal mining is often chaotic and sporadic, lacking proper planning and adherence to good mining practices. The latter type is frequently associated with illegal mining activity, although this is not always the case.</p> <p>In Image 1 above, we can clearly see that the alluvial gold and tin mining example can be classified as informal mining. There are no visible mining infrastructures in the area, and the mining pit appears sporadic and abandoned, resembling a pond.</p> <p>While proven to be very useful, a significant drawback of very high-resolution images is that they are mostly not open data, making access to large spatial and temporal-scale datasets prohibitively expensive. For this reason, large-scale studies often rely more on high-resolution images, using only scarce and limited amounts of very high-resolution data for creating training datasets and/or validation.</p> <h2 id="automated-approach">Automated Approach</h2> <p>Given the large spatial and temporal scales involved, especially for time-series analysis on a regional or global level, an automated approach to mining area delineation and classification is essential. As previously mentioned, human experts interpret mining areas based on visual aspects rather than spectral characteristics (though hyperspectral imagery can improve accuracy). These mining areas are primarily recognized by their spatial patterns. Until recently, deep learning models have proven to be the most effective solution for this type of problem.</p> <p>I develop a small scale deep learning model to automate delinitation of artisinal/small-scale gold mining (ASGM) in some portecteed forest area in Indonesia. I used coarser-resolution NICFI satellite data with a pixel size of 5 meters, which is still sufficient for this purpose. Even lower-resolution satellite images, such as those from Sentinel-2 or Landsat, can produce good results for delineation. The training labels for ASGM boundary were manually delineated from very high-resolution WorldView images, which were then transferred to NICFI images from the same month. The model used was a U-Net architecture, trained on 39 tiles of 256x256 pixels, augmented to 195 images through flipping and rotation. Despite the relatively small training dataset, the model performed well in tracking the development of illegal alluvial gold mining in a protected forest in Indonesia.</p> <p>Below are the accuracy assessments from the validation images. The overall accuracy are 98%. Here, I only show a few validation images containing difficult scenery and look-alike features, such as large active channel bars, formal coal mining areas, and deforestation for agriculture. The model correctly labeled most of these as non-artisanal and small-scale gold mining (ASGM). Some notable false positives were detected in the ponds of formal coal mining areas. It is important to note that the current training data contain no examples of other mining types besides ASGM. Given this limitation, the fact that the model does not classify the entire area of coal mining as ASGM is already a strong result. Incorporating additional, more diverse training data would likely improve the model’s accuracy further.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_unet_validation-480.webp 480w,/assets/img/post_5_unet_validation-800.webp 800w,/assets/img/post_5_unet_validation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_unet_validation.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Visual comparison between the validation data labels and the model prediction. </div> <p>After the model get a good accuracy in the testing stage, the model are deployed for a time series analysis in the subset of the study area:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_timeseries_result-480.webp 480w,/assets/img/post_5_timeseries_result-800.webp 800w,/assets/img/post_5_timeseries_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_timeseries_result.gif" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Timeseries classification result of ASGM areas, roads, and huts. </div> <p>Since this project also aimed to test early detection approach of mining activity, we included labels for hauling roads and mining huts, which often appear before intense mining activity begins. The model also able to deliniate huts and hauling roads as long as it is visible in the imagery by human eyes.</p> <h2 id="environmental-impact">Environmental Impact</h2> <p>As mentioned earlier, satellite imagery can also provide insights into various environmental impacts. Below, we show an empirical model of turbidity levels in rivers downstream of the previously modeled alluvial gold mining sites from Sentinel 2 imagery. By comparing the graph of mining activity with turbidity levels, we can observe a temporary pause in mining activity from late 2019 to 2021, likely due to the COVID-19 pandemic. During the same period, we also observed a decrease in river turbidity, suggesting a direct link between mining activity and river pollution.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_turbidity-480.webp 480w,/assets/img/post_5_turbidity-800.webp 800w,/assets/img/post_5_turbidity-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_turbidity.gif" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Turbidity level downstream of the mining area. </div> <h2 id="further-analysis-with-additional-geospatial-data-layers">Further Analysis with Additional Geospatial Data Layers</h2> <p>For legal and compliance analysis, a reasonable first step is to overlay the generated mining area outlines with other geospatial data layers linked to regulations governing mining activities in a specific country. For example, in Indonesia, we can use mining concession boundaries to determine whether mining activities are conducted within valid permit areas. We can also add data layers related to environmentally restricted areas, such as conservation zones, protected forests, and riparian zones, where mining is prohibited. This is a first-order approach to analyzing compliance levels. As previously stated, the complete regulatory framework for mining is complex, and further detailed analysis is needed for conclusive statements. However, this level of analysis is often sufficient to assess and estimate compliance at a national level.</p> <p>Below is an example of the national level overlay results in Indonesia using data from 2019. Note that the data used in this example are not official and may be incorrect, false, or inaccurate. Nevertheless, the purpose of this post is to demonstrate how compliance levels of mining activities can be assessed using remote sensing and basic geospatial analysis.The results of this data overlay include the percentage of mining areas inside and outside concession boundaries, as well as the percentage of mining areas within environmentally restricted zones.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_donut_chart-480.webp 480w,/assets/img/post_5_donut_chart-800.webp 800w,/assets/img/post_5_donut_chart-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_donut_chart.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Donut chart of the mining are classified by its location relative to concession area and environmentally restricted area. </div> <h2 id="complience-analysis">Complience Analysis</h2> <p>To better understand the overlay results, we need to consider relevant regulations. In this study, we incorporated data layers related to mining permits and land-use-based environmental restrictions. These layers help analyze the compliance of mining activities with legal and environmental regulations. Below are the key regulatory frameworks considered:</p> <ol> <li>According to <em>UU No. 4 Tahun 2009</em>, mining activities outside of their designated exploitation concession boundaries are strictly prohibited.</li> <li>According to <em>UU No. 41 Tahun 1999</em>, any land-use activity, including mining, is prohibited within conservation areas.</li> <li>According to <em>UU No. 41 Tahun 1999</em>, surface mining in protected forests is prohibited. Underground mining activity. However, underground mining may be allowed under specific conditions.</li> <li>According to <em>UU No. 41 Tahun 1999</em>, surface mining in production forests is prohibited. Nevertheless, special licenses may be granted to permit mining activities under additional requirements.</li> <li>According to <em>PP No. 38 Tahun 2011</em>, any land-use activity, including mining, is prohibited within riparian zones. However, special licenses may be issued to allow the redirection of river flows and riparian zones under certain conditions.</li> </ol> <p>based on these we will classify mining activity activity into three different complience category:</p> <ol> <li><strong>Category 1: High Compliance</strong> This is the highest compliance class. Mining areas in this category are located: <ul> <li>Within exploitation concession boundaries, and</li> <li>Outside any land-use-based environmental restriction areas.</li> </ul> </li> <li><strong>Category 2: Conditional Compliance</strong> Mining areas in this category are: <ul> <li>Within exploitation concession boundaries, but</li> <li>Located within production forests or riparian zones.</li> <li>If these mining activities have obtained the necessary additional permits to operate in production forests and/or redirect rivers, their compliance status aligns with Category 1.</li> </ul> </li> <li><strong>Category 3: Low Compliance</strong> This is the least compliance class in this analysis. The mining area are This is the least compliant category. Mining areas in this class are either: <ul> <li>Located within exploitation concession boundaries but also in protected forests or conservation areas, where mining is strictly prohibited, or</li> <li>Situated outside any concession boundaries, regardless of other restrictions.</li> </ul> </li> </ol> <p>The chart below visualize the categorization of the mining areas:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_classification_diagram-480.webp 480w,/assets/img/post_5_classification_diagram-800.webp 800w,/assets/img/post_5_classification_diagram-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_classification_diagram.gif" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Complience category based on overlay results </div> <p>The result can also be visualized on province basis using pie chart map as shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_category_pie_chart-480.webp 480w,/assets/img/post_5_category_pie_chart-800.webp 800w,/assets/img/post_5_category_pie_chart-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_category_pie_chart.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Pie chart showing the percentage area of each category for every province. </div> <h2 id="further-analysis">Further analysis</h2> <p>I also think it would be interesting to combine this dataset with detailed census data. For example, I attempted to combine it with the WorldPop gridded population dataset to estimate the number of people living within a 10 km buffer of mining areas. This helps identify the potential population directly impacted by mining activities. Further analysis of health, education, and income data for this population could be valuable for future research.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_5_pop-480.webp 480w,/assets/img/post_5_pop-800.webp 800w,/assets/img/post_5_pop-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_5_pop.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. Total population living within 10 km buffer of mining areas </div> <h2 id="conclussion">Conclussion</h2> <p>Satellite imagery provides extensive spatial and temporal coverage, making it a valuable tool for large-scale monitoring of terrestrial activities, including illegal mining. Using satellite data alone, we can extract information such as mining boundaries over time, mining methods, commodities, and environmental impacts. In our small-scale test, we demonstrated how deep learning can automate the mining boundary delineation process with good accuracy. To assess the compliance status of mining activities, additional geospatial data layers are required. In this example, we used unofficial mining concession boundaries and environmentally restricted area boundaries as an example. This simple yet effective approach enables high-scale monitoring to identify trends in mining activities and their compliance with regulations.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Using satellite imagery to monitor illegal mining]]></summary></entry><entry><title type="html">Exploratory Data Analysis (EDA) for Hyperspectral Imagery</title><link href="https://nasirlukman.github.io/blog/2024/EDA/" rel="alternate" type="text/html" title="Exploratory Data Analysis (EDA) for Hyperspectral Imagery"/><published>2024-12-09T23:36:10+00:00</published><updated>2024-12-09T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/EDA</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/EDA/"><![CDATA[<p>One of the main characteristics of hyperspectral imagery is its high-dimensional data (i.e., a high number of spectral bands). This type of data, while providing a higher level of detail in the spectral characteristics of the material we observe, also raises challenges in handling the data effectively. Higher dimensional data means it becomes more challenging to extract meaningful information for analysis. These challenges are often referred to as <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">the curse of dimensionality</a>.</p> <p>In this post, I will show my approach in conducting exploratory data analysis (EDA) on a hyperspectral imagery with the goal of deriving meaningful geological information from the data. In this post, we will assume no geological prior knowledge of the region (although nowadays that is hardly the case, especially for Earth’s surface). We will rely solely on the hyperspectral data itself and some basic spectrometry and geology knowledge.</p> <p>We will use an airborne hyperspectral image covering the shortwave infrared range (SWIR) from ~2000 nm to ~2400 nm over an area of about 10 km² in an arid region. All of the analysis performed in this post is done using standard scientific libraries in the Python environment and an open-source software called <a href="http://hyppy.is-great.org/?i=1">Hyppy</a> developed at the University of Twente.</p> <h2 id="1-basic-visualization">1. Basic visualization</h2> <p>The obvious first step in EDA of hyperspectral imagery is to visualize the image. We can choose to visualize the image in grayscale for selected wavelength bands of interest and create false color composites to observe the main structural characteristics of the region.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_composite-480.webp 480w,/assets/img/post_4_composite-800.webp 800w,/assets/img/post_4_composite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_composite.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. False color composite image (R: 2088 nm; G: 2199 nm; B: 2328 nm) </div> <p>My initial interpretation of the region is that it is most likely mainly composed of sedimentary bedding influenced by a fault with apparent left-lateral movement, based on the drag fold formed along the fault lines.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_basic_interpretation-480.webp 480w,/assets/img/post_4_basic_interpretation-800.webp 800w,/assets/img/post_4_basic_interpretation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_basic_interpretation.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Basic geological feature initial interpretation from the image </div> <p>When it comes to mineralogical/geological interpretations, I find it helpful to begin with a very broad interpretation. Knowing that the region is likely predominantly composed of sedimentary rocks already provides significant constraints for further interpretation, which may be very useful in the next phase. We may revisit this interpretation later if further analysis or data does not support it.</p> <h2 id="2-getting-to-know-the-data">2. Getting to know the data</h2> <p>It is very important to familiarize ourselves with the data we are working with. At this stage, I typically inspect the spectra of some pixels that stand out in the visualization and get a sense of the variation in spectral responses present in the image. For this, I often use specialized software such as <a href="https://www.nv5geospatialsoftware.com/Products/ENVI">ENVI</a>, <a href="https://plugins.qgis.org/plugins/temporalprofiletool/">QGIS with Spectral Profile Plugin</a>, or <a href="http://hyppy.is-great.org/?i=1">Hyppy</a>. The later two is an open source program which are available for free.</p> <p>At this stage, we can also plot a histogram of the mean reflectance values of the image to see how many visible clusters are present across the spectral bands. Note that the reflectance value are in the sacale of 10,000.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_mean_histogram-480.webp 480w,/assets/img/post_4_mean_histogram-800.webp 800w,/assets/img/post_4_mean_histogram-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_mean_histogram.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Histogram of mean albedo of each pixel in the image showing two main albedo class. </div> <p>From the histogram, we can decide on a threshold to classify our pixels based on their average albedo. This is generally equivalent to classifying the image into bright-colored minerals and dark-colored minerals (albeit in the shortwave infrared range, not in the visible range). Typically, low-albedo minerals in SWIR also appear dark in visible light. Our first classification results are shown below which shows the most basic classification of the image we have: reflective vs absortive minerals.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_albedo_class-480.webp 480w,/assets/img/post_4_albedo_class-800.webp 800w,/assets/img/post_4_albedo_class-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_albedo_class.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Map showing the distribution of two albedo class. </div> <h2 id="3-pca-and-k-means-clustering">3. PCA and K-Means Clustering</h2> <p>Since the number of pixels and spectral bands is often too high to handle for meaningful interpretation, dimensional reduction and data clustering methods can be useful for grouping data into clusters of spectra based on their spectral similarity which can make further analysis to be easier. While we can directly apply K-Means clustering to the data, this is not usually recommended. Each dimension of our data carries varying levels of information and noise. For high-dimensional data, only a few dimensions typically contain significant information, while others only add noise to the algorithm.</p> <p>PCA is a dimensionality reduction method that organizes data based on its variability in the data space, corresponding to its information content. It identifies the directions (principal components) where the data varies the most and projects the data onto these axes in descending order of variance. The downside is that the data is transformed into an orthogonal space where the units lose their original physical meaning. In this example, we visualize the first 10 principal components and observe that by the 10th component, there is minimal discriminatory power. Therefore, we reduce the dimensionality from 55 to 10 principal components, preserving the most significant information, and use this result as the input for K-Means clustering.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_PCA-480.webp 480w,/assets/img/post_4_PCA-800.webp 800w,/assets/img/post_4_PCA-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_PCA.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. First 10 PCA images. </div> <p>The K-Means algorithm clusters data points based on their similarities. It assigns each point to one of K clusters based on its proximity to the cluster centroids, iterating to minimize variance within clusters. Similarities are computed using Euclidean distance, which I explained in a <a href="https://nasirlukman.github.io/blog/2024/distance/">previous post</a>.</p> <p>K-Means requires the user to define the number of clusters (\(K\) ). The elbow method can help determine this, by plotting the within-cluster sum of squares (WCSS) for various K values. The optimal number of clusters is where the WCSS curve starts to saturate, resembling an elbow. For this dataset, the optimal number of clusters is 3, as shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_WCSS-480.webp 480w,/assets/img/post_4_WCSS-800.webp 800w,/assets/img/post_4_WCSS-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_WCSS.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. WCSS result for cluster values ranging from 1 to 11. </div> <p>Using \(K=3\) , we perform clustering, with the results shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_cluster_map-480.webp 480w,/assets/img/post_4_cluster_map-800.webp 800w,/assets/img/post_4_cluster_map-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_cluster_map.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. K-Mean clustering result from the first 10 principle component of our hyperspectral images. </div> <p>We then can transform the pixels back from PCA space to the original data space to examine the average mean spectra of each cluster:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_cluster_spectra-480.webp 480w,/assets/img/post_4_cluster_spectra-800.webp 800w,/assets/img/post_4_cluster_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_cluster_spectra.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. Average spectra of each cluster. </div> <p>Compared to our initial simple classification by mean albedo, this approach offers more nuance. For instance, the high-albedo reflectance now separates into two distinct spectral shapes, while the low-albedo minerals remain a single cluster. To further refine the low-albedo cluster, we could mask the high-albedo pixels and repeat the process. However, for this example, I am satisfied with these results. At this stage, I observe that the low-albedo cluster has largely featureless spectra (likely consisting of minerals without distinct features in the SWIR range), making further attempt for meaningful subdivision challenging.</p> <h2 id="4-endmember-extraction-and-linear-spectreal-unmixing">4. Endmember Extraction and Linear Spectreal Unmixing</h2> <p>Since our average spectra likely represent complex mixtures, it is useful to extract their possible pure spectral shapes. At this stage, we have decided to categorize our image into three distinct classes. We will use the <a href="">N-FINDR</a> algorithm with \(n=3\) to extract the three purest endmembers from our image. The data distribution in 2D PCA space and the extracted endmember pixels are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_nfindr_plot-480.webp 480w,/assets/img/post_4_nfindr_plot-800.webp 800w,/assets/img/post_4_nfindr_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_nfindr_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 9. Data shape in reduced 2 PCA dimension showing clear linear relationship between three endmembers. Red star is the vertex of the triangle which corespond to the purest pixel on the image. </div> <p>This is an excellent 2D PCA representation. The 2D simplex (triangle) is almost perfectly formed, indicating that our entire dataset can be described as a linear combination of three endmember spectra. These endmembers therefore must be the pixel that correspond to the vertices of the triangle. After transforming the extracted endmembers back into the original data space, we observe their pure spectral signatures:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_endmember_spectra-480.webp 480w,/assets/img/post_4_endmember_spectra-800.webp 800w,/assets/img/post_4_endmember_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_endmember_spectra.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 10. Spectra of the purest pixels (endmembers). </div> <p>This is a good point to start naming our classes properly. You could match the spectra to a spectral library using a feature-matching algorithm to identify the mineral spectra most similar to the extracted endmembers. For simplicity, I use broad categorizations. I define the first spectrum as the <strong>Low-Albedo Mineral Group,</strong> likely dominated by plagioclase or mafic minerals, interpreted as part of a volcanic rock complex. The second spectrum corresponds to the <strong>Hydroxyl Mineral Group</strong>, based on its \(AlOH\) feature around 2200 nm, likely related to the occurance of white micas or clays, interpreted as part of siliciclastic rocks such as arkose. The third spectrum represents the <strong>Carbonate Mineral Group</strong>, with a \(CO_3\) feature near 2300 nm, likely from calcareous sedimentary rocks like limestone or calcareous sandstone/siltstone.</p> <p>With our pure endmembers identified, we can perform linear spectral unmixing to estimate their relative abundances. At this stage of analysis, I prefer to not constrain the unmixing result to be strictly sum-to-one since there are still many unknowns. These abundance results are interpreted as <em>unconstrained abundances</em>, distinct from <em>absolute abundances</em>, which have more physical meaning. Below are the unconstrained abundance maps for each endmember:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_unmixing_result-480.webp 480w,/assets/img/post_4_unmixing_result-800.webp 800w,/assets/img/post_4_unmixing_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_unmixing_result.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 11. Unconstrained abundance of the three endmembers. </div> <p>Since we are dealing with only three mineral groups, we can assign each abundance to an RGB channel to produce a ternary representation of the unconstrained abundances:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_unmixing_result_ternary_with_legend-480.webp 480w,/assets/img/post_4_unmixing_result_ternary_with_legend-800.webp 800w,/assets/img/post_4_unmixing_result_ternary_with_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_unmixing_result_ternary_with_legend.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 12. Ternary map of the unconstrained abundance of the three endmembers. </div> <p>It is important to note that this ternary representation is purely for visualization and does not strictly correspond to the absolute abundance of each endmember.</p> <h2 id="5-minimum-wavelength-mapping">5. Minimum Wavelength Mapping</h2> <p>Many distinct hyroxyl and carboante minerals can be distinguished based on the subtle difference in the wavelength position of their deepest absorption feature. Using a method called minimum wavelength mapping, we can detect these subtle shifts and potentially refine our classification to include specific members of the carbonate and hydroxyl mineral groups. The first step is to detect the wavelength of the deepest absorption feature across the entire spectral range.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_minwav-480.webp 480w,/assets/img/post_4_minwav-800.webp 800w,/assets/img/post_4_minwav-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_minwav.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 13. Minimum wavelength position histogram for the whole spectral range. </div> <p>We observe at least three distinct distributions of \(AlOH\) absorption features and five distributions of \(CO_3\) absorption features. For the \(AlOH\) group, the lowest feature observed at 2195 nm likely corresponds to lithium-rich white mica, such as lepidolite. The other two \(AlOH\) features, around 2210 nm and 2220 nm, likely correspond to \(Al\)-rich white mica, such as muscovite, with minor geochemical differences attributed to variations of geochemistry and temperature of the mineral formation.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_AlOH_minwav_legend-480.webp 480w,/assets/img/post_4_AlOH_minwav_legend-800.webp 800w,/assets/img/post_4_AlOH_minwav_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_AlOH_minwav_legend.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 14. Minimum wavelength map of hydroxile features. </div> <p>For the \(CO_3\) group, there is significant variation in the deepest feature wavelengths. Although identifying specific minerals at this stage is challenging, the observed ranges suggest these features are unlikely to correspond to calcite, the most common carbonate mineral. For instance, features around 2335 nm are commonly associated with siderite, 2320 nm with dolomite, and 2305 nm with magnesite.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_CO3_minwav_legend-480.webp 480w,/assets/img/post_4_CO3_minwav_legend-800.webp 800w,/assets/img/post_4_CO3_minwav_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_CO3_minwav_legend.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 15. Minimum wavelength map of carbonate features. </div> <p>It is essential to note that pinpointing specific minerals requires further analysis. While we cannot yet confirm the mineral species, the variations in these wavelength ranges are likely related to mineralogical differences. Therefore, the spatial distribution of these distinct groups remains valid, even when we are still uncertain with the definitive mineral identifications.</p> <h2 id="6-further-comments">6. Further comments</h2> <p>In this post, I demonstrated some typical EDA steps for hyperspectral analysis for geological investigations in an unfamiliar region. These EDA steps serve to familiarize us with the data and provide a solid foundation for further investigation.</p> <p>Here we see that SWIR hyperspectral data alone can reveal a wealth of information, even without incorporating additional datasets, prior knowledge of the region, or advanced analysis techniques. However, complementary datasets, such as VNIR and LWIR spectral data, could significantly enhance geological and mineralogical interpretation of the region. Additionally, methods beyond infrared spectrometry, such as gamma-ray spectrometry, offer valuable tools for geological mapping.</p> <p>In practice, prior knowledge of the study area—such as geological maps or models—is often available and can effectively guide the analysis. More importantly, incorporating fieldwork data, even from sparse sampling points, is crucial for validating and refining the results.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[My typical approach on EDA for a new hyperspectral projects for geological investigations. Includes method such as PCA, K-Means, N-FINDR, Linear Spectral Unmixing, and Minimum Wavelength Mapping.]]></summary></entry><entry><title type="html">Endmember Extraction from Hyperspectral Imagery Using N-FINDR</title><link href="https://nasirlukman.github.io/blog/2024/nfindr/" rel="alternate" type="text/html" title="Endmember Extraction from Hyperspectral Imagery Using N-FINDR"/><published>2024-11-27T23:36:10+00:00</published><updated>2024-11-27T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/nfindr</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/nfindr/"><![CDATA[<p>Hyperspectral imagery often contains mixed pixels—pixels that represent areas with more than one class of interest. Given the complexity of the scenes, and the rigid structure of images, it is unrealistic to assume every pixel to correspond to a single class. These classes could include features like water, trees, shrubs, grass, soil, or roads when performing land cover classification using satellite or airborne imagery. In earth science, the class of interest often is minerals that forms rocks. In any way, trying to find the purest pixels , or <em>endmembers</em>, of each class in our image is something that often useful for further analysis.</p> <p>In this post, I’ll provide a brief overview of one endmember extraction algorithm reffered to as <em>N-FINDR</em>. But, before diving into the details of the algorithm, it is important to acknowledge the general limitations of endmember extraction algorithms:</p> <ol> <li><strong>Purity is not guaranteed</strong>: These algorithms don’t guarantee that the extracted spectra represent a pure spectra of specific class of interest. Instead, they identify the purest spectra present in the image.</li> <li><strong>Known number of endmembers</strong>: The number of endmembers in the image must be known beforehand. This can be estimated using domain expertise, auxiliary measurements, other algorithms, or trial and error.</li> <li><strong>Linear mixture model assumption</strong>: Most endmember extraction algorithms, including N-FINDR, assume a linear mixture model.</li> </ol> <h2 id="how-n-findr-works">How N-FINDR Works</h2> <p>The core idea of N-FINDR is simple yet clever: it identifies the vertices of the simplex formed by the data distribution in reduced dimensions. These vertices are the purest spectra present in the dataset. The general steps of the algorithm is as follows:</p> <ol> <li><strong>Reprojection</strong>: Reproject all pixels into a lower-dimensional space using an orthogonal transformation like Principle Component Analysis (PCA) or Minimum Noise Fraction (MNF). MNF is often preferred because it minimizes the influence of noise.</li> <li><strong>Dimensionality reduction</strong>: Reduce the dimensionality to the first \((n−1)\) components, where \(n\) is the number of endmembers. At this stage, the data points should lie inside an \((n-1)\) dimensional simplex.</li> <li><strong>Iterative vertex selection</strong>: <ul> <li>Randomly select \(n\) points and calculate the simplex’s volume (or area in 2D).</li> <li>Iteratively replace one vertex with another pixel. If the new simplex’s volume is larger, accept the replacement. Otherwise, reject it and try again.</li> </ul> </li> <li><strong>Termination</strong>: After a fixed number of iterations without improvement, the algorithm terminates, and the final set of pixels is taken as the endmembers.</li> <li><strong>Reprojection back</strong>: Reproject the selected pixels into the original dimensional space to obtain the endmember spectra.</li> </ol> <h2 id="synthetic-data-example">Synthetic Data Example</h2> <p>To illustrate, let’s consider an idealized case of 1,000 synthetic mixed pixels generated from three endmembers. Since we’re dealing with three endmembers, we reproject the data into its first two principal components. In this reduced space, the data points lie perfectly on a 2D simplex—a triangle as shown in the image below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_synthetic_mixture_MNF-480.webp 480w,/assets/img/post_3_synthetic_mixture_MNF-800.webp 800w,/assets/img/post_3_synthetic_mixture_MNF-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_synthetic_mixture_MNF.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. First two principal components of the synthetic mixture of three endmembers </div> <p>If each data point is a linear mixture of three pure endmembers, the endmembers will be located at the vertices of a triangular region, commonly referred to as a simplex. In this 2D example, identifying the simplex is relatively straightforward through visual inspection. However, as the number of endmembers increases, the dimensionality of the principal component representation also grows, making it increasingly difficult to determine the simplex visually. To overcome this challenge, we employ an iterative simplex-finding algorithm, which can be generalized to handle higher-dimensional data. The animation below illustrates the iterative process of refining the simplex:</p> <div style="display: flex; justify-content: center;"> <img src="/assets/img/post_3_nfindr_iterative.gif" alt="NFINDR"/> </div> <div class="caption"> Image 2. Ilustration of NFINDR algorithm in action </div> <h2 id="real-data-example">Real Data Example</h2> <p>In real-world scenarios, hyperspectral data is rarely as ideal as synthetic examples. Complex noise, non-linearities, and other factors often result in an imperfectly formed simplex. Nevertheless, algorithms like N-FINDR can still provide valuable output.</p> <p>For this example, we examine laboratory-acquired hyperspectral imagery of a sandstone sample. Below is a false-color composite image of the sample:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_rock_image-480.webp 480w,/assets/img/post_3_rock_image-800.webp 800w,/assets/img/post_3_rock_image-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_rock_image.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. False color composite hyperspectral iamge of a sandstone sample </div> <p>A quick inspection of the rock suggests that it is predominantly composed of three minerals. Thus, we assign \(n=3\) for this analysis. The results of the MNF transformation and the selected simplex vertices by N-FINDR are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_real_mixture_MNF-480.webp 480w,/assets/img/post_3_real_mixture_MNF-800.webp 800w,/assets/img/post_3_real_mixture_MNF-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_real_mixture_MNF.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. First two principal components of the sandstone rock sample. The red do represent the selected purest spectra by N-FINDR algorithm. </div> <p>Notice that the simplex is not perfectly formed, and the triangular structure appears slightly distorted. This suggests minor non-linear behavior in the actual mixtures. Additionally, some outliers lie outside the simplex, possibly influenced by accessory minerals. Such minerals, often present in small amounts, are common in natural rock samples and can affect the spectra of certain pixels. These influences may not be fully captured in a 2D representation.</p> <p>We can examine the spectra of the selected purest pixels by transforming them back to their original dimensions. Below are the resulting spectra for the three identified endmembers:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_pure_endmember_result-480.webp 480w,/assets/img/post_3_pure_endmember_result-800.webp 800w,/assets/img/post_3_pure_endmember_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_pure_endmember_result.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Resulting spectra of the three endmember from N-FINDR algorithm </div> <p>If you know your mineralogy and infrared spectroscopy you can immedietly recognize these minerals. The red spectra have a strong absorption feature in ~2200 nm region which related the \(Al-OH\) bonds of white mica/clay mienrals. The blue spectra have an absroption feature in ~2330 nm region related to \(CO_3\) bonds of carbonate minerals. The green and bright spectra represent quartz mineral. we still can see a very weak feature in ~2200 nm sugest that it is not 100% pure spectra and there is still a small influence of clay minerals.</p> <p>While these spectra are not perfectly pure, they are sufficiently representative to be useful for further analysis. For instance, as shown in our <a href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/">previous post</a>, we used these endmember spectra for spectral unmixing and achieved excellent results, with an RMSE of only 0.0186.</p> <p>To understand the spatial context, we can reshape the extracted data back into its original image structure to visualize the locations of the purest pixels:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_rock_image_with_pure_pixel-480.webp 480w,/assets/img/post_3_rock_image_with_pure_pixel-800.webp 800w,/assets/img/post_3_rock_image_with_pure_pixel-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_rock_image_with_pure_pixel.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. False color composite hyperspectral image of a sandstone sample along with its purest pixel location. </div> <p>This example shows that N-FINDR is a powerful and intuitive algorithm for endmember extraction. Despite its limitations, such as the need for prior knowledge of the number of endmembers and the assumption of a linear mixture model, it often still provides a usefull results.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[A brief overview, ilustration and case example of N-FINDR algorithm to extract mineral endmembers in hyperspectral imagery.]]></summary></entry><entry><title type="html">Bayesian Spectral Unmixing</title><link href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/" rel="alternate" type="text/html" title="Bayesian Spectral Unmixing"/><published>2024-11-24T12:36:10+00:00</published><updated>2024-11-24T12:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/bayes-unmixing</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/bayes-unmixing/"><![CDATA[<p>In the <a href="https://nasirlukman.github.io/blog/2024/distance/">previous post</a> we discussed how spectral unmixing inherently suffers from uncertainty—stemming both from the data and the model. Traditional optimization approaches, like the one we used earlier, often assume that these uncertainties are either negligible or nonexistent. However, in practice, this is rarely the case.</p> <p>In this post, we’ll take a brief look at the <strong>Bayesian approach</strong> to <strong>spectral unmixing</strong>, which explicitly accounts for these uncertainties. By incorporating them into the model, we propagate the uncertainty through to the final results. Instead of a single vector of mineral abundances, the Bayesian approach provides a probability distribution for these abundances, offering deeper insight into the confidence we have in our estimates.</p> <p>While we won’t dive too deeply into the math, a basic formulation helps set the stage. The linear mixture model can be expressed as:</p> \[\mathbf{y} = \mathbf{E} \mathbf{a} + \mathbf{e}\] <p>where:</p> <ul> <li>\(\mathbf{y}\) is the observed spectrum,</li> <li>\(\mathbf{E}\) is the endmembers matrix,</li> <li>\(\mathbf{a}\) is the abundance vector,</li> <li>\(\mathbf{e}\) represents error terms/uncertainty.</li> </ul> <blockquote> <p>Context for this post: We are focusing on unmixing for minerals on particulate surfaces (e.g., rock surfaces). Due to multiple-scattering effects, the linear relationship above does not hold when using reflectance data. Instead, we will use the <a href="https://en.wikipedia.org/wiki/Single-scattering_albedo">Single Scattering Albedo (SSA)</a> which derived from Hapke’s Model, as it better handles these effect. For those interested in the underlying theory, I highly recommend consulting <a href="https://www.cambridge.org/core/books/theory-of-reflectance-and-emittance-spectroscopy/C266E1164D5E14DA18141F03D0E0EAB0">this book</a>; these two papers that really helps me a lot with the subject: <a href="https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/JB094iB10p13619">[1]</a>, <a href="https://www.researchgate.net/publication/264564339_A_Review_of_Nonlinear_Hyperspectral_Unmixing_Methods">[2]</a>; or other sources (including my <a href="https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;opi=89978449&amp;url=http://essay.utwente.nl/101556/1/Lukman_MA_ITC.pdf&amp;ved=2ahUKEwjqlY-m8faJAxUdw6ACHRUJKj0QFnoECBkQAQ&amp;usg=AOvVaw3Tbo1LEGrTchQ7edNZoxGt">thesis</a>😉)</p> </blockquote> <h3 id="bayesian-framework">Bayesian Framework</h3> <p>Following <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ Theorem</a>, we can represent the spectral unmixing problem as:</p> \[P(\mathbf{a}, \sigma^2 \mid \mathbf{y}, \mathbf{E}) \propto P(\mathbf{y} \mid \mathbf{a}, \sigma^2, \mathbf{E}) P(\mathbf{a}) P(\sigma^2)\] <p>where:</p> <ul> <li>\(P(\mathbf{a}, \sigma^2 \mid \mathbf{y}, \mathbf{E})\) is the posterior distribution of the abundance vector and error variance given the observed spectrum and endmembers,</li> <li>\(P(\mathbf{y} \mid \mathbf{a}, \sigma^2, \mathbf{E})\) is the likelihood of the observed spectrum,</li> <li>\(P(\mathbf{a})\) is the prior distribution of the abundance vector,</li> <li>\(P(\sigma^2)\) is the prior distribution of the error variance,</li> <li>and \(\propto\) denote proportionality</li> </ul> <p>We assume that the error term \(\mathbf{e}\) is normally distributed, giving us a <a href="https://distribution-explorer.github.io/continuous/normal.html">Normal</a> likelihood:</p> \[P(\mathbf{y} \mid \mathbf{a}, \sigma^2, \mathbf{E}) = \mathcal{N}(\mathbf{y} \mid \mathbf{E}\mathbf{a}, \sigma^2\mathbf{I}),\] <p>where \(\mathbf{I}\) is the identity matrix.</p> <p>For the abundance vector \(\mathbf{a}\), we use a <a href="https://distribution-explorer.github.io/multivariate_continuous/dirichlet.html">Dirichlet</a> prior to enforce the non-negativity and sum-to-one constraints:</p> \[P(\mathbf{a}) = \mathcal{D}(\mathbf{a} \mid \boldsymbol{\alpha}),\] <p>where \(\boldsymbol{\alpha}\) is the concentration parameter.</p> <p>For the error variance \(\sigma^2\), we assign a <a href="https://distribution-explorer.github.io/continuous/halfcauchy.html">Half-Cauchy</a> prior:</p> \[P(\sigma^2) = \mathcal{HC}(\sigma^2 \mid \beta),\] <p>with the scale hyperparamter \(\beta\) given a <a href="https://distribution-explorer.github.io/continuous/uniform.html">Unifrom</a> prior such as:</p> \[P(\beta) = \mathcal{U}(\beta \mid 0, 0^{-4}).\] <p>Therefore, we can summarize the hierarchical structure of the random variables as:</p> \[\mathbf{y} \sim \mathcal{N}(\mathbf{E}\mathbf{a}, \sigma^2\mathbf{I})\] \[\mathbf{a} \sim \mathcal{D}(\boldsymbol{\alpha})\] \[\sigma^2 \sim \mathcal{HC}(\beta)\] \[\beta \sim \mathcal{U}(0, 10^{-4})\] <p>As you might guess, this formulation of the posterior distribution cannot be solved analytically. Instead, we use <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"><em>Markov Chain Monte Caelo (MCMC)</em></a> to sample and estimate the posterior. For educational purposes, I’ve implemented a custom sampler based on the <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"><em>Metropolis-Hastings Random Walk</em></a> in Python. In practice, however, modern samplers like <em>NUTS (No-U-Turn Sampler)</em> in an established library such as <a href="https://www.pymc.io/welcome.html">PyMC</a> are often preferable. They offer a more efficient and streamlined sampling process, sparing users the burden of directly managing the nasty mathematics behind these algorithms.</p> <p>In the Metropolis-Hastings algorithm, we iteratively draw samples from the posterior. For each new sample, we evaluate its probability relative to the previous sample. The sample is either accepted or rejected based on this evaluation. Over many iterations, the density of accepted samples approximates the true posterior distribution.</p> <p>For illustration, the animation below shows the random walk process for sampling abundance parameters in a mixture of three endmembers. The blue regions represent the true target distribution. Notice how the sampler, starting from a random point in the parameter space, gradually converges to the high-probability regions:</p> <div style="display: flex; justify-content: center;"> <img src="/assets/img/post_2_random_walk.gif" alt="Random Walk"/> </div> <div class="caption"> Image 1. Random Walk Example on a known target distribution </div> <h3 id="practical-example">Practical Example</h3> <p>In this example, we will analyze a sandstone rock sample. Rock samples are ideal for testing this method since they represent natural surfaces and still allow us to conduct other detailed analytical measurements with laboratory instruments to produce high-quality ‘ground truth’ data for comparison with our results.</p> <p>For the endmembers, we consider three primary components of sandstone: quartz (grains), clay (matrix), and carbonates (cement). The endmember spectra for these minerals are assumed to be known, either from direct laboratory measurements, spectral libraries, or endmember extraction algorithms for hyperspectral imagery. We begin with a single mixed spectrum, as shown in the image below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_data-480.webp 480w,/assets/img/post_2_data-800.webp 800w,/assets/img/post_2_data-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_data.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Endmember spectra for Carbonate, Quartz, Clay minerals, and the observed mixed spectra </div> <p>Using our Metropolis-Hastings sampler, we draw four chains of \(10^5\) random samples, tuning them carefully to ensure we only consider representative samples. For simplicity, we focus solely on the mineral abundances and omit other parameters. Below, we display the abundance trace plots alongside their corresponding marginal posterior distributions. The mean value (expected values) of the samples and the true abundance values are also shown as comparison. The RMSE for this result is 0.0209.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_trace_plot-480.webp 480w,/assets/img/post_2_trace_plot-800.webp 800w,/assets/img/post_2_trace_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_trace_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Marginal posterior distribution of each endmembers abundance and its trace plots </div> <p>There are some cool things that we can do with the posteriors. For instance, we can visualize parameter correlations using a corner plot, as shown below. Note as well how we denote the result with some notation such as: \(0.14_{-0.12}^{+0.16}\) where the central value represents the expected value, while the subscript and superscript indicate the range of possible value within 90% confidence interval.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_corner_plot-480.webp 480w,/assets/img/post_2_corner_plot-800.webp 800w,/assets/img/post_2_corner_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_corner_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Corner plot of the marginal posterior showing correlations between each endmember abundances. Red and blue line represent the expected value (mean) and the true value. The black stripped line represent the boundary of 90% confidence interval. </div> <p>Corner plots are a really useful visualization, especially for high-dimensional parameter spaces. For this three-parameter example, however, we can also visualize the posterior on a ternary diagram:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_ternary-480.webp 480w,/assets/img/post_2_ternary-800.webp 800w,/assets/img/post_2_ternary-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_ternary.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Ternary plot of the posterior of the abundances. Red and blue dot represent the expected value (mean) and the true value. </div> <p>The corner and ternary plots reveal a strong correlation between carbonate and quartz abundances. As carbonate increases, the algorithm compensates by reducing quartz to maintain a reasonable modeled spectrum that aligns with the observed data. Instead of a single modeled spectrum, the output is a distribution of spectra, visualized below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_modeled_spectra-480.webp 480w,/assets/img/post_2_modeled_spectra-800.webp 800w,/assets/img/post_2_modeled_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_modeled_spectra.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Observed spectra vs distribution of the modeled spectra </div> <p>This visualization highlights that, given the data and assumed uncertainties, the reasonable set of modeled spectra is represented by the 2D Normal distribution visualize by its percentiles as shown on the image above.</p> <h3 id="hyperspectral-images">Hyperspectral Images</h3> <p>The same process applies to hyperspectral images on a pixel-by-pixel basis. Here, we analyze a hyperspectral image of a sandstone drill core sample. Remember that for individual spectra (or also pixel in this case) the sampler will need to take and store \(10^{5}\) sample for each parameters. This means that the final result will be a huge 4D array, and the computation might take some time, depending on the efficiency of the sampling algorithm used. Below, we visualize the expected abundance values for each endmember and their 90% confidence intervals range:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_rock_sample-480.webp 480w,/assets/img/post_2_rock_sample-800.webp 800w,/assets/img/post_2_rock_sample-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_rock_sample.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Bayesian spectral unmixing result on a hyperspectral image of a rock sample </div> <p>Comparing our bulk results with <a href="https://en.wikipedia.org/wiki/QEMSCAN">QEMSCAN</a> results, we can achieve excellent agreement with an RMSE of 0.0186.</p> <p>It’s important to highlight that quantification through imaging techniques like this does more than just identify mineral abundances—it also provides a detailed view of the rock’s texture. By analyzing mineral distributions and their spatial relationships, we can potentially infer other critical physical properties of the rock such as porosity and permeability, which might be really usefult for application like reservoir characterization and groundwater studies.</p> <p>The inclusion of uncertainty measurement in spectral unmixing offers an important insights into the reliability of the results. Rather than relying solely on point estimates, we gain a more nuanced understanding of the possible variations and correlations in parameter space. This is particularly valuable when making decisions based on complex data, as it helps avoid overconfidence and identifies parameters requiring further refinement. In mineral quantification, understanding uncertainties can reveal how robust the mineral abundance estimates are, guiding both data interpretation and future analyses.</p> <p>Hyperspectral imaging, as demonstrated in this example, have the potential for a more fast and cost-effective alternative of mineral abundance mapping compared to other laboratory method. Moreover, it has the potential to scale up to airborne and satellite platforms, making it one of a kind method for larger-scale mineral mapping and monitoring.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Bayesian approach on spectral unmixing with an example case using hyperspectral images of sandstone drill core sample.]]></summary></entry><entry><title type="html">Different Distance Metrics Example in Spectral Unmixing</title><link href="https://nasirlukman.github.io/blog/2024/distance/" rel="alternate" type="text/html" title="Different Distance Metrics Example in Spectral Unmixing"/><published>2024-11-15T23:36:10+00:00</published><updated>2024-11-15T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/distance</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/distance/"><![CDATA[<p>In data space, distance is commonly used to measure the similarity between data points. For instance, if points <em>a</em> and <em>b</em> are “close” to each other (i.e., have a small distance), they are considered more similar. This concept is essential in machine learning and data analysis as it can be used to quantifies similarity between datasets.</p> <p>In two dimensions, it’s easy to visualize data points and assess their distances, such as in this example:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_image_1_three_point_distance-480.webp 480w,/assets/img/post_1_image_1_three_point_distance-800.webp 800w,/assets/img/post_1_image_1_three_point_distance-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_image_1_three_point_distance.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Three points in two dimensional space, illustrating the concept of distance. </div> <p>Visually, most of us would agree that points <em>a</em> and <em>b</em> appear closer in distance to each other compared to <em>a</em> and <em>c</em>. But is this really the case? To confirm, we need to define what we mean by “distance” and calculate the distance between each point.</p> <p>In this post, we will examine three different distance metrics and compare their performance in a hypothetical spectral unmixing problem: <em>Euclidean distance, Manhattan distance, and angular distance.</em> I think it is easier to first take a look the visualization of how each metrics measure distance:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_image_2_three_type_of_distance-480.webp 480w,/assets/img/post_1_image_2_three_type_of_distance-800.webp 800w,/assets/img/post_1_image_2_three_type_of_distance-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_image_2_three_type_of_distance.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Comparison of how Euclidean, Manhattan, and Angular distances measure relationships between points. </div> <p>I think this ilustration cleary shows the distinction between how the three metrics measure distance, to formalize this, let’s go to each metrics and see its mathematical formulation.</p> <h3 id="euclidean-distance">Euclidean Distance</h3> <p>The most common and intuitive distance is Euclidean distance, also often referred to as \(L_2\) distance. Between two points \(a\) and \(b\) in data space, Euclidean distance is simply the straight-line distance between the points, which can be expressed mathematically as:</p> \[L_2 = \sqrt{\sum_{i=1}^n (a_i - b_i)^2}\] <h3 id="manhattan-distance">Manhattan Distance</h3> <p>Another way to measure distance from \(a\) to \(b\) is to follow a path parallel to the axis. For example, in the image below, we first move parallel to the y-axis for 1 units, followed by a parallel path along the x-axis for 1 units, and then sum the total path length. This type of “gridded” path is called Manhattan distance (after the gridded road pattern of Manhattan) or \(L_1\) distance. Mathematically, it can be expressed as:</p> \[L_1 = \sum_{i=1}^n |a_i - b_i|\] <h3 id="angular-distance">Angular Distance</h3> <p>For angular distance \((\theta)\), we treat points \(a\) and \(b\) as two vectors originating from the origin \((0,0)\). The angular distance is simply the angle between the two vectors, expressed as:</p> \[\theta = \arccos \left( \frac{a \cdot b}{\|a\| \|b\|} \right)\] <p>In machine learning, angular distance is more commonly referred to as <em>cosine similarity</em> (measured as the cosine of the angle). In spectral analysis, this is often called <em>Spectral Angle Mapping (SAM)</em> and is widely used for spectral matching. Mathematically, angular distance is only valid as a metric if we normalize our data to unit vectors. For unit vectors, this measurement gives the same result as Euclidean distance after normalizing the data.</p> <p>From these definitions of the three distance metrics, lets return to our initial visualization (Image 1): Is point <em>a</em> closer to point <em>b</em> than to point <em>c</em> ? Again, the answer depends on the distance metric. Using Euclidean and Manhattan distances, this statement holds true. However, with angular distance, it is actually false, while <em>a</em> and <em>b</em> have a non-zero angular distance, <em>a</em> and <em>c</em> actually have an angular distance of \(0\). So using this metric, <em>c</em> is closer to <em>a</em> compared to <em>b</em>! I think this simple example already ilustrate how crutial it is to understand the distinction between different distance metrics and in which cases using one is prefered compared to the others.</p> <h2 id="example-case-linear-spectral-unmixing">Example Case: Linear Spectral Unmixing</h2> <p>To illustrate cases in which each distance metric is more appropriate, let’s use linear spectral unmixing as an example. Spectral unmixing is an important analytical technique in remote sensing used to decompose mixed pixel values into their constituent spectral signatures, known as endmembers, and their respective abundances. This process is essential for applications requiring sub-pixel level analysis, such as land cover classification, resource exploration, and environmental monitoring.</p> <p>An important aspect of spectral unmixing is the choice of distance metrics, which measure the similarity or dissimilarity between observed pixel spectra and modeled spectra. The selection of an appropriate metric significantly impacts the accuracy and performance of unmixing algorithms. Understanding these metrics helps optimize the unmixing process, especially in scenarios with high spectral variability or noise.</p> <p>Assuming a linear mixture model, a mixed spectrum of several different endmembers is defined as:</p> \[\mathbf{y} = \mathbf{E} \mathbf{a} + \mathbf{n}\] <p>where:</p> <ul> <li>\(\mathbf{y}\) is the observed spectrum,</li> <li>\(\mathbf{E}\) is the endmembers matrix,</li> <li>\(\mathbf{a}\) is the abundance vector,</li> <li>\(\mathbf{n}\) represents noise.</li> </ul> <p>In this equation, \(\mathbf{y}\) is known from observation, and for simplicity, we assume that a matrix of possible endmembers \(\mathbf{E}\) is also known, and noise \(\mathbf{n}\) is negligible.</p> <p>The goal is to solve for \(\mathbf{a}\) by minimizing the difference between the modeled spectrum \(\mathbf{E} \mathbf{a}\) and the observed spectrum \(\mathbf{y}\), under the conditions that all values of \(\mathbf{a}\) are non-negative and summed-to-one. This may achieved by solving this optimization problem:</p> \[\min_{\mathbf{a}} \; D(\mathbf{y} - \mathbf{E} \mathbf{a})\] <p>subject to:</p> \[\mathbf{a}_i \geq 0 \quad \text{and} \quad \sum_{i=1}^{n} \mathbf{a}_i = 1\] <p>This is where distance metrics \(D(•)\) come into play. The difference we are trying to minimize can be calculated using different distance metrics. Different distance metrics can lead to different results.</p> <p>Now, let’s run some tests under various simplified scenarios to see how each distance metric performs.</p> <h3 id="test-01-mixture-with-gaussian-noise">Test 01: Mixture with Gaussian Noise</h3> <p>For the first test, suppose we have four mineral endmembers (example taken from USGS Spectral Library), as shown below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_image_3_four_endmembers-480.webp 480w,/assets/img/post_1_image_3_four_endmembers-800.webp 800w,/assets/img/post_1_image_3_four_endmembers-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_image_3_four_endmembers.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Endmember spectra for Calcite, Kaolinite, Muscovite, and Quartz </div> <p>We’ll generate 1000 synthetic mixtures with the following conditions:</p> <ol> <li>The mixtures follow the linear mixture model equation.</li> <li>Noise is normally distributed with a mean of \(0\) and a standard deviation chosen randomly between \(10^{-5}\) and \(10^{-3}\).</li> </ol> <p>The accuracy of the spectral unmixing using the three distance metrics are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_first_test-480.webp 480w,/assets/img/post_1_first_test-800.webp 800w,/assets/img/post_1_first_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_first_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p>In this case, <strong>Euclidean distance</strong> clearly outperforms the other two metrics, as it is well-suited for data with normally distributed noise. Under these conditions, minimizing Euclidean distance is equivalent to <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood estimation</a>.</p> <h3 id="test-02-mixture-with-random-spikes">Test 02: Mixture with Random ‘Spikes’</h3> <p>For the second test, instead of adding normal noise, this time we add random “spikes,” where each wavelength band has a \(1\%\) chance of being randomly increased or decreased by a value between \(0.05\) and \(0.2\). While this type of noise is not common in remote sensing or spectroscopy, it will help us illustrate the strengths of Manhattan distance. The accuracy of the spectral unmixing of these synthetic mixtures are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_second_test-480.webp 480w,/assets/img/post_1_second_test-800.webp 800w,/assets/img/post_1_second_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_second_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p>Here, <strong>Manhattan distance</strong> outperforms the other metrics. Manhattan distance is known to be more robust to extreme outliers than Euclidean distance, which squares the error term, making it sensitive to outliers. In contrast, Manhattan distance only takes the absolute value of location differences, making it less affected by outliers.</p> <h3 id="test-03-mixture-with-brightness-difference">Test 03: Mixture with Brightness Difference</h3> <p>While random spikes in reflectance values may not be common in spectroscopy or remote sensing, brightness differences and inaccurate endmembers spectra are issues that often arise with real datasets. To illustrate this problem, let’s randomly add random constant between \(-0.2\) to \(0.2\) to the mixture. This experiment is a simplified simulation of real world scenario where different terrains and illumination condition might cause the sensor to recieve the signal with different intensity if not corrected appropriately.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_third_test-480.webp 480w,/assets/img/post_1_third_test-800.webp 800w,/assets/img/post_1_third_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_third_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p>In this case, <strong>angular distance</strong> (or SAM) has the lowest error, as it essentially ignores magnitude (brightness) differences and focuses on the shape of the spectra. To illustrate further, take a look at the two spectra below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_kaolinite-480.webp 480w,/assets/img/post_1_kaolinite-800.webp 800w,/assets/img/post_1_kaolinite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_kaolinite.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Two kaolinite spectra with different brightness </div> <p>The two spectra above have identical shape but different brightness values. These two spectra may be considered different by Manhattan and Euclidean distances, but angular distance would see them as identical. This feature is one reason why angular distance is widely used in remote sensing applications, where brightness differences due to terrains and illuminations effects are common.</p> <h3 id="test-04-a-more-complicated-mixture">Test 04: A More Complicated Mixture</h3> <p>Now let’s consider a more complex scenario. We will use a larger spectral library, selecting 10 minerals from the USGS spectral library. To generate a mixture, we will randomly select between 2 to 4 endmembers from this library. Since the actual selected minerals are unknown, all 10 possible endmembers will be included in the unmixing process. This situation, where many variables (10 possible endmembers) are considered, but only a few (2–4 endmembers) are non-zero, is known as a <em>sparsity problem.</em></p> <p>Typically, sparsity issues are addressed by incorporating regularization terms into the optimization function. However, for this simple trial, we will not include any regularization and will apply the same spectral unmixing method used in the previous three tests. This allows us to focus solely on the challenges posed by increased complexity in the spectral library.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_10_endmembers-480.webp 480w,/assets/img/post_1_10_endmembers-800.webp 800w,/assets/img/post_1_10_endmembers-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_10_endmembers.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. 10 Endmembers Spectra </div> <p>We will also add an gaussian noise, uniform noise, gamma noise, poisson noise, and random constant as brightness modifier. The image below ilustrate each of the noises:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_noises-480.webp 480w,/assets/img/post_1_noises-800.webp 800w,/assets/img/post_1_noises-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_noises.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 9. Each noises added to the mixture. </div> <p>The unmixing accuracy results are shown in histograms below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_forth_test-480.webp 480w,/assets/img/post_1_forth_test-800.webp 800w,/assets/img/post_1_forth_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_forth_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 10. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p><strong>Manhattan distance</strong> performed exceptionally well in this last case study, which probably can be attributed to its robustness to ouliers and more varying noise types. Despite this, its non-differentiable nature (since its an absolute value function) makes it less appealing for gradient-based optimization algorithms, especially for larger, more complex datasets. For this particular test, Manhattan distance takes 43 seconds for 1,000 data points, compared to 14 seconds for Euclidean distance and 11 seconds for angular distance.</p> <p>This study highlights the importance of carefully selecting the appropriate distance metric based on the nature of the data and the problem being addressed. While Euclidean distance is often the default choice, Manhattan distance or angular distance can outperform it in specific scenarios, as demonstrated in the experiments above.</p> <p>On a final note, it’s important to emphasize that the unmixing approach presented here operates under the assumption of a perfect model and data. In real-world scenarios, this is rarely the case, so we should generally expect the results to be slightly less accurate. However, it’s crucial to acknowledge that spectral unmixing inherently involves significant uncertainty. A more robust approach to address this uncertainty is to adopt a <em>Bayesian framework</em>, which offers a natural way to model such problems. This will be the topic of our <a href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/">next discussion</a>.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Comparison between Euclidean distance, Manhattan distance, and angular distance in spectral unmixing of mineral endmembers.]]></summary></entry><entry><title type="html">Using Raster Calculator in QGIS GUI and Python Console to Make SR Blocks</title><link href="https://nasirlukman.github.io/blog/2021/Raster-Calculator/" rel="alternate" type="text/html" title="Using Raster Calculator in QGIS GUI and Python Console to Make SR Blocks"/><published>2021-08-08T23:36:10+00:00</published><updated>2021-08-08T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2021/Raster-Calculator</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2021/Raster-Calculator/"><![CDATA[<p>Raster Calculator is a robust way to execute a map algebra operation on raster image(s) using a user-friendly calculator-like format. It is a commonly available feature on any GIS software such as ArcGIS and QGis. Raster itself is one of the commonly used data formats in GIS which stores data in cells or pixels and organizes it into rows and columns (position) and each cell or pixel contains a value that represents certain information (visualized as colors). We can use a raster calculator to exploit these array-like properties of raster data to run any map algebra operation on each pixel in a robust way.</p> <p>The benefit of calculating SR in a raster calculator, rather than in any build-up function that your software already provides, is the flexibility of the operation that you can run. Now today we will try to perform a calculation to generate raster data containing a stripping ratio value of each pixel area given the topographic elevation data, and roof and floor elevation of each seam (we will use two seams for this example, let’s name it Seam A and Seam B).</p> <h2 id="raster-calculator-with-qgis-gui">Raster Calculator with QGIS GUI</h2> <h3 id="data-preparation">Data Preparation</h3> <p>Readily available raw elevation data is usually stored in a vector format of in [x,y,z] point text format; so first, we need to convert our data format. If our points data are already in a grid structure, we can perform conversion directly with vector to raster which in QGIS can be found in <strong><em>Raster&gt;Conversion&gt;Rasterized(Vector to Raster)</em></strong>. If our data point is not neatly and densely structured then it becomes an interpolation problem. There are a lot of interpolation methods that we can pick, depending on our initial data and our desired products. For this purpose, I will use IDW Interpolation that in QGIS can be found in <em>**Processing&gt;Toolbox&gt;Interpolation&gt;IDW Interpolation **</em>. Below is an example of IDW interpolation from my topography data.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_6_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_6_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_6_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_6_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. IDW interpolation of topo data points. </div> <p>After all our data layers are ready in raster format, it is always a good idea to check the relationship of our datasets to get a better feel of what we are dealing with, for this example, we will try to make quick cross-sections. There is a very useful plugin in QGIS that I like to use to make a cross-section called <a href="https://plugins.qgis.org/plugins/profiletool/">Profile Tool</a>. You can install this plugin in <strong><em>Plugins&gt;Manage and install plugins…</em></strong> and search for Profile Tool in the search bar. In our data example today, we can see that we have two seams with pretty simple geometry that have a northwest dip direction.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_8_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_8_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_8_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_8_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Quick inspection of the cross section with QGIS Profile Tool. </div> <h3 id="using-raster-calculator">Using Raster Calculator</h3> <p>After all of our data are ready in raster format, we can start to write our expression in the raster calculator. First, open up the raster calculator in <strong><em>Raster&gt;Raster calculator…</em></strong>. The GUI of the raster calculator is pretty straightforward and easy to get used to. every operation, variables, field, layer, etc are stored in the graphic interface so we can just write in using our mouse if we want. raster calculator syntax is based on <a href="https://desktop.arcgis.com/en/arcmap/latest/extensions/spatial-analyst/map-algebra/what-is-map-algebra.htm">map algebra</a>, which is basically an easier-to-read type of algebra.</p> <p>now if we want to make SR blocks, first we have to figure out the expression to calculate it. The simplest definition of SR is just the ratio between overburden and coal or any other valuable material of interest, both on its respective cost units. In this example, it is the ratio between overburden in bulk cubic meters (bcm) to coal in ton.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_12_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_12_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_12_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_12_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. A simple equation to compute SR blocks </div> <p>We can specify the resolution of our output raster by filling the column and row input with this formula:</p> <ul> <li>Column = (Xmax-Xmin)/desired resolution</li> <li>Row = (Ymax-Ymin)/desired resolution</li> </ul> <p>There is a good text indicator at the bottom of the window that tells us whether the expressions that we put are valid or invalid. If the expression is valid, then we can proceed and press OK, if it is invalid, then we need to check and fix our expression.</p> <p>Below is the results of our calculation above after I adjusted the Legends in layer properties.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_14_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_14_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_14_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_14_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. SR block results. </div> <p>After we are familiar with how the raster calculator works, we can run any expression that we want, for our next example, We will try to calculate operating income blocks by subtracting operating cost from revenue.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_16_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_16_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_16_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_16_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Estimating operating income blocks using price and cost assumptions. </div> <p>This is the result of that operation:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_18_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_18_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_18_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_18_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Estimated operation income blocks (in USD). </div> <h2 id="using-raster-calculator-in-qgis-python-console">Using Raster Calculator in QGIS Python Console</h2> <p>You can press Ctrl+Alt+P to open your QGIS python console. This code below will do just about the same as what we did previously in Qgis GUI, but with less clicking and layer rendering, and it’s reusable for your future needs. It is especially useful if you are experimenting with various expressions and input since you can tweak it much faster and easier. You can even modify this code a little bit and write a loop that will execute various expressions and save each of the results into different output files.</p> <blockquote> <p>If you want to reuse this code below you need to change the path and output variable, and all the parameters inside QgsRasterCalculator depending on your needs.</p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span>

<span class="n">path</span><span class="o">=</span><span class="sh">'</span><span class="s">C:/test/</span><span class="sh">'</span>
<span class="n">os</span><span class="p">.</span><span class="nf">chdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">file_list</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">lyr_dict</span><span class="o">=</span><span class="p">{}</span>
<span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">.tif</span><span class="sh">'</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">file_name</span><span class="o">=</span><span class="nb">file</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>
        <span class="n">layer_dict</span><span class="p">[</span><span class="n">file_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nc">QgsRasterLayer</span><span class="p">(</span><span class="n">path</span><span class="o">+</span><span class="nb">file</span><span class="p">),</span> <span class="n">file_name</span><span class="o">+</span><span class="sh">'</span><span class="s">@1</span><span class="sh">'</span><span class="p">]</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">path</span><span class="o">+</span><span class="sh">'</span><span class="s">block_SR.tif</span><span class="sh">'</span>
<span class="n">entries</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">lyr</span> <span class="ow">in</span> <span class="n">lyr_dict</span><span class="p">:</span>
    <span class="n">ras</span> <span class="o">=</span> <span class="nc">QgsRasterCalculatorEntry</span><span class="p">()</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">ref</span> <span class="o">=</span> <span class="n">lyr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">raster</span> <span class="o">=</span> <span class="n">lyr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">bandNumber</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">entries</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">ras</span><span class="p">)</span>
    <span class="n">index</span><span class="o">+=</span><span class="mi">1</span>
    
<span class="n">calc</span> <span class="o">=</span> <span class="nc">QgsRasterCalculator</span><span class="p">(</span><span class="sh">'</span><span class="s">(((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1))*10*1.3*65)</span><span class="se">\
</span><span class="s">                           -((((topo@1 - floor_b@1)-((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1)))*10*2.2)</span><span class="se">\
</span><span class="s">                           +1.135*(((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1))*10*1.3*15))</span><span class="sh">'</span><span class="p">,</span> 
                           <span class="n">output</span><span class="p">,</span> <span class="sh">'</span><span class="s">GTiff</span><span class="sh">'</span><span class="p">,</span> <span class="n">topo</span><span class="p">.</span><span class="nf">extent</span><span class="p">(),</span> <span class="nf">int</span><span class="p">(</span><span class="n">topo</span><span class="p">.</span><span class="nf">width</span><span class="p">()</span><span class="o">/</span><span class="mi">10</span><span class="p">),</span> <span class="nf">int</span><span class="p">(</span><span class="n">topo</span><span class="p">.</span><span class="nf">height</span><span class="p">()</span><span class="o">/</span><span class="mi">10</span><span class="p">),</span> <span class="n">entries</span><span class="p">)</span>
<span class="n">calc</span><span class="p">.</span><span class="nf">processCalculation</span><span class="p">()</span>
</code></pre></div></div> <p>Here is a quick breakdown of the code above:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span>

<span class="n">path</span><span class="o">=</span><span class="sh">'</span><span class="s">C:/test/</span><span class="sh">'</span>
<span class="n">os</span><span class="p">.</span><span class="nf">chdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">file_list</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">lyr_dict</span><span class="o">=</span><span class="p">{}</span>
<span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">.tif</span><span class="sh">'</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">file_name</span><span class="o">=</span><span class="nb">file</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>
        <span class="n">layer_dict</span><span class="p">[</span><span class="n">file_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nc">QgsRasterLayer</span><span class="p">(</span><span class="n">path</span><span class="o">+</span><span class="nb">file</span><span class="p">),</span> <span class="n">file_name</span><span class="o">+</span><span class="sh">'</span><span class="s">@1</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p>this code block will work to open up every raster (<em>.tif</em> extension) file in your working directory, so be sure to put all your needed raster files into one directory. After that, the loop will write those files into a layer dictionary. The dictionary will contain the name of the file without its extension as a key and its <code class="language-plaintext highlighter-rouge">QgsRasterLayer</code> class and names (which is the file name + <em>‘@1’</em>). This is the naming convention for a raster layer in which the number after <em>’@’</em> specifies the number of bands that the raster contains (in our case it is 1).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">output</span> <span class="o">=</span> <span class="n">path</span><span class="o">+</span><span class="sh">'</span><span class="s">block_SR.tif</span><span class="sh">'</span>
<span class="n">entries</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">lyr</span> <span class="ow">in</span> <span class="n">lyr_dict</span><span class="p">:</span>
    <span class="n">ras</span> <span class="o">=</span> <span class="nc">QgsRasterCalculatorEntry</span><span class="p">()</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">ref</span> <span class="o">=</span> <span class="n">lyr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">raster</span> <span class="o">=</span> <span class="n">lyr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">bandNumber</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">entries</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">ras</span><span class="p">)</span>
    <span class="n">index</span><span class="o">+=</span><span class="mi">1</span>
</code></pre></div></div> <p>In this block, we are using a <code class="language-plaintext highlighter-rouge">QgsRasterCalculatorEntry</code> class reference to create a list entry for every layer and its attributes such as naming reference, raster layer variable, and its band number from our <code class="language-plaintext highlighter-rouge">lyr_dict</code> dictionary. After that, we put all of our <code class="language-plaintext highlighter-rouge">QgsRasterCalculatorEntry</code> classes into a list called <code class="language-plaintext highlighter-rouge">entries</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">calc</span> <span class="o">=</span> <span class="nc">QgsRasterCalculator</span><span class="p">(</span><span class="sh">'</span><span class="s">(((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1))*10*1.3*65)</span><span class="se">\
</span><span class="s">                           -((((topo@1 - floor_b@1)-((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1)))*10*2.2)</span><span class="se">\
</span><span class="s">                           +1.135*(((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1))*10*1.3*15))</span><span class="sh">'</span><span class="p">,</span> 
                           <span class="n">output</span><span class="p">,</span> <span class="sh">'</span><span class="s">GTiff</span><span class="sh">'</span><span class="p">,</span> <span class="n">topo</span><span class="p">.</span><span class="nf">extent</span><span class="p">(),</span> <span class="nf">int</span><span class="p">(</span><span class="n">topo</span><span class="p">.</span><span class="nf">width</span><span class="p">()</span><span class="o">/</span><span class="mi">10</span><span class="p">),</span> <span class="nf">int</span><span class="p">(</span><span class="n">topo</span><span class="p">.</span><span class="nf">height</span><span class="p">()</span><span class="o">/</span><span class="mi">10</span><span class="p">),</span> <span class="n">entries</span><span class="p">)</span>
<span class="n">calc</span><span class="p">.</span><span class="nf">processCalculation</span><span class="p">()</span>
</code></pre></div></div> <p>This is where the actual calculation occurs. <code class="language-plaintext highlighter-rouge">QgsRasterCalculator</code> takes the following parameters to run:</p> <ul> <li>expression: which can be any expression you like, written in string format</li> <li>output file path also in string. Be sure to specify the extension behind the file name</li> <li>output format which is also in string. The most commonly used file format is GTiff for <em>.tif</em> file</li> <li>the extent from the output file which is usually the same as the input extent, or any numbers depending on your needs</li> <li>nrows and ncols which define the total number of rows and columns on a given extent. For this example, since I want a 10-meter resolution raster as output and I have a 1-meter resolution for the input, I just divided my input height and width by ten</li> <li><code class="language-plaintext highlighter-rouge">entries</code> list</li> </ul> <p>Afterward, you can execute your calculation by using <code class="language-plaintext highlighter-rouge">processCalculation( )</code> function from <code class="language-plaintext highlighter-rouge">QgsRasterCalculator</code>. And the results will be the same as with our example using the GUI above.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Raster Calculator is a very useful tool to have at our disposal. Let's try it to make SR blocks]]></summary></entry></feed>