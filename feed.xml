<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://nasirlukman.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nasirlukman.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-10T15:04:20+00:00</updated><id>https://nasirlukman.github.io/feed.xml</id><title type="html">Earth.etc</title><subtitle></subtitle><entry><title type="html">Exploratior Data Analysis (EDA) for Hyperspectral Imagery</title><link href="https://nasirlukman.github.io/blog/2024/EDA/" rel="alternate" type="text/html" title="Exploratior Data Analysis (EDA) for Hyperspectral Imagery"/><published>2024-12-09T23:36:10+00:00</published><updated>2024-12-09T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/EDA</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/EDA/"><![CDATA[<p>One of the main characteristics of hyperspectral imagery is its high-dimensional data (i.e., a high number of spectral bands). This type of data, while providing a higher level of detail in the spectral characteristics of the material we observe, also raises challenges in handling the data effectively. Higher dimensional data means it becomes more challenging to extract meaningful information for analysis. These challenges are often referred to as <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">the curse of dimensionality</a>.</p> <p>In this post, I will show my approach in conducting exploratory data analysis (EDA) on a hyperspectral imagery with the goal of deriving meaningful geological information from the data. In this post, we will assume no geological prior knowledge of the region (although nowadays that is hardly the case, especially for Earth’s surface). We will rely solely on the hyperspectral data itself and some basic spectrometry and geology knowledge.</p> <p>We will use an airborne hyperspectral image covering the shortwave infrared range (SWIR) from ~2000 nm to ~2400 nm over an area of about 10 km² in an arid region. All of the analysis performed in this post is done using standard scientific libraries in the Python environment and an open-source software called <a href="http://hyppy.is-great.org/?i=1">Hyppy</a> developed at the University of Twente.</p> <h2 id="1-basic-visualization">1. Basic visualization</h2> <p>The obvious first step in EDA of hyperspectral imagery is to visualize the image. We can choose to visualize the image in grayscale for selected wavelength bands of interest and create false color composites to observe the main structural characteristics of the region.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_composite-480.webp 480w,/assets/img/post_4_composite-800.webp 800w,/assets/img/post_4_composite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_composite.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. False color composite image </div> <p>My initial interpretation of the region is that it is most likely mainly composed of sedimentary bedding influenced by a fault with apparent left-lateral movement, based on the drag fold formed along the fault lines.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_basic_interpretation-480.webp 480w,/assets/img/post_4_basic_interpretation-800.webp 800w,/assets/img/post_4_basic_interpretation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_basic_interpretation.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Basic geological feature initial interpretation from the image </div> <p>When it comes to mineralogical/geological interpretations, I find it helpful to begin with a very broad interpretation. Knowing that the region is likely predominantly composed of sedimentary rocks already provides significant constraints for further interpretation, which may be very useful in the next phase. We may revisit this interpretation later if further analysis or data does not support it.</p> <h2 id="2-getting-to-know-the-data">2. Getting to know the data</h2> <p>It is very important to familiarize ourselves with the data we are working with. At this stage, I typically inspect the spectra of some pixels that stand out in the visualization and get a sense of the variation in spectral responses present in the image. For this, I often use specialized software such as <a href="https://www.nv5geospatialsoftware.com/Products/ENVI">ENVI</a>, <a href="https://plugins.qgis.org/plugins/temporalprofiletool/">QGIS with Spectral Profile Plugin</a>, or <a href="http://hyppy.is-great.org/?i=1">Hyppy</a>. The later two is an open source program which are available for free.</p> <p>At this stage, we can also plot a histogram of the mean reflectance values of the image to see how many visible clusters are present across the spectral bands. Note that the reflectance value are in the sacale of 10,000.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_mean_histogram-480.webp 480w,/assets/img/post_4_mean_histogram-800.webp 800w,/assets/img/post_4_mean_histogram-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_mean_histogram.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Histogram of mean albedo of each pixel in the image showing two main albedo class. </div> <p>From the histogram, we can decide on a threshold to classify our pixels based on their average albedo. This is generally equivalent to classifying the image into bright-colored minerals and dark-colored minerals (albeit in the shortwave infrared range, not in the visible range). Typically, low-albedo minerals in SWIR also appear dark in visible light. Our first classification results are shown below which shows the most basic classification of the image we have: reflective vs absortive minerals.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_albedo_class-480.webp 480w,/assets/img/post_4_albedo_class-800.webp 800w,/assets/img/post_4_albedo_class-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_albedo_class.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Map showing the distribution of two albedo class. </div> <h2 id="3-pca-and-k-means-clustering">3. PCA and K-Means Clustering</h2> <p>Since the number of pixels and spectral bands is often too high to handle for meaningful interpretation, dimensional reduction and data clustering methods can be useful for grouping data into clusters of spectra based on their spectral similarity which can make further analysis to be easier. While we can directly apply K-Means clustering to the data, this is not usually recommended. Each dimension of our data carries varying levels of information and noise. For high-dimensional data, only a few dimensions typically contain significant information, while others only add noise to the algorithm.</p> <p>PCA is a dimensionality reduction method that organizes data based on its variability in the data space, corresponding to its information content. It identifies the directions (principal components) where the data varies the most and projects the data onto these axes in descending order of variance. The downside is that the data is transformed into an orthogonal space where the units lose their original physical meaning. In this example, we visualize the first 10 principal components and observe that by the 10th component, there is minimal discriminatory power. Therefore, we reduce the dimensionality from 55 to 10 principal components, preserving the most significant information, and use this result as the input for K-Means clustering.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_PCA-480.webp 480w,/assets/img/post_4_PCA-800.webp 800w,/assets/img/post_4_PCA-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_PCA.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. First 10 PCA images. </div> <p>The K-Means algorithm clusters data points based on their similarities. It assigns each point to one of K clusters based on its proximity to the cluster centroids, iterating to minimize variance within clusters. Similarities are computed using Euclidean distance, which I explained in a <a href="https://nasirlukman.github.io/blog/2024/distance/">previous post</a>.</p> <p>K-Means requires the user to define the number of clusters (\(K\) ). The elbow method can help determine this, by plotting the within-cluster sum of squares (WCSS) for various K values. The optimal number of clusters is where the WCSS curve starts to saturate, resembling an elbow. For this dataset, the optimal number of clusters is 3, as shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_WCSS-480.webp 480w,/assets/img/post_4_WCSS-800.webp 800w,/assets/img/post_4_WCSS-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_WCSS.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. WCSS result for cluster values ranging from 1 to 11. </div> <p>Using \(K=3\) , we perform clustering, with the results shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_cluster_map-480.webp 480w,/assets/img/post_4_cluster_map-800.webp 800w,/assets/img/post_4_cluster_map-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_cluster_map.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. K-Mean clustering result from the first 10 principle component of our hyperspectral images. </div> <p>We then can transform the pixels back from PCA space to the original data space to examine the average mean spectra of each cluster:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_cluster_spectra-480.webp 480w,/assets/img/post_4_cluster_spectra-800.webp 800w,/assets/img/post_4_cluster_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_cluster_spectra.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. Average spectra of each cluster. </div> <p>Compared to our initial simple classification by mean albedo, this approach offers more nuance. For instance, the high-albedo reflectance now separates into two distinct spectral shapes, while the low-albedo minerals remain a single cluster. To further refine the low-albedo cluster, we could mask the high-albedo pixels and repeat the process. However, for this example, I am satisfied with these results. At this stage, I observe that the low-albedo cluster has largely featureless spectra (likely consisting of minerals without distinct features in the SWIR range), making further attempt for meaningful subdivision challenging.</p> <h2 id="4-endmember-extraction-and-linear-spectreal-unmixing">4. Endmember Extraction and Linear Spectreal Unmixing</h2> <p>Since our average spectra likely represent complex mixtures, it is useful to extract their possible pure spectral shapes. At this stage, we have decided to categorize our image into three distinct classes. We will use the <a href="">N-FINDR</a> algorithm with \(n=3\) to extract the three purest endmembers from our image. The data distribution in 2D PCA space and the extracted endmember pixels are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_nfindr_plot-480.webp 480w,/assets/img/post_4_nfindr_plot-800.webp 800w,/assets/img/post_4_nfindr_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_nfindr_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 9. Data shape in reduced 2 PCA dimension showing clear linear relationship between three endmembers. Red star is the vertex of the triangle which corespond to the purest pixel on the image. </div> <p>This is one of the most texbook like 2D PCA representations of a real hyperspectral image I have encountered. The 2D simplex (triangle) is almost perfectly formed, indicating that our entire dataset can be described as a linear combination of three endmember spectra. These endmembers therefore must be the pixel that correspond to the vertices of the triangle. After transforming the extracted endmembers back into the original data space, we observe their pure spectral signatures:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_endmember_spectra-480.webp 480w,/assets/img/post_4_endmember_spectra-800.webp 800w,/assets/img/post_4_endmember_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_endmember_spectra.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 10. Spectra of the purest pixels (endmembers). </div> <p>This is a good point to start naming our classes properly. You could match the spectra to a spectral library using a feature-matching algorithm to identify the mineral spectra most similar to the extracted endmembers. For simplicity, I use broad categorizations. I define the first spectrum as the <strong>Low-Albedo Mineral Group,</strong> likely dominated by plagioclase or mafic minerals, interpreted as part of a volcanic rock complex. The second spectrum corresponds to the <strong>Hydroxyl Mineral Group</strong>, based on its \(AlOH\) feature around 2200 nm, likely related to the occurance of white micas or clays, interpreted as part of siliciclastic rocks such as arkose. The third spectrum represents the <strong>Carbonate Mineral Group</strong>, with a \(CO_3\) feature near 2300 nm, likely from calcareous sedimentary rocks like limestone or calcareous sandstone/siltstone.</p> <p>With our pure endmembers identified, we can perform linear spectral unmixing to estimate their relative abundances. At this stage of analysis, I prefer to not constrain the unmixing result to be strictly sum-to-one since there are still many unknowns. hese results are interpreted as “unconstrained abundances,” distinct from “absolute abundances,” which have more physical meaning. Below are the unconstrained abundance maps for each endmember:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_unmixing_result-480.webp 480w,/assets/img/post_4_unmixing_result-800.webp 800w,/assets/img/post_4_unmixing_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_unmixing_result.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 11. Unconstrained abundance of the three endmembers. </div> <p>Since we are dealing with only three mineral groups, we can assign each abundance to an RGB channel to produce a ternary representation of the unconstrained abundances:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_unmixing_result_ternary_with_legend-480.webp 480w,/assets/img/post_4_unmixing_result_ternary_with_legend-800.webp 800w,/assets/img/post_4_unmixing_result_ternary_with_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_unmixing_result_ternary_with_legend.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 12. Ternary map of the unconstrained abundance of the three endmembers. </div> <p>It is important to note that this ternary representation is purely for visualization and does not strictly correspond to the absolute abundance of each endmember.</p> <h2 id="5-minimum-wavelength-mapping">5. Minimum Wavelength Mapping</h2> <p>Many distinct hyroxyl and carboante minerals can be distinguished based on the subtle difference in the wavelength position of their deepest absorption feature. Using a method called minimum wavelength mapping, we can detect these subtle shifts and potentially refine our classification to include specific members of the carbonate and hydroxyl mineral groups. The first step is to detect the wavelength of the deepest absorption feature across the entire spectral range.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_minwav-480.webp 480w,/assets/img/post_4_minwav-800.webp 800w,/assets/img/post_4_minwav-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_minwav.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 13. Minimum wavelength position histogram for the whole spectral range. </div> <p>We observe at least three distinct distributions of \(AlOH\) absorption features and five distributions of \(CO_3\) absorption features. For the \(AlOH\) group, the lowest feature observed at 2195 nm likely corresponds to lithium-rich white mica, such as lepidolite. The other two \(AlOH\) features, around 2210 nm and 2220 nm, likely correspond to \(Al\)-rich white mica, such as muscovite, with minor geochemical differences attributed to variations of geochemistry and temperature of the mineral formation.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_AlOH_minwav_legend-480.webp 480w,/assets/img/post_4_AlOH_minwav_legend-800.webp 800w,/assets/img/post_4_AlOH_minwav_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_AlOH_minwav_legend.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 14. Minimum wavelength map of hydroxile features. </div> <p>For the CO3 group, there is significant variation in the deepest feature wavelengths. Although identifying specific minerals at this stage is challenging, the observed ranges suggest these features are unlikely to correspond to calcite, the most common carbonate mineral. For instance, features around 2335 nm are commonly associated with siderite, 2320 nm with dolomite, and 2305 nm with magnesite.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_CO3_minwav_legend-480.webp 480w,/assets/img/post_4_CO3_minwav_legend-800.webp 800w,/assets/img/post_4_CO3_minwav_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_CO3_minwav_legend.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 15. Minimum wavelength map of carbonate features. </div> <p>It is essential to note that pinpointing specific minerals requires further analysis. While we cannot yet confirm the mineral species, the variations in these wavelength ranges are likely related to mineralogical differences. Therefore, the spatial distribution of these distinct groups remains valid, even when we are still uncertain with the definitive mineral identifications.</p> <h2 id="6-further-comments">6. Further comments</h2> <p>In this post, I demonstrate typical EDA steps for hyperspectral analysis for geological investigations in an unfamiliar region. These EDA steps serve to familiarize us with the data and provide a solid foundation for further investigation. However, complementary datasets, such as VNIR and LWIR spectral data, could significantly enhance geological and mineralogical studies by increasing discrimination power. Additionally, methods beyond infrared spectrometry, such as gamma-ray spectrometry, offer valuable tools for geological mapping, particularly in arid regions.</p> <p>Here we see that SWIR hyperspectral data alone can reveal a wealth of information, even without incorporating additional datasets, prior knowledge of the region, or advanced analysis techniques. In practice, prior knowledge of the study area—such as geological maps or models—is often available and can effectively guide the analysis. Furthermore, integrating other remote sensing data and, more importantly, incorporating fieldwork data, even from sparse sampling points, is crucial for validating and refining the results.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[My typical approach on EDA for a new hyperspectral projects for geological investigations. Includes method such as PCA, K-Means, N-FINDR, Linear Spectral Unmixing, and Minimum Wavelength Mapping.]]></summary></entry><entry><title type="html">Endmember Extraction from Hyperspectral Imagery Using N-FINDR</title><link href="https://nasirlukman.github.io/blog/2024/nfindr/" rel="alternate" type="text/html" title="Endmember Extraction from Hyperspectral Imagery Using N-FINDR"/><published>2024-11-27T23:36:10+00:00</published><updated>2024-11-27T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/nfindr</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/nfindr/"><![CDATA[<p>Hyperspectral imagery often contains mixed pixels—pixels that represent areas with more than one class of interest. Given the complexity of the scenes, and the rigid structure of images, it is unrealistic to assume every pixel to correspond to a single class. These classes could include features like water, trees, shrubs, grass, soil, or roads when performing land cover classification using satellite or airborne imagery. In earth science, the class of interest often is minerals that forms rocks. In any way, trying to find the purest pixels , or <em>endmembers</em>, of each class in our image is something that often useful for further analysis.</p> <p>In this post, I’ll provide a brief overview of one endmember extraction algorithm reffered to as <em>N-FINDR</em>. But, before diving into the details of the algorithm, it is important to acknowledge the general limitations of endmember extraction algorithms:</p> <ol> <li><strong>Purity is not guaranteed</strong>: These algorithms don’t guarantee that the extracted spectra represent a pure spectra of specific class of interest. Instead, they identify the purest spectra present in the image.</li> <li><strong>Known number of endmembers</strong>: The number of endmembers in the image must be known beforehand. This can be estimated using domain expertise, auxiliary measurements, other algorithms, or trial and error.</li> <li><strong>Linear mixture model assumption</strong>: Most endmember extraction algorithms, including N-FINDR, assume a linear mixture model.</li> </ol> <h2 id="how-n-findr-works">How N-FINDR Works</h2> <p>The core idea of N-FINDR is simple yet clever: it identifies the vertices of the simplex formed by the data distribution in reduced dimensions. These vertices are the purest spectra present in the dataset. The general steps of the algorithm is as follows:</p> <ol> <li><strong>Reprojection</strong>: Reproject all pixels into a lower-dimensional space using an orthogonal transformation like Principle Component Analysis (PCA) or Minimum Noise Fraction (MNF). MNF is often preferred because it minimizes the influence of noise.</li> <li><strong>Dimensionality reduction</strong>: Reduce the dimensionality to the first \((n−1)\) components, where \(n\) is the number of endmembers. At this stage, the data points should lie inside an \((n-1)\) dimensional simplex.</li> <li><strong>Iterative vertex selection</strong>: <ul> <li>Randomly select \(n\) points and calculate the simplex’s volume (or area in 2D).</li> <li>Iteratively replace one vertex with another pixel. If the new simplex’s volume is larger, accept the replacement. Otherwise, reject it and try again.</li> </ul> </li> <li><strong>Termination</strong>: After a fixed number of iterations without improvement, the algorithm terminates, and the final set of pixels is taken as the endmembers.</li> <li><strong>Reprojection back</strong>: Reproject the selected pixels into the original dimensional space to obtain the endmember spectra.</li> </ol> <h2 id="synthetic-data-example">Synthetic Data Example</h2> <p>To illustrate, let’s consider an idealized case of 1,000 synthetic mixed pixels generated from three endmembers. Since we’re dealing with three endmembers, we reproject the data into its first two principal components. In this reduced space, the data points lie perfectly on a 2D simplex—a triangle as shown in the image below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_synthetic_mixture_MNF-480.webp 480w,/assets/img/post_3_synthetic_mixture_MNF-800.webp 800w,/assets/img/post_3_synthetic_mixture_MNF-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_synthetic_mixture_MNF.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. First two principal components of the synthetic mixture of three endmembers </div> <p>If each data point is a linear mixture of three pure endmembers, the endmembers will be located at the vertices of a triangular region, commonly referred to as a simplex. In this 2D example, identifying the simplex is relatively straightforward through visual inspection. However, as the number of endmembers increases, the dimensionality of the principal component representation also grows, making it increasingly difficult to determine the simplex visually. To overcome this challenge, we employ an iterative simplex-finding algorithm, which can be generalized to handle higher-dimensional data. The animation below illustrates the iterative process of refining the simplex:</p> <div style="display: flex; justify-content: center;"> <img src="/assets/img/post_3_nfindr_iterative.gif" alt="NFINDR"/> </div> <div class="caption"> Image 2. Ilustration of NFINDR algorithm in action </div> <h2 id="real-data-example">Real Data Example</h2> <p>In real-world scenarios, hyperspectral data is rarely as ideal as synthetic examples. Complex noise, non-linearities, and other factors often result in an imperfectly formed simplex. Nevertheless, algorithms like N-FINDR can still provide valuable output.</p> <p>For this example, we examine laboratory-acquired hyperspectral imagery of a sandstone sample. Below is a false-color composite image of the sample:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_rock_image-480.webp 480w,/assets/img/post_3_rock_image-800.webp 800w,/assets/img/post_3_rock_image-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_rock_image.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. False color composite hyperspectral iamge of a sandstone sample </div> <p>A quick inspection of the rock suggests that it is predominantly composed of three minerals. Thus, we assign \(n=3\) for this analysis. The results of the MNF transformation and the selected simplex vertices by N-FINDR are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_real_mixture_MNF-480.webp 480w,/assets/img/post_3_real_mixture_MNF-800.webp 800w,/assets/img/post_3_real_mixture_MNF-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_real_mixture_MNF.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. First two principal components of the sandstone rock sample. The red do represent the selected purest spectra by N-FINDR algorithm. </div> <p>Notice that the simplex is not perfectly formed, and the triangular structure appears slightly distorted. This suggests minor non-linear behavior in the actual mixtures. Additionally, some outliers lie outside the simplex, possibly influenced by accessory minerals. Such minerals, often present in small amounts, are common in natural rock samples and can affect the spectra of certain pixels. These influences may not be fully captured in a 2D representation.</p> <p>We can examine the spectra of the selected purest pixels by transforming them back to their original dimensions. Below are the resulting spectra for the three identified endmembers:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_pure_endmember_result-480.webp 480w,/assets/img/post_3_pure_endmember_result-800.webp 800w,/assets/img/post_3_pure_endmember_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_pure_endmember_result.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Resulting spectra of the three endmember from N-FINDR algorithm </div> <p>If you know your mineralogy and infrared spectroscopy you can immedietly recognize these minerals. The red spectra have a strong absorption feature in ~2200 nm region which related the \(Al-OH\) bonds of white mica/clay mienrals. The blue spectra have an absroption feature in ~2330 nm region related to \(CO_3\) bonds of carbonate minerals. The green and bright spectra represent quartz mineral. we still can see a very weak feature in ~2200 nm sugest that it is not 100% pure spectra and there is still a small influence of clay minerals.</p> <p>While these spectra are not perfectly pure, they are sufficiently representative to be useful for further analysis. For instance, as shown in our <a href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/">previous post</a>, we used these endmember spectra for spectral unmixing and achieved excellent results, with an RMSE of only 0.0186.</p> <p>To understand the spatial context, we can reshape the extracted data back into its original image structure to visualize the locations of the purest pixels:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_rock_image_with_pure_pixel-480.webp 480w,/assets/img/post_3_rock_image_with_pure_pixel-800.webp 800w,/assets/img/post_3_rock_image_with_pure_pixel-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_rock_image_with_pure_pixel.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. False color composite hyperspectral image of a sandstone sample along with its purest pixel location. </div> <p>This example shows that N-FINDR is a powerful and intuitive algorithm for endmember extraction. Despite its limitations, such as the need for prior knowledge of the number of endmembers and the assumption of a linear mixture model, it often still provides a usefull results.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[A brief overview, ilustration and case example of N-FINDR algorithm to extract mineral endmembers in hyperspectral imagery.]]></summary></entry><entry><title type="html">Bayesian Spectral Unmixing</title><link href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/" rel="alternate" type="text/html" title="Bayesian Spectral Unmixing"/><published>2024-11-24T12:36:10+00:00</published><updated>2024-11-24T12:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/bayes-unmixing</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/bayes-unmixing/"><![CDATA[<p>In the <a href="https://nasirlukman.github.io/blog/2024/distance/">previous post</a> we discussed how spectral unmixing inherently suffers from uncertainty—stemming both from the data and the model. Traditional optimization approaches, like the one we used earlier, often assume that these uncertainties are either negligible or nonexistent. However, in practice, this is rarely the case.</p> <p>In this post, we’ll take a brief look at the <strong>Bayesian approach</strong> to <strong>spectral unmixing</strong>, which explicitly accounts for these uncertainties. By incorporating them into the model, we propagate the uncertainty through to the final results. Instead of a single vector of mineral abundances, the Bayesian approach provides a probability distribution for these abundances, offering deeper insight into the confidence we have in our estimates.</p> <p>While we won’t dive too deeply into the math, a basic formulation helps set the stage. The linear mixture model can be expressed as:</p> \[\mathbf{y} = \mathbf{E} \mathbf{a} + \mathbf{e}\] <p>where:</p> <ul> <li>\(\mathbf{y}\) is the observed spectrum,</li> <li>\(\mathbf{E}\) is the endmembers matrix,</li> <li>\(\mathbf{a}\) is the abundance vector,</li> <li>\(\mathbf{e}\) represents error terms/uncertainty.</li> </ul> <blockquote> <p>Context for this post: We are focusing on unmixing for minerals on particulate surfaces (e.g., rock surfaces). Due to multiple-scattering effects, the linear relationship above does not hold when using reflectance data. Instead, we will use the <a href="https://en.wikipedia.org/wiki/Single-scattering_albedo">Single Scattering Albedo (SSA)</a> which derived from Hapke’s Model, as it better handles these effect. For those interested in the underlying theory, I highly recommend consulting <a href="https://www.cambridge.org/core/books/theory-of-reflectance-and-emittance-spectroscopy/C266E1164D5E14DA18141F03D0E0EAB0">this book</a>; these two papers that really helps me a lot with the subject: <a href="https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/JB094iB10p13619">[1]</a>, <a href="https://www.researchgate.net/publication/264564339_A_Review_of_Nonlinear_Hyperspectral_Unmixing_Methods">[2]</a>; or other sources (including my <a href="https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;opi=89978449&amp;url=http://essay.utwente.nl/101556/1/Lukman_MA_ITC.pdf&amp;ved=2ahUKEwjqlY-m8faJAxUdw6ACHRUJKj0QFnoECBkQAQ&amp;usg=AOvVaw3Tbo1LEGrTchQ7edNZoxGt">thesis</a>😉)</p> </blockquote> <h3 id="bayesian-framework">Bayesian Framework</h3> <p>Following <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ Theorem</a>, we can represent the spectral unmixing problem as:</p> \[P(\mathbf{a}, \sigma^2 \mid \mathbf{y}, \mathbf{E}) \propto P(\mathbf{y} \mid \mathbf{a}, \sigma^2, \mathbf{E}) P(\mathbf{a}) P(\sigma^2)\] <p>where:</p> <ul> <li>\(P(\mathbf{a}, \sigma^2 \mid \mathbf{y}, \mathbf{E})\) is the posterior distribution of the abundance vector and error variance given the observed spectrum and endmembers,</li> <li>\(P(\mathbf{y} \mid \mathbf{a}, \sigma^2, \mathbf{E})\) is the likelihood of the observed spectrum,</li> <li>\(P(\mathbf{a})\) is the prior distribution of the abundance vector,</li> <li>\(P(\sigma^2)\) is the prior distribution of the error variance,</li> <li>and \(\propto\) denote proportionality</li> </ul> <p>We assume that the error term \(\mathbf{e}\) is normally distributed, giving us a <a href="https://distribution-explorer.github.io/continuous/normal.html">Normal</a> likelihood:</p> \[P(\mathbf{y} \mid \mathbf{a}, \sigma^2, \mathbf{E}) = \mathcal{N}(\mathbf{y} \mid \mathbf{E}\mathbf{a}, \sigma^2\mathbf{I}),\] <p>where \(\mathbf{I}\) is the identity matrix.</p> <p>For the abundance vector \(\mathbf{a}\), we use a <a href="https://distribution-explorer.github.io/multivariate_continuous/dirichlet.html">Dirichlet</a> prior to enforce the non-negativity and sum-to-one constraints:</p> \[P(\mathbf{a}) = \mathcal{D}(\mathbf{a} \mid \boldsymbol{\alpha}),\] <p>where \(\boldsymbol{\alpha}\) is the concentration parameter.</p> <p>For the error variance \(\sigma^2\), we assign a <a href="https://distribution-explorer.github.io/continuous/halfcauchy.html">Half-Cauchy</a> prior:</p> \[P(\sigma^2) = \mathcal{HC}(\sigma^2 \mid \beta),\] <p>with the scale hyperparamter \(\beta\) given a <a href="https://distribution-explorer.github.io/continuous/uniform.html">Unifrom</a> prior such as:</p> \[P(\beta) = \mathcal{U}(\beta \mid 0, 0^{-4}).\] <p>Therefore, we can summarize the hierarchical structure of the random variables as:</p> \[\mathbf{y} \sim \mathcal{N}(\mathbf{E}\mathbf{a}, \sigma^2\mathbf{I})\] \[\mathbf{a} \sim \mathcal{D}(\boldsymbol{\alpha})\] \[\sigma^2 \sim \mathcal{HC}(\beta)\] \[\beta \sim \mathcal{U}(0, 10^{-4})\] <p>As you might guess, this formulation of the posterior distribution cannot be solved analytically. Instead, we use <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"><em>Markov Chain Monte Caelo (MCMC)</em></a> to sample and estimate the posterior. For educational purposes, I’ve implemented a custom sampler based on the <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"><em>Metropolis-Hastings Random Walk</em></a> in Python. In practice, however, modern samplers like <em>NUTS (No-U-Turn Sampler)</em> in an established library such as <a href="https://www.pymc.io/welcome.html">PyMC</a> are often preferable. They offer a more efficient and streamlined sampling process, sparing users the burden of directly managing the nasty mathematics behind these algorithms.</p> <p>In the Metropolis-Hastings algorithm, we iteratively draw samples from the posterior. For each new sample, we evaluate its probability relative to the previous sample. The sample is either accepted or rejected based on this evaluation. Over many iterations, the density of accepted samples approximates the true posterior distribution.</p> <p>For illustration, the animation below shows the random walk process for sampling abundance parameters in a mixture of three endmembers. The blue regions represent the true target distribution. Notice how the sampler, starting from a random point in the parameter space, gradually converges to the high-probability regions:</p> <div style="display: flex; justify-content: center;"> <img src="/assets/img/post_2_random_walk.gif" alt="Random Walk"/> </div> <div class="caption"> Image 1. Random Walk Example on a known target distribution </div> <h3 id="practical-example">Practical Example</h3> <p>In this example, we will analyze a sandstone rock sample. Rock samples are ideal for testing this method since they represent natural surfaces and still allow us to conduct other detailed analytical measurements with laboratory instruments to produce high-quality ‘ground truth’ data for comparison with our results.</p> <p>For the endmembers, we consider three primary components of sandstone: quartz (grains), clay (matrix), and carbonates (cement). The endmember spectra for these minerals are assumed to be known, either from direct laboratory measurements, spectral libraries, or endmember extraction algorithms for hyperspectral imagery. We begin with a single mixed spectrum, as shown in the image below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_data-480.webp 480w,/assets/img/post_2_data-800.webp 800w,/assets/img/post_2_data-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_data.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Endmember spectra for Carbonate, Quartz, Clay minerals, and the observed mixed spectra </div> <p>Using our Metropolis-Hastings sampler, we draw four chains of \(10^5\) random samples, tuning them carefully to ensure we only consider representative samples. For simplicity, we focus solely on the mineral abundances and omit other parameters. Below, we display the abundance trace plots alongside their corresponding marginal posterior distributions. The mean value (expected values) of the samples and the true abundance values are also shown as comparison. The RMSE for this result is 0.0209.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_trace_plot-480.webp 480w,/assets/img/post_2_trace_plot-800.webp 800w,/assets/img/post_2_trace_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_trace_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Marginal posterior distribution of each endmembers abundance and its trace plots </div> <p>There are some cool things that we can do with the posteriors. For instance, we can visualize parameter correlations using a corner plot, as shown below. Note as well how we denote the result with some notation such as: \(0.14_{-0.12}^{+0.16}\) where the central value represents the expected value, while the subscript and superscript indicate the range of possible value within 90% confidence interval.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_corner_plot-480.webp 480w,/assets/img/post_2_corner_plot-800.webp 800w,/assets/img/post_2_corner_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_corner_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Corner plot of the marginal posterior showing correlations between each endmember abundances. Red and blue line represent the expected value (mean) and the true value. The black stripped line represent the boundary of 90% confidence interval. </div> <p>Corner plots are a really useful visualization, especially for high-dimensional parameter spaces. For this three-parameter example, however, we can also visualize the posterior on a ternary diagram:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_ternary-480.webp 480w,/assets/img/post_2_ternary-800.webp 800w,/assets/img/post_2_ternary-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_ternary.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Ternary plot of the posterior of the abundances. Red and blue dot represent the expected value (mean) and the true value. </div> <p>The corner and ternary plots reveal a strong correlation between carbonate and quartz abundances. As carbonate increases, the algorithm compensates by reducing quartz to maintain a reasonable modeled spectrum that aligns with the observed data. Instead of a single modeled spectrum, the output is a distribution of spectra, visualized below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_modeled_spectra-480.webp 480w,/assets/img/post_2_modeled_spectra-800.webp 800w,/assets/img/post_2_modeled_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_modeled_spectra.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Observed spectra vs distribution of the modeled spectra </div> <p>This visualization highlights that, given the data and assumed uncertainties, the reasonable set of modeled spectra is represented by the 2D Normal distribution visualize by its percentiles as shown on the image above.</p> <h3 id="hyperspectral-images">Hyperspectral Images</h3> <p>The same process applies to hyperspectral images on a pixel-by-pixel basis. Here, we analyze a hyperspectral image of a sandstone drill core sample. Remember that for individual spectra (or also pixel in this case) the sampler will need to take and store \(10^{5}\) sample for each parameters. This means that the final result will be a huge 4D array, and the computation might take some time, depending on the efficiency of the sampling algorithm used. Below, we visualize the expected abundance values for each endmember and their 90% confidence intervals range:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_rock_sample-480.webp 480w,/assets/img/post_2_rock_sample-800.webp 800w,/assets/img/post_2_rock_sample-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_rock_sample.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Bayesian spectral unmixing result on a hyperspectral image of a rock sample </div> <p>Comparing our bulk results with <a href="https://en.wikipedia.org/wiki/QEMSCAN">QEMSCAN</a> results, we can achieve excellent agreement with an RMSE of 0.0186.</p> <p>It’s important to highlight that quantification through imaging techniques like this does more than just identify mineral abundances—it also provides a detailed view of the rock’s texture. By analyzing mineral distributions and their spatial relationships, we can potentially infer other critical physical properties of the rock such as porosity and permeability, which might be really usefult for application like reservoir characterization and groundwater studies.</p> <p>The inclusion of uncertainty measurement in spectral unmixing offers an important insights into the reliability of the results. Rather than relying solely on point estimates, we gain a more nuanced understanding of the possible variations and correlations in parameter space. This is particularly valuable when making decisions based on complex data, as it helps avoid overconfidence and identifies parameters requiring further refinement. In mineral quantification, understanding uncertainties can reveal how robust the mineral abundance estimates are, guiding both data interpretation and future analyses.</p> <p>Hyperspectral imaging, as demonstrated in this example, have the potential for a more fast and cost-effective alternative of mineral abundance mapping compared to other laboratory method. Moreover, it has the potential to scale up to airborne and satellite platforms, making it one of a kind method for larger-scale mineral mapping and monitoring.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Bayesian approach on spectral unmixing with an example case using hyperspectral images of sandstone drill core sample.]]></summary></entry><entry><title type="html">Different Distance Metrics Example in Spectral Unmixing</title><link href="https://nasirlukman.github.io/blog/2024/distance/" rel="alternate" type="text/html" title="Different Distance Metrics Example in Spectral Unmixing"/><published>2024-11-15T23:36:10+00:00</published><updated>2024-11-15T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/distance</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/distance/"><![CDATA[<p>In data space, distance is commonly used to measure the similarity between data points. For instance, if points <em>a</em> and <em>b</em> are “close” to each other (i.e., have a small distance), they are considered more similar. This concept is essential in machine learning and data analysis as it can be used to quantifies similarity between datasets.</p> <p>In two dimensions, it’s easy to visualize data points and assess their distances, such as in this example:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_image_1_three_point_distance-480.webp 480w,/assets/img/post_1_image_1_three_point_distance-800.webp 800w,/assets/img/post_1_image_1_three_point_distance-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_image_1_three_point_distance.jpg" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Three points in two dimensional space, illustrating the concept of distance. </div> <p>Visually, most of us would agree that points <em>a</em> and <em>b</em> appear closer in distance to each other compared to <em>a</em> and <em>c</em>. But is this really the case? To confirm, we need to define what we mean by “distance” and calculate the distance between each point.</p> <p>In this post, we will examine three different distance metrics and compare their performance in a hypothetical spectral unmixing problem: <em>Euclidean distance, Manhattan distance, and angular distance.</em> I think it is easier to first take a look the visualization of how each metrics measure distance:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_image_2_three_type_of_distance-480.webp 480w,/assets/img/post_1_image_2_three_type_of_distance-800.webp 800w,/assets/img/post_1_image_2_three_type_of_distance-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_image_2_three_type_of_distance.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Comparison of how Euclidean, Manhattan, and Angular distances measure relationships between points. </div> <p>I think this ilustration cleary shows the distinction between how the three metrics measure distance, to formalize this, let’s go to each metrics and see its mathematical foromulation.</p> <h3 id="euclidean-distance">Euclidean Distance</h3> <p>The most common and intuitive distance is Euclidean distance, also often referred to as \(L_2\) distance. Between two points <em>a</em> and <em>b</em> in data space, Euclidean distance is simply the straight-line distance between the points, which can be expressed mathematically as:</p> \[L_2 = \sqrt{\sum_{i=1}^n (a_i - b_i)^2}\] <h3 id="manhattan-distance">Manhattan Distance</h3> <p>Another way to measure distance from \(a\) to \(b\) is to follow a path parallel to the axis. For example, in the image below, we first move parallel to the y-axis for 1 units, followed by a parallel path along the x-axis for 1 units, and then sum the total path length. This type of “gridded” path is called Manhattan distance (after the gridded road pattern of Manhattan) or \(L_1\) distance. Mathematically, it can be expressed as:</p> \[L_1 = \sum_{i=1}^n |a_i - b_i|\] <h3 id="angular-distance">Angular Distance</h3> <p>For angular distance \((\theta)\), we treat points \(a\) and \(b\) as two vectors originating from the origin \((0,0)\). The angular distance is simply the angle between the two vectors, expressed as:</p> \[\theta = \arccos \left( \frac{a \cdot b}{\|a\| \|b\|} \right)\] <p>In machine learning, angular distance is more commonly referred to as <em>cosine similarity</em> (measured as the cosine of the angle). In spectral analysis, this is often called <em>Spectral Angle Mapping (SAM)</em> and is widely used for spectral matching. Mathematically, angular distance is only valid as a metric if we normalize our data to unit vectors. For unit vectors, this measurement gives the same result as Euclidean distance after normalizing the data.</p> <p>From these definitions of the three distance metrics, lets return to our initial visualization (Image 1): Is point <em>a</em> closer to point <em>b</em> than to point <em>c</em> ? Again, the answer depends on the distance metric. Using Euclidean and Manhattan distances, this statement holds true. However, with angular distance, it is actually false, while <em>a</em> and <em>b</em> have a non-zero angular distance, <em>a</em> and <em>c</em> actually have an angular distance of \(0\). So using this metric, <em>c</em> is closer to <em>a</em> compared to <em>b</em>! I think this simple example already ilustrate how crutial it is to understand the distinction between different distance metrics and in which cases using one is prefered compared to the others.</p> <h2 id="example-case-linear-spectral-unmixing">Example Case: Linear Spectral Unmixing</h2> <p>To illustrate cases in which each distance metric is more appropriate, let’s use linear spectral unmixing as an example. Spectral unmixing is an important analytical technique in remote sensing used to decompose mixed pixel values into their constituent spectral signatures, known as endmembers, and their respective abundances. This process is essential for applications requiring sub-pixel level analysis, such as land cover classification, resource exploration, and environmental monitoring.</p> <p>An important aspect of spectral unmixing is the choice of distance metrics, which measure the similarity or dissimilarity between observed pixel spectra and modeled spectra. The selection of an appropriate metric significantly impacts the accuracy and performance of unmixing algorithms. Understanding these metrics helps optimize the unmixing process, especially in scenarios with high spectral variability or noise.</p> <p>Assuming a linear mixture model, a mixed spectrum of several different endmembers is defined as:</p> \[\mathbf{y} = \mathbf{E} \mathbf{a} + \mathbf{n}\] <p>where:</p> <ul> <li>\(\mathbf{y}\) is the observed spectrum,</li> <li>\(\mathbf{E}\) is the endmembers matrix,</li> <li>\(\mathbf{a}\) is the abundance vector,</li> <li>\(\mathbf{n}\) represents noise.</li> </ul> <p>In this equation, \(\mathbf{y}\) is known from observation, and for simplicity, we assume that a matrix of possible endmembers \(\mathbf{E}\) is also known, and noise \(\mathbf{n}\) is negligible.</p> <p>The goal is to solve for \(\mathbf{a}\) by minimizing the difference between the modeled spectrum \(\mathbf{E} \mathbf{a}\) and the observed spectrum \(\mathbf{y}\), under the conditions that all values of \(\mathbf{a}\) are non-negative and summed-to-one. This may achieved by solving this optimization problem:</p> \[\min_{\mathbf{a}} \; D(\mathbf{y} - \mathbf{E} \mathbf{a})\] <p>subject to:</p> \[\mathbf{a}_i \geq 0 \quad \text{and} \quad \sum_{i=1}^{n} \mathbf{a}_i = 1\] <p>This is where distance metrics \(D(•)\) come into play. The difference we are trying to minimize can be calculated using different distance metrics. Different distance metrics can lead to different results.</p> <p>Now, let’s run some tests under various simplified scenarios to see how each distance metric performs.</p> <h3 id="test-01-mixture-with-gaussian-noise">Test 01: Mixture with Gaussian Noise</h3> <p>For the first test, suppose we have four mineral endmembers (example taken from USGS Spectral Library), as shown below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_image_3_four_endmembers-480.webp 480w,/assets/img/post_1_image_3_four_endmembers-800.webp 800w,/assets/img/post_1_image_3_four_endmembers-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_image_3_four_endmembers.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Endmember spectra for Calcite, Kaolinite, Muscovite, and Quartz </div> <p>We’ll generate 1000 synthetic mixtures with the following conditions:</p> <ol> <li>The mixtures follow the linear mixture model equation.</li> <li>Noise is normally distributed with a mean of \(0\) and a standard deviation chosen randomly between \(10^{-5}\) and \(10^{-3}\).</li> </ol> <p>The accuracy of the spectral unmixing using the three distance metrics are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_first_test-480.webp 480w,/assets/img/post_1_first_test-800.webp 800w,/assets/img/post_1_first_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_first_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p>In this case, <strong>Euclidean distance</strong> clearly outperforms the other two metrics, as it is well-suited for data with normally distributed noise. Under these conditions, minimizing Euclidean distance is equivalent to <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood estimation</a>.</p> <h3 id="test-02-mixture-with-random-spikes">Test 02: Mixture with Random ‘Spikes’</h3> <p>For the second test, instead of adding normal noise, this time we add random “spikes,” where each wavelength band has a \(1\%\) chance of being randomly increased or decreased by a value between \(0.05\) and \(0.2\). While this type of noise is not common in remote sensing or spectroscopy, it will help us illustrate the strengths of Manhattan distance. The accuracy of the spectral unmixing of these synthetic mixtures are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_second_test-480.webp 480w,/assets/img/post_1_second_test-800.webp 800w,/assets/img/post_1_second_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_second_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p>Here, <strong>Manhattan distance</strong> outperforms the other metrics. Manhattan distance is known to be more robust to extreme outliers than Euclidean distance, which squares the error term, making it sensitive to outliers. In contrast, Manhattan distance only takes the absolute value of location differences, making it less affected by outliers.</p> <h3 id="test-03-mixture-with-brightness-difference">Test 03: Mixture with Brightness Difference</h3> <p>While random spikes in reflectance values may not be common in spectroscopy or remote sensing, brightness differences and inaccurate endmembers spectra are issues that often arise with real datasets. To illustrate this problem, let’s randomly add random constant between \(-0.2\) to \(0.2\) to the mixture. This experiment is a simplified simulation of real world scenario where different terrains and illumination condition might cause the sensor to recieve the signal with different intensity if not corrected appropriately.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_third_test-480.webp 480w,/assets/img/post_1_third_test-800.webp 800w,/assets/img/post_1_third_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_third_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p>In this case, <strong>angular distance</strong> (or SAM) has the lowest error, as it essentially ignores magnitude (brightness) differences and focuses on the shape of the spectra. To illustrate further, take a look at the two spectra below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_kaolinite-480.webp 480w,/assets/img/post_1_kaolinite-800.webp 800w,/assets/img/post_1_kaolinite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_kaolinite.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Two kaolinite spectra with different brightness </div> <p>The two spectra above have identical shape but different brightness values. These two spectra may be considered different by Manhattan and Euclidean distances, but angular distance would see them as identical. This feature is one reason why angular distance is widely used in remote sensing applications, where brightness differences due to terrains and illuminations effects are common.</p> <h3 id="test-04-a-more-complicated-mixture">Test 04: A More Complicated Mixture</h3> <p>Now let’s consider a more complex scenario. We will use a larger spectral library, selecting 10 minerals from the USGS spectral library. To generate a mixture, we will randomly select between 2 to 4 endmembers from this library. Since the actual selected minerals are unknown, all 10 possible endmembers will be included in the unmixing process. This situation, where many variables (10 possible endmembers) are considered, but only a few (2–4 endmembers) are non-zero, is known as a <em>sparsity problem.</em></p> <p>Typically, sparsity issues are addressed by incorporating regularization terms into the optimization function. However, for this simple trial, we will not include any regularization and will apply the same spectral unmixing method used in the previous three tests. This allows us to focus solely on the challenges posed by increased complexity in the spectral library.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_10_endmembers-480.webp 480w,/assets/img/post_1_10_endmembers-800.webp 800w,/assets/img/post_1_10_endmembers-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_10_endmembers.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. 10 Endmembers Spectra </div> <p>We will also add an gaussian noise, uniform noise, gamma noise, poisson noise, and random constant as brightness modifier. The image below ilustrate each of the noises:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_noises-480.webp 480w,/assets/img/post_1_noises-800.webp 800w,/assets/img/post_1_noises-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_noises.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 9. Each noises added to the mixture. </div> <p>The unmixing accuracy results are shown in histograms below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_forth_test-480.webp 480w,/assets/img/post_1_forth_test-800.webp 800w,/assets/img/post_1_forth_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_forth_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 10. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p><strong>Manhattan distance</strong> performed exceptionally well in this last case study, which probably can be attributed to its robustness to ouliers and more varying noise types. Despite this, its non-differentiable nature (since its an absolute value function) makes it less appealing for gradient-based optimization algorithms, especially for larger, more complex datasets. For this particular test, Manhattan distance takes 43 seconds for 1,000 data points, compared to 14 seconds for Euclidean distance and 11 seconds for angular distance.</p> <p>This study highlights the importance of carefully selecting the appropriate distance metric based on the nature of the data and the problem being addressed. While Euclidean distance is often the default choice, Manhattan distance or angular distance can outperform it in specific scenarios, as demonstrated in the experiments above.</p> <p>On a final note, it’s important to emphasize that the unmixing approach presented here operates under the assumption of a perfect model and data. In real-world scenarios, this is rarely the case, so we should generally expect the results to be slightly less accurate. However, it’s crucial to acknowledge that spectral unmixing inherently involves significant uncertainty. A more robust approach to address this uncertainty is to adopt a <em>Bayesian framework</em>, which offers a natural way to model such problems. This could be an intriguing topic for a future discussion.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Comparison between Euclidean distance, Manhattan distance, and angular distance in spectral unmixing of mineral endmembers.]]></summary></entry></feed>