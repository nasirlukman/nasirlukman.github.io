<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://nasirlukman.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nasirlukman.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-03T06:49:58+00:00</updated><id>https://nasirlukman.github.io/feed.xml</id><title type="html">Earth.etc</title><subtitle></subtitle><entry><title type="html">Exploratory Data Analysis (EDA) for Hyperspectral Imagery</title><link href="https://nasirlukman.github.io/blog/2024/EDA/" rel="alternate" type="text/html" title="Exploratory Data Analysis (EDA) for Hyperspectral Imagery"/><published>2024-12-09T23:36:10+00:00</published><updated>2024-12-09T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/EDA</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/EDA/"><![CDATA[<p>One of the main characteristics of hyperspectral imagery is its high-dimensional data (i.e., a high number of spectral bands). This type of data, while providing a higher level of detail in the spectral characteristics of the material we observe, also raises challenges in handling the data effectively. Higher dimensional data means it becomes more challenging to extract meaningful information for analysis. These challenges are often referred to as <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">the curse of dimensionality</a>.</p> <p>In this post, I will show my approach in conducting exploratory data analysis (EDA) on a hyperspectral imagery with the goal of deriving meaningful geological information from the data. In this post, we will assume no geological prior knowledge of the region (although nowadays that is hardly the case, especially for Earth’s surface). We will rely solely on the hyperspectral data itself and some basic spectrometry and geology knowledge.</p> <p>We will use an airborne hyperspectral image covering the shortwave infrared range (SWIR) from ~2000 nm to ~2400 nm over an area of about 10 km² in an arid region. All of the analysis performed in this post is done using standard scientific libraries in the Python environment and an open-source software called <a href="http://hyppy.is-great.org/?i=1">Hyppy</a> developed at the University of Twente.</p> <h2 id="1-basic-visualization">1. Basic visualization</h2> <p>The obvious first step in EDA of hyperspectral imagery is to visualize the image. We can choose to visualize the image in grayscale for selected wavelength bands of interest and create false color composites to observe the main structural characteristics of the region.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_composite-480.webp 480w,/assets/img/post_4_composite-800.webp 800w,/assets/img/post_4_composite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_composite.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. False color composite image (R: 2088 nm; G: 2199 nm; B: 2328 nm) </div> <p>My initial interpretation of the region is that it is most likely mainly composed of sedimentary bedding influenced by a fault with apparent left-lateral movement, based on the drag fold formed along the fault lines.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_basic_interpretation-480.webp 480w,/assets/img/post_4_basic_interpretation-800.webp 800w,/assets/img/post_4_basic_interpretation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_basic_interpretation.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Basic geological feature initial interpretation from the image </div> <p>When it comes to mineralogical/geological interpretations, I find it helpful to begin with a very broad interpretation. Knowing that the region is likely predominantly composed of sedimentary rocks already provides significant constraints for further interpretation, which may be very useful in the next phase. We may revisit this interpretation later if further analysis or data does not support it.</p> <h2 id="2-getting-to-know-the-data">2. Getting to know the data</h2> <p>It is very important to familiarize ourselves with the data we are working with. At this stage, I typically inspect the spectra of some pixels that stand out in the visualization and get a sense of the variation in spectral responses present in the image. For this, I often use specialized software such as <a href="https://www.nv5geospatialsoftware.com/Products/ENVI">ENVI</a>, <a href="https://plugins.qgis.org/plugins/temporalprofiletool/">QGIS with Spectral Profile Plugin</a>, or <a href="http://hyppy.is-great.org/?i=1">Hyppy</a>. The later two is an open source program which are available for free.</p> <p>At this stage, we can also plot a histogram of the mean reflectance values of the image to see how many visible clusters are present across the spectral bands. Note that the reflectance value are in the sacale of 10,000.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_mean_histogram-480.webp 480w,/assets/img/post_4_mean_histogram-800.webp 800w,/assets/img/post_4_mean_histogram-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_mean_histogram.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Histogram of mean albedo of each pixel in the image showing two main albedo class. </div> <p>From the histogram, we can decide on a threshold to classify our pixels based on their average albedo. This is generally equivalent to classifying the image into bright-colored minerals and dark-colored minerals (albeit in the shortwave infrared range, not in the visible range). Typically, low-albedo minerals in SWIR also appear dark in visible light. Our first classification results are shown below which shows the most basic classification of the image we have: reflective vs absortive minerals.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_albedo_class-480.webp 480w,/assets/img/post_4_albedo_class-800.webp 800w,/assets/img/post_4_albedo_class-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_albedo_class.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Map showing the distribution of two albedo class. </div> <h2 id="3-pca-and-k-means-clustering">3. PCA and K-Means Clustering</h2> <p>Since the number of pixels and spectral bands is often too high to handle for meaningful interpretation, dimensional reduction and data clustering methods can be useful for grouping data into clusters of spectra based on their spectral similarity which can make further analysis to be easier. While we can directly apply K-Means clustering to the data, this is not usually recommended. Each dimension of our data carries varying levels of information and noise. For high-dimensional data, only a few dimensions typically contain significant information, while others only add noise to the algorithm.</p> <p>PCA is a dimensionality reduction method that organizes data based on its variability in the data space, corresponding to its information content. It identifies the directions (principal components) where the data varies the most and projects the data onto these axes in descending order of variance. The downside is that the data is transformed into an orthogonal space where the units lose their original physical meaning. In this example, we visualize the first 10 principal components and observe that by the 10th component, there is minimal discriminatory power. Therefore, we reduce the dimensionality from 55 to 10 principal components, preserving the most significant information, and use this result as the input for K-Means clustering.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_PCA-480.webp 480w,/assets/img/post_4_PCA-800.webp 800w,/assets/img/post_4_PCA-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_PCA.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. First 10 PCA images. </div> <p>The K-Means algorithm clusters data points based on their similarities. It assigns each point to one of K clusters based on its proximity to the cluster centroids, iterating to minimize variance within clusters. Similarities are computed using Euclidean distance, which I explained in a <a href="https://nasirlukman.github.io/blog/2024/distance/">previous post</a>.</p> <p>K-Means requires the user to define the number of clusters (\(K\) ). The elbow method can help determine this, by plotting the within-cluster sum of squares (WCSS) for various K values. The optimal number of clusters is where the WCSS curve starts to saturate, resembling an elbow. For this dataset, the optimal number of clusters is 3, as shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_WCSS-480.webp 480w,/assets/img/post_4_WCSS-800.webp 800w,/assets/img/post_4_WCSS-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_WCSS.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. WCSS result for cluster values ranging from 1 to 11. </div> <p>Using \(K=3\) , we perform clustering, with the results shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_cluster_map-480.webp 480w,/assets/img/post_4_cluster_map-800.webp 800w,/assets/img/post_4_cluster_map-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_cluster_map.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. K-Mean clustering result from the first 10 principle component of our hyperspectral images. </div> <p>We then can transform the pixels back from PCA space to the original data space to examine the average mean spectra of each cluster:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_cluster_spectra-480.webp 480w,/assets/img/post_4_cluster_spectra-800.webp 800w,/assets/img/post_4_cluster_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_cluster_spectra.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. Average spectra of each cluster. </div> <p>Compared to our initial simple classification by mean albedo, this approach offers more nuance. For instance, the high-albedo reflectance now separates into two distinct spectral shapes, while the low-albedo minerals remain a single cluster. To further refine the low-albedo cluster, we could mask the high-albedo pixels and repeat the process. However, for this example, I am satisfied with these results. At this stage, I observe that the low-albedo cluster has largely featureless spectra (likely consisting of minerals without distinct features in the SWIR range), making further attempt for meaningful subdivision challenging.</p> <h2 id="4-endmember-extraction-and-linear-spectreal-unmixing">4. Endmember Extraction and Linear Spectreal Unmixing</h2> <p>Since our average spectra likely represent complex mixtures, it is useful to extract their possible pure spectral shapes. At this stage, we have decided to categorize our image into three distinct classes. We will use the <a href="">N-FINDR</a> algorithm with \(n=3\) to extract the three purest endmembers from our image. The data distribution in 2D PCA space and the extracted endmember pixels are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_nfindr_plot-480.webp 480w,/assets/img/post_4_nfindr_plot-800.webp 800w,/assets/img/post_4_nfindr_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_nfindr_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 9. Data shape in reduced 2 PCA dimension showing clear linear relationship between three endmembers. Red star is the vertex of the triangle which corespond to the purest pixel on the image. </div> <p>This is one of the most texbook like 2D PCA representations of a real hyperspectral image I have encountered. The 2D simplex (triangle) is almost perfectly formed, indicating that our entire dataset can be described as a linear combination of three endmember spectra. These endmembers therefore must be the pixel that correspond to the vertices of the triangle. After transforming the extracted endmembers back into the original data space, we observe their pure spectral signatures:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_endmember_spectra-480.webp 480w,/assets/img/post_4_endmember_spectra-800.webp 800w,/assets/img/post_4_endmember_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_endmember_spectra.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 10. Spectra of the purest pixels (endmembers). </div> <p>This is a good point to start naming our classes properly. You could match the spectra to a spectral library using a feature-matching algorithm to identify the mineral spectra most similar to the extracted endmembers. For simplicity, I use broad categorizations. I define the first spectrum as the <strong>Low-Albedo Mineral Group,</strong> likely dominated by plagioclase or mafic minerals, interpreted as part of a volcanic rock complex. The second spectrum corresponds to the <strong>Hydroxyl Mineral Group</strong>, based on its \(AlOH\) feature around 2200 nm, likely related to the occurance of white micas or clays, interpreted as part of siliciclastic rocks such as arkose. The third spectrum represents the <strong>Carbonate Mineral Group</strong>, with a \(CO_3\) feature near 2300 nm, likely from calcareous sedimentary rocks like limestone or calcareous sandstone/siltstone.</p> <p>With our pure endmembers identified, we can perform linear spectral unmixing to estimate their relative abundances. At this stage of analysis, I prefer to not constrain the unmixing result to be strictly sum-to-one since there are still many unknowns. These abundance results are interpreted as <em>unconstrained abundances</em>, distinct from <em>absolute abundances</em>, which have more physical meaning. Below are the unconstrained abundance maps for each endmember:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_unmixing_result-480.webp 480w,/assets/img/post_4_unmixing_result-800.webp 800w,/assets/img/post_4_unmixing_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_unmixing_result.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 11. Unconstrained abundance of the three endmembers. </div> <p>Since we are dealing with only three mineral groups, we can assign each abundance to an RGB channel to produce a ternary representation of the unconstrained abundances:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_unmixing_result_ternary_with_legend-480.webp 480w,/assets/img/post_4_unmixing_result_ternary_with_legend-800.webp 800w,/assets/img/post_4_unmixing_result_ternary_with_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_unmixing_result_ternary_with_legend.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 12. Ternary map of the unconstrained abundance of the three endmembers. </div> <p>It is important to note that this ternary representation is purely for visualization and does not strictly correspond to the absolute abundance of each endmember.</p> <h2 id="5-minimum-wavelength-mapping">5. Minimum Wavelength Mapping</h2> <p>Many distinct hyroxyl and carboante minerals can be distinguished based on the subtle difference in the wavelength position of their deepest absorption feature. Using a method called minimum wavelength mapping, we can detect these subtle shifts and potentially refine our classification to include specific members of the carbonate and hydroxyl mineral groups. The first step is to detect the wavelength of the deepest absorption feature across the entire spectral range.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_minwav-480.webp 480w,/assets/img/post_4_minwav-800.webp 800w,/assets/img/post_4_minwav-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_minwav.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 13. Minimum wavelength position histogram for the whole spectral range. </div> <p>We observe at least three distinct distributions of \(AlOH\) absorption features and five distributions of \(CO_3\) absorption features. For the \(AlOH\) group, the lowest feature observed at 2195 nm likely corresponds to lithium-rich white mica, such as lepidolite. The other two \(AlOH\) features, around 2210 nm and 2220 nm, likely correspond to \(Al\)-rich white mica, such as muscovite, with minor geochemical differences attributed to variations of geochemistry and temperature of the mineral formation.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_AlOH_minwav_legend-480.webp 480w,/assets/img/post_4_AlOH_minwav_legend-800.webp 800w,/assets/img/post_4_AlOH_minwav_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_AlOH_minwav_legend.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 14. Minimum wavelength map of hydroxile features. </div> <p>For the \(CO_3\) group, there is significant variation in the deepest feature wavelengths. Although identifying specific minerals at this stage is challenging, the observed ranges suggest these features are unlikely to correspond to calcite, the most common carbonate mineral. For instance, features around 2335 nm are commonly associated with siderite, 2320 nm with dolomite, and 2305 nm with magnesite.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_4_CO3_minwav_legend-480.webp 480w,/assets/img/post_4_CO3_minwav_legend-800.webp 800w,/assets/img/post_4_CO3_minwav_legend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_4_CO3_minwav_legend.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 15. Minimum wavelength map of carbonate features. </div> <p>It is essential to note that pinpointing specific minerals requires further analysis. While we cannot yet confirm the mineral species, the variations in these wavelength ranges are likely related to mineralogical differences. Therefore, the spatial distribution of these distinct groups remains valid, even when we are still uncertain with the definitive mineral identifications.</p> <h2 id="6-further-comments">6. Further comments</h2> <p>In this post, I demonstrated some typical EDA steps for hyperspectral analysis for geological investigations in an unfamiliar region. These EDA steps serve to familiarize us with the data and provide a solid foundation for further investigation.</p> <p>Here we see that SWIR hyperspectral data alone can reveal a wealth of information, even without incorporating additional datasets, prior knowledge of the region, or advanced analysis techniques. However, complementary datasets, such as VNIR and LWIR spectral data, could significantly enhance geological and mineralogical interpretation of the region. Additionally, methods beyond infrared spectrometry, such as gamma-ray spectrometry, offer valuable tools for geological mapping.</p> <p>In practice, prior knowledge of the study area—such as geological maps or models—is often available and can effectively guide the analysis. More importantly, incorporating fieldwork data, even from sparse sampling points, is crucial for validating and refining the results.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[My typical approach on EDA for a new hyperspectral projects for geological investigations. Includes method such as PCA, K-Means, N-FINDR, Linear Spectral Unmixing, and Minimum Wavelength Mapping.]]></summary></entry><entry><title type="html">Endmember Extraction from Hyperspectral Imagery Using N-FINDR</title><link href="https://nasirlukman.github.io/blog/2024/nfindr/" rel="alternate" type="text/html" title="Endmember Extraction from Hyperspectral Imagery Using N-FINDR"/><published>2024-11-27T23:36:10+00:00</published><updated>2024-11-27T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/nfindr</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/nfindr/"><![CDATA[<p>Hyperspectral imagery often contains mixed pixels—pixels that represent areas with more than one class of interest. Given the complexity of the scenes, and the rigid structure of images, it is unrealistic to assume every pixel to correspond to a single class. These classes could include features like water, trees, shrubs, grass, soil, or roads when performing land cover classification using satellite or airborne imagery. In earth science, the class of interest often is minerals that forms rocks. In any way, trying to find the purest pixels , or <em>endmembers</em>, of each class in our image is something that often useful for further analysis.</p> <p>In this post, I’ll provide a brief overview of one endmember extraction algorithm reffered to as <em>N-FINDR</em>. But, before diving into the details of the algorithm, it is important to acknowledge the general limitations of endmember extraction algorithms:</p> <ol> <li><strong>Purity is not guaranteed</strong>: These algorithms don’t guarantee that the extracted spectra represent a pure spectra of specific class of interest. Instead, they identify the purest spectra present in the image.</li> <li><strong>Known number of endmembers</strong>: The number of endmembers in the image must be known beforehand. This can be estimated using domain expertise, auxiliary measurements, other algorithms, or trial and error.</li> <li><strong>Linear mixture model assumption</strong>: Most endmember extraction algorithms, including N-FINDR, assume a linear mixture model.</li> </ol> <h2 id="how-n-findr-works">How N-FINDR Works</h2> <p>The core idea of N-FINDR is simple yet clever: it identifies the vertices of the simplex formed by the data distribution in reduced dimensions. These vertices are the purest spectra present in the dataset. The general steps of the algorithm is as follows:</p> <ol> <li><strong>Reprojection</strong>: Reproject all pixels into a lower-dimensional space using an orthogonal transformation like Principle Component Analysis (PCA) or Minimum Noise Fraction (MNF). MNF is often preferred because it minimizes the influence of noise.</li> <li><strong>Dimensionality reduction</strong>: Reduce the dimensionality to the first \((n−1)\) components, where \(n\) is the number of endmembers. At this stage, the data points should lie inside an \((n-1)\) dimensional simplex.</li> <li><strong>Iterative vertex selection</strong>: <ul> <li>Randomly select \(n\) points and calculate the simplex’s volume (or area in 2D).</li> <li>Iteratively replace one vertex with another pixel. If the new simplex’s volume is larger, accept the replacement. Otherwise, reject it and try again.</li> </ul> </li> <li><strong>Termination</strong>: After a fixed number of iterations without improvement, the algorithm terminates, and the final set of pixels is taken as the endmembers.</li> <li><strong>Reprojection back</strong>: Reproject the selected pixels into the original dimensional space to obtain the endmember spectra.</li> </ol> <h2 id="synthetic-data-example">Synthetic Data Example</h2> <p>To illustrate, let’s consider an idealized case of 1,000 synthetic mixed pixels generated from three endmembers. Since we’re dealing with three endmembers, we reproject the data into its first two principal components. In this reduced space, the data points lie perfectly on a 2D simplex—a triangle as shown in the image below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_synthetic_mixture_MNF-480.webp 480w,/assets/img/post_3_synthetic_mixture_MNF-800.webp 800w,/assets/img/post_3_synthetic_mixture_MNF-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_synthetic_mixture_MNF.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. First two principal components of the synthetic mixture of three endmembers </div> <p>If each data point is a linear mixture of three pure endmembers, the endmembers will be located at the vertices of a triangular region, commonly referred to as a simplex. In this 2D example, identifying the simplex is relatively straightforward through visual inspection. However, as the number of endmembers increases, the dimensionality of the principal component representation also grows, making it increasingly difficult to determine the simplex visually. To overcome this challenge, we employ an iterative simplex-finding algorithm, which can be generalized to handle higher-dimensional data. The animation below illustrates the iterative process of refining the simplex:</p> <div style="display: flex; justify-content: center;"> <img src="/assets/img/post_3_nfindr_iterative.gif" alt="NFINDR"/> </div> <div class="caption"> Image 2. Ilustration of NFINDR algorithm in action </div> <h2 id="real-data-example">Real Data Example</h2> <p>In real-world scenarios, hyperspectral data is rarely as ideal as synthetic examples. Complex noise, non-linearities, and other factors often result in an imperfectly formed simplex. Nevertheless, algorithms like N-FINDR can still provide valuable output.</p> <p>For this example, we examine laboratory-acquired hyperspectral imagery of a sandstone sample. Below is a false-color composite image of the sample:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_rock_image-480.webp 480w,/assets/img/post_3_rock_image-800.webp 800w,/assets/img/post_3_rock_image-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_rock_image.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. False color composite hyperspectral iamge of a sandstone sample </div> <p>A quick inspection of the rock suggests that it is predominantly composed of three minerals. Thus, we assign \(n=3\) for this analysis. The results of the MNF transformation and the selected simplex vertices by N-FINDR are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_real_mixture_MNF-480.webp 480w,/assets/img/post_3_real_mixture_MNF-800.webp 800w,/assets/img/post_3_real_mixture_MNF-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_real_mixture_MNF.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. First two principal components of the sandstone rock sample. The red do represent the selected purest spectra by N-FINDR algorithm. </div> <p>Notice that the simplex is not perfectly formed, and the triangular structure appears slightly distorted. This suggests minor non-linear behavior in the actual mixtures. Additionally, some outliers lie outside the simplex, possibly influenced by accessory minerals. Such minerals, often present in small amounts, are common in natural rock samples and can affect the spectra of certain pixels. These influences may not be fully captured in a 2D representation.</p> <p>We can examine the spectra of the selected purest pixels by transforming them back to their original dimensions. Below are the resulting spectra for the three identified endmembers:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_pure_endmember_result-480.webp 480w,/assets/img/post_3_pure_endmember_result-800.webp 800w,/assets/img/post_3_pure_endmember_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_pure_endmember_result.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Resulting spectra of the three endmember from N-FINDR algorithm </div> <p>If you know your mineralogy and infrared spectroscopy you can immedietly recognize these minerals. The red spectra have a strong absorption feature in ~2200 nm region which related the \(Al-OH\) bonds of white mica/clay mienrals. The blue spectra have an absroption feature in ~2330 nm region related to \(CO_3\) bonds of carbonate minerals. The green and bright spectra represent quartz mineral. we still can see a very weak feature in ~2200 nm sugest that it is not 100% pure spectra and there is still a small influence of clay minerals.</p> <p>While these spectra are not perfectly pure, they are sufficiently representative to be useful for further analysis. For instance, as shown in our <a href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/">previous post</a>, we used these endmember spectra for spectral unmixing and achieved excellent results, with an RMSE of only 0.0186.</p> <p>To understand the spatial context, we can reshape the extracted data back into its original image structure to visualize the locations of the purest pixels:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_3_rock_image_with_pure_pixel-480.webp 480w,/assets/img/post_3_rock_image_with_pure_pixel-800.webp 800w,/assets/img/post_3_rock_image_with_pure_pixel-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_3_rock_image_with_pure_pixel.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. False color composite hyperspectral image of a sandstone sample along with its purest pixel location. </div> <p>This example shows that N-FINDR is a powerful and intuitive algorithm for endmember extraction. Despite its limitations, such as the need for prior knowledge of the number of endmembers and the assumption of a linear mixture model, it often still provides a usefull results.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[A brief overview, ilustration and case example of N-FINDR algorithm to extract mineral endmembers in hyperspectral imagery.]]></summary></entry><entry><title type="html">Bayesian Spectral Unmixing</title><link href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/" rel="alternate" type="text/html" title="Bayesian Spectral Unmixing"/><published>2024-11-24T12:36:10+00:00</published><updated>2024-11-24T12:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/bayes-unmixing</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/bayes-unmixing/"><![CDATA[<p>In the <a href="https://nasirlukman.github.io/blog/2024/distance/">previous post</a> we discussed how spectral unmixing inherently suffers from uncertainty—stemming both from the data and the model. Traditional optimization approaches, like the one we used earlier, often assume that these uncertainties are either negligible or nonexistent. However, in practice, this is rarely the case.</p> <p>In this post, we’ll take a brief look at the <strong>Bayesian approach</strong> to <strong>spectral unmixing</strong>, which explicitly accounts for these uncertainties. By incorporating them into the model, we propagate the uncertainty through to the final results. Instead of a single vector of mineral abundances, the Bayesian approach provides a probability distribution for these abundances, offering deeper insight into the confidence we have in our estimates.</p> <p>While we won’t dive too deeply into the math, a basic formulation helps set the stage. The linear mixture model can be expressed as:</p> \[\mathbf{y} = \mathbf{E} \mathbf{a} + \mathbf{e}\] <p>where:</p> <ul> <li>\(\mathbf{y}\) is the observed spectrum,</li> <li>\(\mathbf{E}\) is the endmembers matrix,</li> <li>\(\mathbf{a}\) is the abundance vector,</li> <li>\(\mathbf{e}\) represents error terms/uncertainty.</li> </ul> <blockquote> <p>Context for this post: We are focusing on unmixing for minerals on particulate surfaces (e.g., rock surfaces). Due to multiple-scattering effects, the linear relationship above does not hold when using reflectance data. Instead, we will use the <a href="https://en.wikipedia.org/wiki/Single-scattering_albedo">Single Scattering Albedo (SSA)</a> which derived from Hapke’s Model, as it better handles these effect. For those interested in the underlying theory, I highly recommend consulting <a href="https://www.cambridge.org/core/books/theory-of-reflectance-and-emittance-spectroscopy/C266E1164D5E14DA18141F03D0E0EAB0">this book</a>; these two papers that really helps me a lot with the subject: <a href="https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/JB094iB10p13619">[1]</a>, <a href="https://www.researchgate.net/publication/264564339_A_Review_of_Nonlinear_Hyperspectral_Unmixing_Methods">[2]</a>; or other sources (including my <a href="https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;opi=89978449&amp;url=http://essay.utwente.nl/101556/1/Lukman_MA_ITC.pdf&amp;ved=2ahUKEwjqlY-m8faJAxUdw6ACHRUJKj0QFnoECBkQAQ&amp;usg=AOvVaw3Tbo1LEGrTchQ7edNZoxGt">thesis</a>😉)</p> </blockquote> <h3 id="bayesian-framework">Bayesian Framework</h3> <p>Following <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ Theorem</a>, we can represent the spectral unmixing problem as:</p> \[P(\mathbf{a}, \sigma^2 \mid \mathbf{y}, \mathbf{E}) \propto P(\mathbf{y} \mid \mathbf{a}, \sigma^2, \mathbf{E}) P(\mathbf{a}) P(\sigma^2)\] <p>where:</p> <ul> <li>\(P(\mathbf{a}, \sigma^2 \mid \mathbf{y}, \mathbf{E})\) is the posterior distribution of the abundance vector and error variance given the observed spectrum and endmembers,</li> <li>\(P(\mathbf{y} \mid \mathbf{a}, \sigma^2, \mathbf{E})\) is the likelihood of the observed spectrum,</li> <li>\(P(\mathbf{a})\) is the prior distribution of the abundance vector,</li> <li>\(P(\sigma^2)\) is the prior distribution of the error variance,</li> <li>and \(\propto\) denote proportionality</li> </ul> <p>We assume that the error term \(\mathbf{e}\) is normally distributed, giving us a <a href="https://distribution-explorer.github.io/continuous/normal.html">Normal</a> likelihood:</p> \[P(\mathbf{y} \mid \mathbf{a}, \sigma^2, \mathbf{E}) = \mathcal{N}(\mathbf{y} \mid \mathbf{E}\mathbf{a}, \sigma^2\mathbf{I}),\] <p>where \(\mathbf{I}\) is the identity matrix.</p> <p>For the abundance vector \(\mathbf{a}\), we use a <a href="https://distribution-explorer.github.io/multivariate_continuous/dirichlet.html">Dirichlet</a> prior to enforce the non-negativity and sum-to-one constraints:</p> \[P(\mathbf{a}) = \mathcal{D}(\mathbf{a} \mid \boldsymbol{\alpha}),\] <p>where \(\boldsymbol{\alpha}\) is the concentration parameter.</p> <p>For the error variance \(\sigma^2\), we assign a <a href="https://distribution-explorer.github.io/continuous/halfcauchy.html">Half-Cauchy</a> prior:</p> \[P(\sigma^2) = \mathcal{HC}(\sigma^2 \mid \beta),\] <p>with the scale hyperparamter \(\beta\) given a <a href="https://distribution-explorer.github.io/continuous/uniform.html">Unifrom</a> prior such as:</p> \[P(\beta) = \mathcal{U}(\beta \mid 0, 0^{-4}).\] <p>Therefore, we can summarize the hierarchical structure of the random variables as:</p> \[\mathbf{y} \sim \mathcal{N}(\mathbf{E}\mathbf{a}, \sigma^2\mathbf{I})\] \[\mathbf{a} \sim \mathcal{D}(\boldsymbol{\alpha})\] \[\sigma^2 \sim \mathcal{HC}(\beta)\] \[\beta \sim \mathcal{U}(0, 10^{-4})\] <p>As you might guess, this formulation of the posterior distribution cannot be solved analytically. Instead, we use <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"><em>Markov Chain Monte Caelo (MCMC)</em></a> to sample and estimate the posterior. For educational purposes, I’ve implemented a custom sampler based on the <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"><em>Metropolis-Hastings Random Walk</em></a> in Python. In practice, however, modern samplers like <em>NUTS (No-U-Turn Sampler)</em> in an established library such as <a href="https://www.pymc.io/welcome.html">PyMC</a> are often preferable. They offer a more efficient and streamlined sampling process, sparing users the burden of directly managing the nasty mathematics behind these algorithms.</p> <p>In the Metropolis-Hastings algorithm, we iteratively draw samples from the posterior. For each new sample, we evaluate its probability relative to the previous sample. The sample is either accepted or rejected based on this evaluation. Over many iterations, the density of accepted samples approximates the true posterior distribution.</p> <p>For illustration, the animation below shows the random walk process for sampling abundance parameters in a mixture of three endmembers. The blue regions represent the true target distribution. Notice how the sampler, starting from a random point in the parameter space, gradually converges to the high-probability regions:</p> <div style="display: flex; justify-content: center;"> <img src="/assets/img/post_2_random_walk.gif" alt="Random Walk"/> </div> <div class="caption"> Image 1. Random Walk Example on a known target distribution </div> <h3 id="practical-example">Practical Example</h3> <p>In this example, we will analyze a sandstone rock sample. Rock samples are ideal for testing this method since they represent natural surfaces and still allow us to conduct other detailed analytical measurements with laboratory instruments to produce high-quality ‘ground truth’ data for comparison with our results.</p> <p>For the endmembers, we consider three primary components of sandstone: quartz (grains), clay (matrix), and carbonates (cement). The endmember spectra for these minerals are assumed to be known, either from direct laboratory measurements, spectral libraries, or endmember extraction algorithms for hyperspectral imagery. We begin with a single mixed spectrum, as shown in the image below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_data-480.webp 480w,/assets/img/post_2_data-800.webp 800w,/assets/img/post_2_data-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_data.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Endmember spectra for Carbonate, Quartz, Clay minerals, and the observed mixed spectra </div> <p>Using our Metropolis-Hastings sampler, we draw four chains of \(10^5\) random samples, tuning them carefully to ensure we only consider representative samples. For simplicity, we focus solely on the mineral abundances and omit other parameters. Below, we display the abundance trace plots alongside their corresponding marginal posterior distributions. The mean value (expected values) of the samples and the true abundance values are also shown as comparison. The RMSE for this result is 0.0209.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_trace_plot-480.webp 480w,/assets/img/post_2_trace_plot-800.webp 800w,/assets/img/post_2_trace_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_trace_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Marginal posterior distribution of each endmembers abundance and its trace plots </div> <p>There are some cool things that we can do with the posteriors. For instance, we can visualize parameter correlations using a corner plot, as shown below. Note as well how we denote the result with some notation such as: \(0.14_{-0.12}^{+0.16}\) where the central value represents the expected value, while the subscript and superscript indicate the range of possible value within 90% confidence interval.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_corner_plot-480.webp 480w,/assets/img/post_2_corner_plot-800.webp 800w,/assets/img/post_2_corner_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_corner_plot.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Corner plot of the marginal posterior showing correlations between each endmember abundances. Red and blue line represent the expected value (mean) and the true value. The black stripped line represent the boundary of 90% confidence interval. </div> <p>Corner plots are a really useful visualization, especially for high-dimensional parameter spaces. For this three-parameter example, however, we can also visualize the posterior on a ternary diagram:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_ternary-480.webp 480w,/assets/img/post_2_ternary-800.webp 800w,/assets/img/post_2_ternary-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_ternary.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Ternary plot of the posterior of the abundances. Red and blue dot represent the expected value (mean) and the true value. </div> <p>The corner and ternary plots reveal a strong correlation between carbonate and quartz abundances. As carbonate increases, the algorithm compensates by reducing quartz to maintain a reasonable modeled spectrum that aligns with the observed data. Instead of a single modeled spectrum, the output is a distribution of spectra, visualized below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_modeled_spectra-480.webp 480w,/assets/img/post_2_modeled_spectra-800.webp 800w,/assets/img/post_2_modeled_spectra-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_modeled_spectra.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Observed spectra vs distribution of the modeled spectra </div> <p>This visualization highlights that, given the data and assumed uncertainties, the reasonable set of modeled spectra is represented by the 2D Normal distribution visualize by its percentiles as shown on the image above.</p> <h3 id="hyperspectral-images">Hyperspectral Images</h3> <p>The same process applies to hyperspectral images on a pixel-by-pixel basis. Here, we analyze a hyperspectral image of a sandstone drill core sample. Remember that for individual spectra (or also pixel in this case) the sampler will need to take and store \(10^{5}\) sample for each parameters. This means that the final result will be a huge 4D array, and the computation might take some time, depending on the efficiency of the sampling algorithm used. Below, we visualize the expected abundance values for each endmember and their 90% confidence intervals range:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_2_rock_sample-480.webp 480w,/assets/img/post_2_rock_sample-800.webp 800w,/assets/img/post_2_rock_sample-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_2_rock_sample.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Bayesian spectral unmixing result on a hyperspectral image of a rock sample </div> <p>Comparing our bulk results with <a href="https://en.wikipedia.org/wiki/QEMSCAN">QEMSCAN</a> results, we can achieve excellent agreement with an RMSE of 0.0186.</p> <p>It’s important to highlight that quantification through imaging techniques like this does more than just identify mineral abundances—it also provides a detailed view of the rock’s texture. By analyzing mineral distributions and their spatial relationships, we can potentially infer other critical physical properties of the rock such as porosity and permeability, which might be really usefult for application like reservoir characterization and groundwater studies.</p> <p>The inclusion of uncertainty measurement in spectral unmixing offers an important insights into the reliability of the results. Rather than relying solely on point estimates, we gain a more nuanced understanding of the possible variations and correlations in parameter space. This is particularly valuable when making decisions based on complex data, as it helps avoid overconfidence and identifies parameters requiring further refinement. In mineral quantification, understanding uncertainties can reveal how robust the mineral abundance estimates are, guiding both data interpretation and future analyses.</p> <p>Hyperspectral imaging, as demonstrated in this example, have the potential for a more fast and cost-effective alternative of mineral abundance mapping compared to other laboratory method. Moreover, it has the potential to scale up to airborne and satellite platforms, making it one of a kind method for larger-scale mineral mapping and monitoring.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Bayesian approach on spectral unmixing with an example case using hyperspectral images of sandstone drill core sample.]]></summary></entry><entry><title type="html">Different Distance Metrics Example in Spectral Unmixing</title><link href="https://nasirlukman.github.io/blog/2024/distance/" rel="alternate" type="text/html" title="Different Distance Metrics Example in Spectral Unmixing"/><published>2024-11-15T23:36:10+00:00</published><updated>2024-11-15T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2024/distance</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2024/distance/"><![CDATA[<p>In data space, distance is commonly used to measure the similarity between data points. For instance, if points <em>a</em> and <em>b</em> are “close” to each other (i.e., have a small distance), they are considered more similar. This concept is essential in machine learning and data analysis as it can be used to quantifies similarity between datasets.</p> <p>In two dimensions, it’s easy to visualize data points and assess their distances, such as in this example:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_image_1_three_point_distance-480.webp 480w,/assets/img/post_1_image_1_three_point_distance-800.webp 800w,/assets/img/post_1_image_1_three_point_distance-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_image_1_three_point_distance.jpg" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Three points in two dimensional space, illustrating the concept of distance. </div> <p>Visually, most of us would agree that points <em>a</em> and <em>b</em> appear closer in distance to each other compared to <em>a</em> and <em>c</em>. But is this really the case? To confirm, we need to define what we mean by “distance” and calculate the distance between each point.</p> <p>In this post, we will examine three different distance metrics and compare their performance in a hypothetical spectral unmixing problem: <em>Euclidean distance, Manhattan distance, and angular distance.</em> I think it is easier to first take a look the visualization of how each metrics measure distance:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_image_2_three_type_of_distance-480.webp 480w,/assets/img/post_1_image_2_three_type_of_distance-800.webp 800w,/assets/img/post_1_image_2_three_type_of_distance-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_image_2_three_type_of_distance.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Comparison of how Euclidean, Manhattan, and Angular distances measure relationships between points. </div> <p>I think this ilustration cleary shows the distinction between how the three metrics measure distance, to formalize this, let’s go to each metrics and see its mathematical formulation.</p> <h3 id="euclidean-distance">Euclidean Distance</h3> <p>The most common and intuitive distance is Euclidean distance, also often referred to as \(L_2\) distance. Between two points \(a\) and \(b\) in data space, Euclidean distance is simply the straight-line distance between the points, which can be expressed mathematically as:</p> \[L_2 = \sqrt{\sum_{i=1}^n (a_i - b_i)^2}\] <h3 id="manhattan-distance">Manhattan Distance</h3> <p>Another way to measure distance from \(a\) to \(b\) is to follow a path parallel to the axis. For example, in the image below, we first move parallel to the y-axis for 1 units, followed by a parallel path along the x-axis for 1 units, and then sum the total path length. This type of “gridded” path is called Manhattan distance (after the gridded road pattern of Manhattan) or \(L_1\) distance. Mathematically, it can be expressed as:</p> \[L_1 = \sum_{i=1}^n |a_i - b_i|\] <h3 id="angular-distance">Angular Distance</h3> <p>For angular distance \((\theta)\), we treat points \(a\) and \(b\) as two vectors originating from the origin \((0,0)\). The angular distance is simply the angle between the two vectors, expressed as:</p> \[\theta = \arccos \left( \frac{a \cdot b}{\|a\| \|b\|} \right)\] <p>In machine learning, angular distance is more commonly referred to as <em>cosine similarity</em> (measured as the cosine of the angle). In spectral analysis, this is often called <em>Spectral Angle Mapping (SAM)</em> and is widely used for spectral matching. Mathematically, angular distance is only valid as a metric if we normalize our data to unit vectors. For unit vectors, this measurement gives the same result as Euclidean distance after normalizing the data.</p> <p>From these definitions of the three distance metrics, lets return to our initial visualization (Image 1): Is point <em>a</em> closer to point <em>b</em> than to point <em>c</em> ? Again, the answer depends on the distance metric. Using Euclidean and Manhattan distances, this statement holds true. However, with angular distance, it is actually false, while <em>a</em> and <em>b</em> have a non-zero angular distance, <em>a</em> and <em>c</em> actually have an angular distance of \(0\). So using this metric, <em>c</em> is closer to <em>a</em> compared to <em>b</em>! I think this simple example already ilustrate how crutial it is to understand the distinction between different distance metrics and in which cases using one is prefered compared to the others.</p> <h2 id="example-case-linear-spectral-unmixing">Example Case: Linear Spectral Unmixing</h2> <p>To illustrate cases in which each distance metric is more appropriate, let’s use linear spectral unmixing as an example. Spectral unmixing is an important analytical technique in remote sensing used to decompose mixed pixel values into their constituent spectral signatures, known as endmembers, and their respective abundances. This process is essential for applications requiring sub-pixel level analysis, such as land cover classification, resource exploration, and environmental monitoring.</p> <p>An important aspect of spectral unmixing is the choice of distance metrics, which measure the similarity or dissimilarity between observed pixel spectra and modeled spectra. The selection of an appropriate metric significantly impacts the accuracy and performance of unmixing algorithms. Understanding these metrics helps optimize the unmixing process, especially in scenarios with high spectral variability or noise.</p> <p>Assuming a linear mixture model, a mixed spectrum of several different endmembers is defined as:</p> \[\mathbf{y} = \mathbf{E} \mathbf{a} + \mathbf{n}\] <p>where:</p> <ul> <li>\(\mathbf{y}\) is the observed spectrum,</li> <li>\(\mathbf{E}\) is the endmembers matrix,</li> <li>\(\mathbf{a}\) is the abundance vector,</li> <li>\(\mathbf{n}\) represents noise.</li> </ul> <p>In this equation, \(\mathbf{y}\) is known from observation, and for simplicity, we assume that a matrix of possible endmembers \(\mathbf{E}\) is also known, and noise \(\mathbf{n}\) is negligible.</p> <p>The goal is to solve for \(\mathbf{a}\) by minimizing the difference between the modeled spectrum \(\mathbf{E} \mathbf{a}\) and the observed spectrum \(\mathbf{y}\), under the conditions that all values of \(\mathbf{a}\) are non-negative and summed-to-one. This may achieved by solving this optimization problem:</p> \[\min_{\mathbf{a}} \; D(\mathbf{y} - \mathbf{E} \mathbf{a})\] <p>subject to:</p> \[\mathbf{a}_i \geq 0 \quad \text{and} \quad \sum_{i=1}^{n} \mathbf{a}_i = 1\] <p>This is where distance metrics \(D(•)\) come into play. The difference we are trying to minimize can be calculated using different distance metrics. Different distance metrics can lead to different results.</p> <p>Now, let’s run some tests under various simplified scenarios to see how each distance metric performs.</p> <h3 id="test-01-mixture-with-gaussian-noise">Test 01: Mixture with Gaussian Noise</h3> <p>For the first test, suppose we have four mineral endmembers (example taken from USGS Spectral Library), as shown below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_image_3_four_endmembers-480.webp 480w,/assets/img/post_1_image_3_four_endmembers-800.webp 800w,/assets/img/post_1_image_3_four_endmembers-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_image_3_four_endmembers.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Endmember spectra for Calcite, Kaolinite, Muscovite, and Quartz </div> <p>We’ll generate 1000 synthetic mixtures with the following conditions:</p> <ol> <li>The mixtures follow the linear mixture model equation.</li> <li>Noise is normally distributed with a mean of \(0\) and a standard deviation chosen randomly between \(10^{-5}\) and \(10^{-3}\).</li> </ol> <p>The accuracy of the spectral unmixing using the three distance metrics are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_first_test-480.webp 480w,/assets/img/post_1_first_test-800.webp 800w,/assets/img/post_1_first_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_first_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p>In this case, <strong>Euclidean distance</strong> clearly outperforms the other two metrics, as it is well-suited for data with normally distributed noise. Under these conditions, minimizing Euclidean distance is equivalent to <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood estimation</a>.</p> <h3 id="test-02-mixture-with-random-spikes">Test 02: Mixture with Random ‘Spikes’</h3> <p>For the second test, instead of adding normal noise, this time we add random “spikes,” where each wavelength band has a \(1\%\) chance of being randomly increased or decreased by a value between \(0.05\) and \(0.2\). While this type of noise is not common in remote sensing or spectroscopy, it will help us illustrate the strengths of Manhattan distance. The accuracy of the spectral unmixing of these synthetic mixtures are shown below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_second_test-480.webp 480w,/assets/img/post_1_second_test-800.webp 800w,/assets/img/post_1_second_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_second_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p>Here, <strong>Manhattan distance</strong> outperforms the other metrics. Manhattan distance is known to be more robust to extreme outliers than Euclidean distance, which squares the error term, making it sensitive to outliers. In contrast, Manhattan distance only takes the absolute value of location differences, making it less affected by outliers.</p> <h3 id="test-03-mixture-with-brightness-difference">Test 03: Mixture with Brightness Difference</h3> <p>While random spikes in reflectance values may not be common in spectroscopy or remote sensing, brightness differences and inaccurate endmembers spectra are issues that often arise with real datasets. To illustrate this problem, let’s randomly add random constant between \(-0.2\) to \(0.2\) to the mixture. This experiment is a simplified simulation of real world scenario where different terrains and illumination condition might cause the sensor to recieve the signal with different intensity if not corrected appropriately.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_third_test-480.webp 480w,/assets/img/post_1_third_test-800.webp 800w,/assets/img/post_1_third_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_third_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p>In this case, <strong>angular distance</strong> (or SAM) has the lowest error, as it essentially ignores magnitude (brightness) differences and focuses on the shape of the spectra. To illustrate further, take a look at the two spectra below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_kaolinite-480.webp 480w,/assets/img/post_1_kaolinite-800.webp 800w,/assets/img/post_1_kaolinite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_kaolinite.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Two kaolinite spectra with different brightness </div> <p>The two spectra above have identical shape but different brightness values. These two spectra may be considered different by Manhattan and Euclidean distances, but angular distance would see them as identical. This feature is one reason why angular distance is widely used in remote sensing applications, where brightness differences due to terrains and illuminations effects are common.</p> <h3 id="test-04-a-more-complicated-mixture">Test 04: A More Complicated Mixture</h3> <p>Now let’s consider a more complex scenario. We will use a larger spectral library, selecting 10 minerals from the USGS spectral library. To generate a mixture, we will randomly select between 2 to 4 endmembers from this library. Since the actual selected minerals are unknown, all 10 possible endmembers will be included in the unmixing process. This situation, where many variables (10 possible endmembers) are considered, but only a few (2–4 endmembers) are non-zero, is known as a <em>sparsity problem.</em></p> <p>Typically, sparsity issues are addressed by incorporating regularization terms into the optimization function. However, for this simple trial, we will not include any regularization and will apply the same spectral unmixing method used in the previous three tests. This allows us to focus solely on the challenges posed by increased complexity in the spectral library.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_10_endmembers-480.webp 480w,/assets/img/post_1_10_endmembers-800.webp 800w,/assets/img/post_1_10_endmembers-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_10_endmembers.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. 10 Endmembers Spectra </div> <p>We will also add an gaussian noise, uniform noise, gamma noise, poisson noise, and random constant as brightness modifier. The image below ilustrate each of the noises:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_noises-480.webp 480w,/assets/img/post_1_noises-800.webp 800w,/assets/img/post_1_noises-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_noises.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 9. Each noises added to the mixture. </div> <p>The unmixing accuracy results are shown in histograms below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_1_forth_test-480.webp 480w,/assets/img/post_1_forth_test-800.webp 800w,/assets/img/post_1_forth_test-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/post_1_forth_test.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 10. Histogram showing the accuracy (RMSE) of 1000 sepctral unmixing using three different distance metrics </div> <p><strong>Manhattan distance</strong> performed exceptionally well in this last case study, which probably can be attributed to its robustness to ouliers and more varying noise types. Despite this, its non-differentiable nature (since its an absolute value function) makes it less appealing for gradient-based optimization algorithms, especially for larger, more complex datasets. For this particular test, Manhattan distance takes 43 seconds for 1,000 data points, compared to 14 seconds for Euclidean distance and 11 seconds for angular distance.</p> <p>This study highlights the importance of carefully selecting the appropriate distance metric based on the nature of the data and the problem being addressed. While Euclidean distance is often the default choice, Manhattan distance or angular distance can outperform it in specific scenarios, as demonstrated in the experiments above.</p> <p>On a final note, it’s important to emphasize that the unmixing approach presented here operates under the assumption of a perfect model and data. In real-world scenarios, this is rarely the case, so we should generally expect the results to be slightly less accurate. However, it’s crucial to acknowledge that spectral unmixing inherently involves significant uncertainty. A more robust approach to address this uncertainty is to adopt a <em>Bayesian framework</em>, which offers a natural way to model such problems. This will be the topic of our <a href="https://nasirlukman.github.io/blog/2024/bayes-unmixing/">next discussion</a>.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Comparison between Euclidean distance, Manhattan distance, and angular distance in spectral unmixing of mineral endmembers.]]></summary></entry><entry><title type="html">Using Raster Calculator in QGIS GUI and Python Console to Make SR Blocks</title><link href="https://nasirlukman.github.io/blog/2021/Raster-Calculator/" rel="alternate" type="text/html" title="Using Raster Calculator in QGIS GUI and Python Console to Make SR Blocks"/><published>2021-08-08T23:36:10+00:00</published><updated>2021-08-08T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2021/Raster-Calculator</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2021/Raster-Calculator/"><![CDATA[<p>Raster Calculator is a robust way to execute a map algebra operation on raster image(s) using a user-friendly calculator-like format. It is a commonly available feature on any GIS software such as ArcGIS and QGis. Raster itself is one of the commonly used data formats in GIS which stores data in cells or pixels and organizes it into rows and columns (position) and each cell or pixel contains a value that represents certain information (visualized as colors). We can use a raster calculator to exploit these array-like properties of raster data to run any map algebra operation on each pixel in a robust way.</p> <p>The benefit of calculating SR in a raster calculator, rather than in any build-up function that your software already provides, is the flexibility of the operation that you can run. Now today we will try to perform a calculation to generate raster data containing a stripping ratio value of each pixel area given the topographic elevation data, and roof and floor elevation of each seam (we will use two seams for this example, let’s name it Seam A and Seam B).</p> <h2 id="raster-calculator-with-qgis-gui">Raster Calculator with QGIS GUI</h2> <h3 id="data-preparation">Data Preparation</h3> <p>Readily available raw elevation data is usually stored in a vector format of in [x,y,z] point text format; so first, we need to convert our data format. If our points data are already in a grid structure, we can perform conversion directly with vector to raster which in QGIS can be found in <strong><em>Raster&gt;Conversion&gt;Rasterized(Vector to Raster)</em></strong>. If our data point is not neatly and densely structured then it becomes an interpolation problem. There are a lot of interpolation methods that we can pick, depending on our initial data and our desired products. For this purpose, I will use IDW Interpolation that in QGIS can be found in <em>**Processing&gt;Toolbox&gt;Interpolation&gt;IDW Interpolation **</em>. Below is an example of IDW interpolation from my topography data.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_6_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_6_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_6_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_6_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. IDW interpolation of topo data points. </div> <p>After all our data layers are ready in raster format, it is always a good idea to check the relationship of our datasets to get a better feel of what we are dealing with, for this example, we will try to make quick cross-sections. There is a very useful plugin in QGIS that I like to use to make a cross-section called <a href="https://plugins.qgis.org/plugins/profiletool/">Profile Tool</a>. You can install this plugin in <strong><em>Plugins&gt;Manage and install plugins…</em></strong> and search for Profile Tool in the search bar. In our data example today, we can see that we have two seams with pretty simple geometry that have a northwest dip direction.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_8_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_8_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_8_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_8_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Quick inspection of the cross section with QGIS Profile Tool. </div> <h3 id="using-raster-calculator">Using Raster Calculator</h3> <p>After all of our data are ready in raster format, we can start to write our expression in the raster calculator. First, open up the raster calculator in <strong><em>Raster&gt;Raster calculator…</em></strong>. The GUI of the raster calculator is pretty straightforward and easy to get used to. every operation, variables, field, layer, etc are stored in the graphic interface so we can just write in using our mouse if we want. raster calculator syntax is based on <a href="https://desktop.arcgis.com/en/arcmap/latest/extensions/spatial-analyst/map-algebra/what-is-map-algebra.htm">map algebra</a>, which is basically an easier-to-read type of algebra.</p> <p>now if we want to make SR blocks, first we have to figure out the expression to calculate it. The simplest definition of SR is just the ratio between overburden and coal or any other valuable material of interest, both on its respective cost units. In this example, it is the ratio between overburden in bulk cubic meters (bcm) to coal in ton.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_12_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_12_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_12_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_12_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. A simple equation to compute SR blocks </div> <p>We can specify the resolution of our output raster by filling the column and row input with this formula:</p> <ul> <li>Column = (Xmax-Xmin)/desired resolution</li> <li>Row = (Ymax-Ymin)/desired resolution</li> </ul> <p>There is a good text indicator at the bottom of the window that tells us whether the expressions that we put are valid or invalid. If the expression is valid, then we can proceed and press OK, if it is invalid, then we need to check and fix our expression.</p> <p>Below is the results of our calculation above after I adjusted the Legends in layer properties.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_14_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_14_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_14_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_14_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. SR block results. </div> <p>After we are familiar with how the raster calculator works, we can run any expression that we want, for our next example, We will try to calculate operating income blocks by subtracting operating cost from revenue.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_16_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_16_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_16_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_16_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Estimating operating income blocks using price and cost assumptions. </div> <p>This is the result of that operation:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Raster_Calculator_files/Raster_Calculator_18_0-480.webp 480w,/img/Raster_Calculator_files/Raster_Calculator_18_0-800.webp 800w,/img/Raster_Calculator_files/Raster_Calculator_18_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Raster_Calculator_files/Raster_Calculator_18_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Estimated operation income blocks (in USD). </div> <h2 id="using-raster-calculator-in-qgis-python-console">Using Raster Calculator in QGIS Python Console</h2> <p>You can press Ctrl+Alt+P to open your QGIS python console. This code below will do just about the same as what we did previously in Qgis GUI, but with less clicking and layer rendering, and it’s reusable for your future needs. It is especially useful if you are experimenting with various expressions and input since you can tweak it much faster and easier. You can even modify this code a little bit and write a loop that will execute various expressions and save each of the results into different output files.</p> <blockquote> <p>If you want to reuse this code below you need to change the path and output variable, and all the parameters inside QgsRasterCalculator depending on your needs.</p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span>

<span class="n">path</span><span class="o">=</span><span class="sh">'</span><span class="s">C:/test/</span><span class="sh">'</span>
<span class="n">os</span><span class="p">.</span><span class="nf">chdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">file_list</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">lyr_dict</span><span class="o">=</span><span class="p">{}</span>
<span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">.tif</span><span class="sh">'</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">file_name</span><span class="o">=</span><span class="nb">file</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>
        <span class="n">layer_dict</span><span class="p">[</span><span class="n">file_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nc">QgsRasterLayer</span><span class="p">(</span><span class="n">path</span><span class="o">+</span><span class="nb">file</span><span class="p">),</span> <span class="n">file_name</span><span class="o">+</span><span class="sh">'</span><span class="s">@1</span><span class="sh">'</span><span class="p">]</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">path</span><span class="o">+</span><span class="sh">'</span><span class="s">block_SR.tif</span><span class="sh">'</span>
<span class="n">entries</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">lyr</span> <span class="ow">in</span> <span class="n">lyr_dict</span><span class="p">:</span>
    <span class="n">ras</span> <span class="o">=</span> <span class="nc">QgsRasterCalculatorEntry</span><span class="p">()</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">ref</span> <span class="o">=</span> <span class="n">lyr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">raster</span> <span class="o">=</span> <span class="n">lyr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">bandNumber</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">entries</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">ras</span><span class="p">)</span>
    <span class="n">index</span><span class="o">+=</span><span class="mi">1</span>
    
<span class="n">calc</span> <span class="o">=</span> <span class="nc">QgsRasterCalculator</span><span class="p">(</span><span class="sh">'</span><span class="s">(((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1))*10*1.3*65)</span><span class="se">\
</span><span class="s">                           -((((topo@1 - floor_b@1)-((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1)))*10*2.2)</span><span class="se">\
</span><span class="s">                           +1.135*(((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1))*10*1.3*15))</span><span class="sh">'</span><span class="p">,</span> 
                           <span class="n">output</span><span class="p">,</span> <span class="sh">'</span><span class="s">GTiff</span><span class="sh">'</span><span class="p">,</span> <span class="n">topo</span><span class="p">.</span><span class="nf">extent</span><span class="p">(),</span> <span class="nf">int</span><span class="p">(</span><span class="n">topo</span><span class="p">.</span><span class="nf">width</span><span class="p">()</span><span class="o">/</span><span class="mi">10</span><span class="p">),</span> <span class="nf">int</span><span class="p">(</span><span class="n">topo</span><span class="p">.</span><span class="nf">height</span><span class="p">()</span><span class="o">/</span><span class="mi">10</span><span class="p">),</span> <span class="n">entries</span><span class="p">)</span>
<span class="n">calc</span><span class="p">.</span><span class="nf">processCalculation</span><span class="p">()</span>
</code></pre></div></div> <p>Here is a quick breakdown of the code above:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span>

<span class="n">path</span><span class="o">=</span><span class="sh">'</span><span class="s">C:/test/</span><span class="sh">'</span>
<span class="n">os</span><span class="p">.</span><span class="nf">chdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">file_list</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">lyr_dict</span><span class="o">=</span><span class="p">{}</span>
<span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">.tif</span><span class="sh">'</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">file_name</span><span class="o">=</span><span class="nb">file</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>
        <span class="n">layer_dict</span><span class="p">[</span><span class="n">file_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nc">QgsRasterLayer</span><span class="p">(</span><span class="n">path</span><span class="o">+</span><span class="nb">file</span><span class="p">),</span> <span class="n">file_name</span><span class="o">+</span><span class="sh">'</span><span class="s">@1</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p>this code block will work to open up every raster (<em>.tif</em> extension) file in your working directory, so be sure to put all your needed raster files into one directory. After that, the loop will write those files into a layer dictionary. The dictionary will contain the name of the file without its extension as a key and its <code class="language-plaintext highlighter-rouge">QgsRasterLayer</code> class and names (which is the file name + <em>‘@1’</em>). This is the naming convention for a raster layer in which the number after <em>’@’</em> specifies the number of bands that the raster contains (in our case it is 1).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">output</span> <span class="o">=</span> <span class="n">path</span><span class="o">+</span><span class="sh">'</span><span class="s">block_SR.tif</span><span class="sh">'</span>
<span class="n">entries</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">lyr</span> <span class="ow">in</span> <span class="n">lyr_dict</span><span class="p">:</span>
    <span class="n">ras</span> <span class="o">=</span> <span class="nc">QgsRasterCalculatorEntry</span><span class="p">()</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">ref</span> <span class="o">=</span> <span class="n">lyr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">raster</span> <span class="o">=</span> <span class="n">lyr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ras</span><span class="p">.</span><span class="n">bandNumber</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">entries</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">ras</span><span class="p">)</span>
    <span class="n">index</span><span class="o">+=</span><span class="mi">1</span>
</code></pre></div></div> <p>In this block, we are using a <code class="language-plaintext highlighter-rouge">QgsRasterCalculatorEntry</code> class reference to create a list entry for every layer and its attributes such as naming reference, raster layer variable, and its band number from our <code class="language-plaintext highlighter-rouge">lyr_dict</code> dictionary. After that, we put all of our <code class="language-plaintext highlighter-rouge">QgsRasterCalculatorEntry</code> classes into a list called <code class="language-plaintext highlighter-rouge">entries</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">calc</span> <span class="o">=</span> <span class="nc">QgsRasterCalculator</span><span class="p">(</span><span class="sh">'</span><span class="s">(((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1))*10*1.3*65)</span><span class="se">\
</span><span class="s">                           -((((topo@1 - floor_b@1)-((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1)))*10*2.2)</span><span class="se">\
</span><span class="s">                           +1.135*(((roof_a@1 - floor_a@1)+(roof_b@1 - floor_b@1))*10*1.3*15))</span><span class="sh">'</span><span class="p">,</span> 
                           <span class="n">output</span><span class="p">,</span> <span class="sh">'</span><span class="s">GTiff</span><span class="sh">'</span><span class="p">,</span> <span class="n">topo</span><span class="p">.</span><span class="nf">extent</span><span class="p">(),</span> <span class="nf">int</span><span class="p">(</span><span class="n">topo</span><span class="p">.</span><span class="nf">width</span><span class="p">()</span><span class="o">/</span><span class="mi">10</span><span class="p">),</span> <span class="nf">int</span><span class="p">(</span><span class="n">topo</span><span class="p">.</span><span class="nf">height</span><span class="p">()</span><span class="o">/</span><span class="mi">10</span><span class="p">),</span> <span class="n">entries</span><span class="p">)</span>
<span class="n">calc</span><span class="p">.</span><span class="nf">processCalculation</span><span class="p">()</span>
</code></pre></div></div> <p>This is where the actual calculation occurs. <code class="language-plaintext highlighter-rouge">QgsRasterCalculator</code> takes the following parameters to run:</p> <ul> <li>expression: which can be any expression you like, written in string format</li> <li>output file path also in string. Be sure to specify the extension behind the file name</li> <li>output format which is also in string. The most commonly used file format is GTiff for <em>.tif</em> file</li> <li>the extent from the output file which is usually the same as the input extent, or any numbers depending on your needs</li> <li>nrows and ncols which define the total number of rows and columns on a given extent. For this example, since I want a 10-meter resolution raster as output and I have a 1-meter resolution for the input, I just divided my input height and width by ten</li> <li><code class="language-plaintext highlighter-rouge">entries</code> list</li> </ul> <p>Afterward, you can execute your calculation by using <code class="language-plaintext highlighter-rouge">processCalculation( )</code> function from <code class="language-plaintext highlighter-rouge">QgsRasterCalculator</code>. And the results will be the same as with our example using the GUI above.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Raster Calculator is a very useful tool to have at our disposal. Let's try it to make SR blocks]]></summary></entry><entry><title type="html">Earthquake Playthrough 01</title><link href="https://nasirlukman.github.io/blog/2021/Earthquake-Playthrough-01/" rel="alternate" type="text/html" title="Earthquake Playthrough 01"/><published>2021-08-01T23:36:10+00:00</published><updated>2021-08-01T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2021/Earthquake-Playthrough-01</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2021/Earthquake-Playthrough-01/"><![CDATA[<p>USGS provides a very useful API to their earthquake catalog called <code class="language-plaintext highlighter-rouge">libcomcat</code> which I think stands for <a href="https://github.com/usgs/libcomcat"><em>library comprehensive catalog</em></a>. In this post, we will try to use <code class="language-plaintext highlighter-rouge">libcomcat</code> to get the earthquake dataset and make some data visualization from it. Hopefully, we can exercise a few python libraries while also learning a few interesting facts about earthquakes.</p> <h1 id="using-libcomcat-to-get-our-dataframe">Using <code class="language-plaintext highlighter-rouge">libcomcat</code> to get our dataframe</h1> <p>According to its <a href="https://github.com/usgs/libcomcat/blob/master/docs/api.md">API Documentation</a> we can use the <code class="language-plaintext highlighter-rouge">search</code> module to get a <code class="language-plaintext highlighter-rouge">SummaryEvent</code> objects and use <code class="language-plaintext highlighter-rouge">get_summary_dataframe</code> to create a <code class="language-plaintext highlighter-rouge">pandas</code> Dataframe of basic information from a list of <code class="language-plaintext highlighter-rouge">SummaryEvent</code> object which contains the following columns:</p> <ul> <li>id: Authoritative ComCat event ID.</li> <li>time: Authoritative event origin time.</li> <li>latitude: Authoritative event latitude.</li> <li>longitude: Authoritative event longitude.</li> <li>depth: Authoritative event depth.</li> <li>magnitude: Authoritative event magnitude.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">libcomcat.search</span> <span class="kn">import</span> <span class="n">search</span>
<span class="kn">from</span> <span class="n">libcomcat.dataframes</span> <span class="kn">import</span> <span class="n">get_summary_data_frame</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1">#setting libcomcat search parameters
</span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[</span><span class="mf">104.414</span><span class="p">,</span> <span class="mf">127.266</span><span class="p">,</span> <span class="o">-</span><span class="mf">13.017</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.119</span><span class="p">]</span>
<span class="n">stime</span> <span class="o">=</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">1940</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">etime</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="nf">utcnow</span><span class="p">()</span>
<span class="n">minmag</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">maxmag</span> <span class="o">=</span> <span class="mf">9.9</span>

<span class="c1">#download SummaryEvent objects based on our predifined search parameters
</span><span class="n">eventlist</span> <span class="o">=</span> <span class="nf">search</span><span class="p">(</span><span class="n">starttime</span><span class="o">=</span><span class="n">stime</span><span class="p">,</span>
                  <span class="n">endtime</span><span class="o">=</span><span class="n">etime</span><span class="p">,</span>
                  <span class="n">minlatitude</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                  <span class="n">maxlatitude</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                  <span class="n">minlongitude</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                  <span class="n">maxlongitude</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                  <span class="n">minmagnitude</span><span class="o">=</span><span class="n">minmag</span><span class="p">,</span>
                  <span class="n">maxmagnitude</span><span class="o">=</span><span class="n">maxmag</span><span class="p">)</span>

<span class="c1">#write summary dataframe into pandas Dataframe
</span><span class="n">df</span> <span class="o">=</span> <span class="nf">get_summary_data_frame</span><span class="p">(</span><span class="n">eventlist</span><span class="p">)</span>
</code></pre></div></div> <blockquote> <p>Notes: Since we are trying to search SummaryEvent objects in a broad bounds area and wide time &amp; magnitude range, this may take a few minutes</p> </blockquote> <p>we can inspect the first five rows of our Dataframe using <code class="language-plaintext highlighter-rouge">data.head()</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Unnamed: 0</th> <th>id</th> <th>time</th> <th>location</th> <th>latitude</th> <th>longitude</th> <th>depth</th> <th>magnitude</th> <th>alert</th> <th>url</th> <th>eventtype</th> <th>significance</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>0</td> <td>iscgemsup901250</td> <td>1940-03-21 13:52:54.000</td> <td>south of Java, Indonesia</td> <td>-10.316</td> <td>107.677</td> <td>15.0</td> <td>6.3</td> <td>NaN</td> <td>https://www.usgs.gov/programs/earthquake-hazards/earthquakes</td> <td>earthquake</td> <td>611</td> </tr> <tr> <th>1</th> <td>1</td> <td>iscgemsup899784</td> <td>1943-04-01 14:18:17.000</td> <td>38 km W of Labuan, Indonesia</td> <td>-6.389</td> <td>105.480</td> <td>35.0</td> <td>7.1</td> <td>NaN</td> <td>https://www.usgs.gov/programs/earthquake-hazards/earthquakes</td> <td>earthquake</td> <td>776</td> </tr> <tr> <th>2</th> <td>2</td> <td>iscgem899940</td> <td>1943-07-23 14:53:10.000</td> <td>87 km SW of Srandakan, Indonesia</td> <td>-8.591</td> <td>109.803</td> <td>60.0</td> <td>7.0</td> <td>NaN</td> <td>https://www.usgs.gov/programs/earthquake-hazards/earthquakes</td> <td>earthquake</td> <td>754</td> </tr> <tr> <th>3</th> <td>3</td> <td>iscgem896483</td> <td>1949-04-23 11:15:33.000</td> <td>95 km N of Ruteng, Indonesia</td> <td>-7.763</td> <td>120.611</td> <td>20.0</td> <td>6.4</td> <td>NaN</td> <td>https://www.usgs.gov/programs/earthquake-hazards/earthquakes</td> <td>earthquake</td> <td>630</td> </tr> <tr> <th>4</th> <td>4</td> <td>iscgem896607</td> <td>1949-06-24 22:38:49.000</td> <td>42 km W of Labuan, Indonesia</td> <td>-6.381</td> <td>105.449</td> <td>60.0</td> <td>6.3</td> <td>NaN</td> <td>https://www.usgs.gov/programs/earthquake-hazards/earthquakes</td> <td>earthquake</td> <td>611</td> </tr> </tbody> </table> <p>5 rows x 12 columns</p> </div> <p>We must be cautious with the units of each variable in our data, which in this case are as follows :</p> <ul> <li>x and y coordinates in decimal degrees</li> <li>depths in kilometers below sea level</li> <li>magnitude in Moment Magnitude (Mw)</li> </ul> <blockquote> <p>We may be familiar with <em>the Ritcher Scale</em> as the unit of earthquake magnitude. Since there are a few proven inaccuracies in <em>the Ritcher Scale</em> most seismology authorities reported their magnitude in <em>Moment Magnitude</em>. These two units measure earthquake magnitude in base ten logarithmic scale and the difference between the units is quite low. Consult <a href="https://en.wikipedia.org/wiki/Seismic_magnitude_scales">wikipedia</a> for more information about this.</p> </blockquote> <h1 id="map-plot-with-basemap">Map plot with <code class="language-plaintext highlighter-rouge">Basemap</code></h1> <p>We already define our boundary area above that we use as one of the search parameters. Let’s look at the map of our area using <code class="language-plaintext highlighter-rouge">Basemap</code>. Since our coordinates are in decimal degrees, we will use <em>EPSG:4326</em> as our projection parameters. We can look at IPSG code for other projections <a href="http://epsg.io/">here</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">mpl_toolkits.basemap</span> <span class="kn">import</span> <span class="n">Basemap</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1">#define the figure
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1">#creating a basemap
</span><span class="n">m</span> <span class="o">=</span> <span class="nc">Basemap</span><span class="p">(</span><span class="n">epsg</span> <span class="o">=</span> <span class="sh">'</span><span class="s">4326</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">resolution</span> <span class="o">=</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">llcrnrlon</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
            <span class="n">llcrnrlat</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">urcrnrlon</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
            <span class="n">urcrnrlat</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">m</span><span class="p">.</span><span class="nf">shadedrelief</span><span class="p">()</span>
<span class="n">m</span><span class="p">.</span><span class="nf">drawcoastlines</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_11_0-480.webp 480w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_11_0-800.webp 800w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_11_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_11_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Study area extent </div> <p>We can plot our earthquake on a map using <code class="language-plaintext highlighter-rouge">Basemap</code> scatter with <em>longitude</em> and <em>latitude</em> as its <code class="language-plaintext highlighter-rouge">x</code> and <code class="language-plaintext highlighter-rouge">y</code> parameters. While we’re at it, let’s try to add <em>depth</em> and <em>magnitude</em> as its <code class="language-plaintext highlighter-rouge">color</code> and <code class="language-plaintext highlighter-rouge">size</code> parameters.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">mpl_toolkits.basemap</span> <span class="kn">import</span> <span class="n">Basemap</span>

<span class="c1">#define the figure
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1">#creating a basemap
</span><span class="n">m</span> <span class="o">=</span> <span class="nc">Basemap</span><span class="p">(</span><span class="n">epsg</span> <span class="o">=</span> <span class="sh">'</span><span class="s">4326</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">resolution</span> <span class="o">=</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">llcrnrlon</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
            <span class="n">llcrnrlat</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">urcrnrlon</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
            <span class="n">urcrnrlat</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">m</span><span class="p">.</span><span class="nf">shadedrelief</span><span class="p">()</span>
<span class="n">m</span><span class="p">.</span><span class="nf">drawcoastlines</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>

<span class="c1">#plotting the earthquakes
</span><span class="n">cax</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">longitude</span><span class="sh">'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">latitude</span><span class="sh">'</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
          <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_13_0-480.webp 480w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_13_0-800.webp 800w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_13_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_13_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Earthquake depth (km) </div> <p>It’s interesting how the depth of the earthquake is increasing to the north. It’s most probably related to the subducted oceanic crust depth which also must be increasing to the north. A section along the latitude would show the shape of the subducted oceanic crust, we will try to make it later.</p> <p>Another piece of information that we can get from the plot above is that the earthquakes are not distributed uniformly along the subduction zone. There are several areas with significantly fewer earthquake occurrences than it’s surroundings which are usually referred to as <a href="https://en.wikipedia.org/wiki/Seismic_gap#:~:text=A%20seismic%20gap%20is%20a,segments%20along%20the%20same%20structure."><em>seismic gap</em></a>. let’s try to make a density heatmap to get a better visualization for this. We will use <code class="language-plaintext highlighter-rouge">np.histogram</code> to calculate a gridded density of the earthquake and plot it with <code class="language-plaintext highlighter-rouge">plt.pcolormash()</code> above our <code class="language-plaintext highlighter-rouge">Basemap</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># define x,y,and z values
</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">longitude</span><span class="sh">'</span><span class="p">]</span>
<span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">latitude</span><span class="sh">'</span><span class="p">]</span>
<span class="n">z</span><span class="p">,</span> <span class="n">xedges</span><span class="p">,</span> <span class="n">yedges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">histogram2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1">#define the figure
</span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="c1">#creating a basemap
</span><span class="n">m</span> <span class="o">=</span> <span class="nc">Basemap</span><span class="p">(</span><span class="n">epsg</span> <span class="o">=</span> <span class="sh">'</span><span class="s">4326</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">resolution</span> <span class="o">=</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">llcrnrlon</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
            <span class="n">llcrnrlat</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">urcrnrlon</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
            <span class="n">urcrnrlat</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">m</span><span class="p">.</span><span class="nf">shadedrelief</span><span class="p">()</span>
<span class="n">m</span><span class="p">.</span><span class="nf">drawcoastlines</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>

<span class="c1">#plot colormesh with alpha&lt;1 for transparency
</span><span class="n">cax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">pcolormesh</span><span class="p">(</span><span class="n">xedges</span><span class="p">,</span> <span class="n">yedges</span><span class="p">,</span> <span class="n">z</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_15_0-480.webp 480w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_15_0-800.webp 800w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_15_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_15_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Earthquake density map </div> <p>we can go one step further and use <em>kernel density estimation</em> to draw a smoother density heatmap by using <code class="language-plaintext highlighter-rouge">gaussian_kde</code> from <code class="language-plaintext highlighter-rouge">scipy</code>.</p> <blockquote> <p><em>kernel density estimation</em> or KDE for short is a statistical method to estimate the probability density function of a random variable based on a finite sample. <a href="https://mathisonian.github.io/kde/">Here</a> is a very neat explanation of how KDE works on one-dimensional data.</p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.stats.kde</span> <span class="kn">import</span> <span class="n">gaussian_kde</span>

<span class="c1">#define x,y, and z values
</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">longitude</span><span class="sh">'</span><span class="p">]</span>
<span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">latitude</span><span class="sh">'</span><span class="p">]</span>
<span class="n">k</span> <span class="o">=</span> <span class="nf">gaussian_kde</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]))</span>
<span class="n">xi</span><span class="p">,</span> <span class="n">yi</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mgrid</span><span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="nf">min</span><span class="p">():</span><span class="n">x</span><span class="p">.</span><span class="nf">max</span><span class="p">():</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="o">**</span><span class="mf">0.5</span><span class="o">*</span><span class="mf">1j</span><span class="p">,</span><span class="n">y</span><span class="p">.</span><span class="nf">min</span><span class="p">():</span><span class="n">y</span><span class="p">.</span><span class="nf">max</span><span class="p">():</span><span class="n">y</span><span class="p">.</span><span class="n">size</span><span class="o">**</span><span class="mf">0.5</span><span class="o">*</span><span class="mf">1j</span><span class="p">]</span>
<span class="n">zi</span> <span class="o">=</span> <span class="nf">k</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">([</span><span class="n">xi</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(),</span> <span class="n">yi</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()]))</span>

<span class="c1">#define the figure
</span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="c1">#creating a basemap
</span><span class="n">m</span> <span class="o">=</span> <span class="nc">Basemap</span><span class="p">(</span><span class="n">epsg</span> <span class="o">=</span> <span class="sh">'</span><span class="s">4326</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">resolution</span> <span class="o">=</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">llcrnrlon</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
            <span class="n">llcrnrlat</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">urcrnrlon</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
            <span class="n">urcrnrlat</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">m</span><span class="p">.</span><span class="nf">shadedrelief</span><span class="p">()</span>
<span class="n">m</span><span class="p">.</span><span class="nf">drawcoastlines</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>

<span class="c1">#plot colormesh with alpha&lt;1 for transparency
</span><span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">pcolormesh</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="n">zi</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">xi</span><span class="p">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_18_1-480.webp 480w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_18_1-800.webp 800w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_18_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_18_1.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 4. Earthquake kernel density map </div> <p>We can see from the map above that the most notable <em>seismic gap</em> are located at the south of Central and West Java, Bali &amp; Lombok, and NTT.</p> <h1 id="cross-section">Cross Section</h1> <p>Now, to see the shape of subducting slabs below Java let’s plot our earthquake datasets along the Y coordinate cross-section. To make a properly scaled cross-section first we need to transform our coordinate from latitude/longitude in decimal degrees, into UTM in the metric unit so it has the same measurement unit with the depth. Our problem is that we are dealing with a large area that spans multiple UTM zones here, and as far as I know, there is no simple and straightforward solution to this issue. Lucky for us, Google already solved this for us when they were facing the same issue for their Google Maps projects in 2005 by inventing a new projection system called <a href="https://en.wikipedia.org/wiki/Web_Mercator_projection">Web Mercator</a>. Let us make two new columns called ‘X_WM’ and ‘Y_WM’ for our X dan Y coordinate in Web Mercator Projection. We will use <code class="language-plaintext highlighter-rouge">Transformer</code> from <code class="language-plaintext highlighter-rouge">pyproj</code> library to calculate our coordinates transformation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyproj</span> <span class="kn">import</span> <span class="n">Transformer</span>
<span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">.</span><span class="nf">from_crs</span><span class="p">(</span><span class="sh">"</span><span class="s">epsg:4326</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">epsg:3857</span><span class="sh">"</span><span class="p">,</span> <span class="n">always_xy</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">X_WM</span><span class="sh">'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">Y_WM</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">longitude</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">latitude</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div> <p>now to make our cross-section in this case we want to use ‘Y_WM’ as our X-axis in the plot, and ‘depth’ as our Y-axis. Remember that depth in our database is still in a positive kilometer so we need to transform it to a negative meter value at our plot by multiplying it by -1000.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">Y_WM</span><span class="sh">'</span><span class="p">],</span>
            <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">]</span><span class="o">*-</span><span class="mi">1000</span><span class="p">),</span>
            <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">]),</span> 
            <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">Y_WM</span><span class="sh">'</span><span class="p">]),</span> <span class="nf">max</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">Y_WM</span><span class="sh">'</span><span class="p">])),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">]</span><span class="o">*-</span><span class="mi">1000</span><span class="p">),</span> <span class="nf">max</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">]</span><span class="o">*-</span><span class="mi">1000</span><span class="p">)))</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_24_0-480.webp 480w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_24_0-800.webp 800w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_24_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_24_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 5. Y-axis cross-section of the earthquake depth shows a subduction slab shape </div> <p>Well, yeah, It’s a subduction zone alright. I wonder what our plot would look like if we use ‘X_WM’ coordinate as our X-axis. Let’s try to make one.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">X_WM</span><span class="sh">'</span><span class="p">],</span>
            <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">]</span><span class="o">*-</span><span class="mi">1000</span><span class="p">),</span>
            <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">]),</span> 
            <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">X_WM</span><span class="sh">'</span><span class="p">]),</span> <span class="nf">max</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">X_WM</span><span class="sh">'</span><span class="p">])),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">]</span><span class="o">*-</span><span class="mi">1000</span><span class="p">),</span> <span class="nf">max</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">]</span><span class="o">*-</span><span class="mi">1000</span><span class="p">)))</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_26_0-480.webp 480w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_26_0-800.webp 800w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_26_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_26_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 6. Y-axis cross-section of the earthquake depth highlight seismic gap at depth of 3km to 5 km. </div> <p>Obviously, we cannot see the shape of our subduction slab in this cross-section, but we can still get a piece of good information with this visualization. Note another <em>seismic gap</em> around depth 3 km to 5 km. <em>Seismic gaps</em> do not only occur on a horizontal plane but also on a vertical plane. We cannot see this gap clearly on our previous cross-section because our visualization is distracted by an anomaly at the eastern part of our area where apparently there is not much seismic gap there. If you look back at our map plot, you can see that this anomalous area is in the southern part of Sulawesi. Well as any Geologist knows, there are a lot of suspicious things going on in Sulawesi’s tectonic settings, so this kind of anomaly comes as no surprise.</p> <h1 id="depth-and-magnitude-distribution">Depth and magnitude distribution</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">'</span><span class="s">ggplot</span><span class="sh">'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Depth Distribution</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">freq</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">km</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="sh">'</span><span class="s">min = %.2f</span><span class="se">\n</span><span class="s">max = %.2f</span><span class="se">\n</span><span class="s">mean = %.2f</span><span class="se">\n</span><span class="s">median = %.2f</span><span class="sh">'</span>
           <span class="o">%</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">max</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">median</span><span class="p">()),</span>
           <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">,</span>
           <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">top</span><span class="sh">'</span><span class="p">,</span>
           <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">transAxes</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Magnitude Distribution</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Mw</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span> 
          <span class="sh">'</span><span class="s">min = %.2f</span><span class="se">\n</span><span class="s">max = %.2f</span><span class="se">\n</span><span class="s">mean = %.2f</span><span class="se">\n</span><span class="s">median = %.2f</span><span class="sh">'</span>
           <span class="o">%</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">max</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">median</span><span class="p">()),</span>
           <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">,</span>
           <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">top</span><span class="sh">'</span><span class="p">,</span>
           <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">transAxes</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_29_0-480.webp 480w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_29_0-800.webp 800w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_29_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_29_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 7. Histograms of Depths and Magnitudes. </div> <p>The interesting thing to notice in this depth distribution is the anomaly at the deep-focal earthquake, earthquake frequency seems to get lower with depth and reach its lowest point at around 300 km, this is expected due to the increasing plasticity of slabs with depths due to increasing pressure and temperature. What is quite unexpected is the rise of the frequency at around 500 km (it is important to note that deep-focus earthquakes are only observed around a subduction zone, so it is safe to assume that it is directly related to subduction activity). One possible explanation of the deep-focus earthquake is transformational faulting in metastable peridotite wedges within a cold slab. Where the mechanical faulting at those depths is hard to explain, some models suggest that transformational faulting due to polymorphic reactions in which olivine transforms to the spinel structure and clinoenstatite transforms to ilmenite may cause such shear instability (<a href="https://www.earth.northwestern.edu/public/emile/PDF/EAO104.pdf">Kirby et al., 1996</a>). This effect of decreasing seismic activity with depth until it reaches the depth where olivine and clinoesntatie transformation occurs where there is a little bump in the earthquake frequency caused an apparent seismic gap in the vertical plane which occurs at around 300 to 500 km.</p> <p>What is surprising for me is the distribution of the magnitude which closely resembles a normal distribution with mean and median values close to each other (or we can say it a log-normal distribution since the magnitudes are in the Ritcher Scale which is a logarithmic scale) rather than resembling a power-law distribution. As for now, I can’t find any explanation for this, whether this is really the case or we actually have a problem with our datasets where USGS has difficulties in detecting the smaller magnitude earthquakes. This <a href="https://en.wikipedia.org/wiki/Gutenberg%E2%80%93Richter_law#Background">wikipedia page</a> suggests the latter would be the case but also mentions some earthquake dynamics models that explain the lower frequency in lower magnitude earthquakes physically.</p> <p>Now it is probably a good idea to split our dataset into several categories and see the distribution of each. Let’s split the depth into three categories based on <a href="https://www.usgs.gov/natural-hazards/earthquake-hazards/science/determining-depth-earthquake?qt-science_center_objects=0#qt-science_center_objects">USGS classification</a> into:</p> <ul> <li>shallow earthquake (0-70)km</li> <li>intermediate earthquake (70-300)km</li> <li>deep earthquake(&gt;300)km</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth_classification</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sh">'</span><span class="s">shallow</span><span class="sh">'</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span><span class="mi">70</span> <span class="nf">else</span><span class="p">(</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span><span class="mi">300</span> <span class="k">else</span> <span class="sh">'</span><span class="s">intermediate</span><span class="sh">'</span><span class="p">))</span>

</code></pre></div></div> <p>In the line above we will use <code class="language-plaintext highlighter-rouge">apply()</code> and <code class="language-plaintext highlighter-rouge">lambda</code> to make a new column called <code class="language-plaintext highlighter-rouge">'depth_classification'</code> in <code class="language-plaintext highlighter-rouge">df</code> Dataframe and put values on it based on the condition in column <code class="language-plaintext highlighter-rouge">depth</code>.</p> <p>Since we need to draw a lot of histograms for depth and magnitude distribution in every classification, let’s write a function to draw it more efficiently</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">classification_histogram</span><span class="p">(</span><span class="n">class_list</span><span class="p">,</span> <span class="n">classification_type</span><span class="p">,</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="n">ncols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
    <span class="n">row</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">nclass</span> <span class="ow">in</span> <span class="n">class_list</span><span class="p">:</span>
        <span class="n">string</span> <span class="o">=</span> <span class="nf">str</span><span class="p">(</span><span class="n">nclass</span><span class="p">[</span><span class="n">classification_type</span><span class="o">+</span><span class="sh">'</span><span class="s">_classification</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">())[</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">row</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span><span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">row</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="n">string</span> <span class="o">+</span><span class="sh">'</span><span class="s"> earthquake depth distribution</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">row</span><span class="p">].</span><span class="nf">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="sh">'</span><span class="s">min = %.2f</span><span class="se">\n</span><span class="s">max = %.2f</span><span class="se">\n</span><span class="s">mean = %.2f</span><span class="se">\n</span><span class="s">median = %.2f</span><span class="se">\n</span><span class="s">count =%i</span><span class="sh">'</span>
                   <span class="o">%</span><span class="p">(</span><span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">min</span><span class="p">(),</span> <span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">max</span><span class="p">(),</span> <span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(),</span> 
                     <span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">median</span><span class="p">(),</span> <span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">].</span><span class="nf">count</span><span class="p">()),</span>
                   <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">,</span>
                   <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
                   <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">top</span><span class="sh">'</span><span class="p">,</span>
                   <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">row</span><span class="p">].</span><span class="n">transAxes</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">row</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span><span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">row</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="n">string</span> <span class="o">+</span><span class="sh">'</span><span class="s"> earthquake magnitude distribution</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">row</span><span class="p">].</span><span class="nf">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="sh">'</span><span class="s">min = %.2f</span><span class="se">\n</span><span class="s">max = %.2f</span><span class="se">\n</span><span class="s">mean = %.2f</span><span class="se">\n</span><span class="s">median = %.2f</span><span class="se">\n</span><span class="s">count =%i</span><span class="sh">'</span>
                   <span class="o">%</span><span class="p">(</span><span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">min</span><span class="p">(),</span> <span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">max</span><span class="p">(),</span> <span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(),</span> 
                     <span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">median</span><span class="p">(),</span> <span class="n">nclass</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">count</span><span class="p">()),</span>
                   <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">,</span>
                   <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">top</span><span class="sh">'</span><span class="p">,</span>
                   <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
                   <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">row</span><span class="p">].</span><span class="n">transAxes</span><span class="p">)</span>
        <span class="n">row</span><span class="o">+=</span><span class="mi">1</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
</code></pre></div></div> <p>the function above is pretty simple and straightforward, the inline string syntax is not the most pleasant syntax to read, but it is pretty efficient.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">depth_class_list</span><span class="o">=</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth_classification</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">shallow</span><span class="sh">'</span><span class="p">],</span>
                  <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth_classification</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">intermediate</span><span class="sh">'</span><span class="p">],</span>
                  <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">depth_classification</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">]]</span>
<span class="nf">classification_histogram</span><span class="p">(</span><span class="n">depth_class_list</span><span class="p">,</span><span class="sh">'</span><span class="s">depth</span><span class="sh">'</span><span class="p">,</span><span class="mi">2</span> <span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_36_0-480.webp 480w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_36_0-800.webp 800w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_36_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_36_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 8. Histograms of different earthquake depth classification. </div> <p>At this stage, I think the normality assumption is reasonable and it could be the basis to split our depth dataset into several groups in our classification. If we look at depth distribution in our present classification, there are still indications of mixing population since we still don’t have an unimodal distribution. I think it is a good idea to try multiple Gaussian fixes in the data in the future, for now, we will settle with this USGS classification.</p> <p>I still don’t think it is a good idea to assume normality in magnitude distribution since I assume that smaller magnitude earthquake occurrences are exponentially higher than larger magnitude occurrences. But since our initial dataset distribution for magnitude shows a normal behavior, I imagine our classification should preserve the shape of the original data (which is the case for this classification), since I assume that earthquake magnitude spreads with the same behavior in all depths. Well, let’s try to split our magnitude to see if that assumption holds!</p> <p>We will divide our magnitude data into several groups based on <a href="http://www.geo.mtu.edu/UPSeis/magnitude.html">this classification</a> into:</p> <ul> <li>minor earthquake (&lt;4)Mw</li> <li>light earthquake (4-5)Mw</li> <li>moderate earthquake (5-6)Mw</li> <li>strong earthquake (6-7)Mw</li> <li>great earthquake (&gt;7)Mw</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude_classification</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sh">'</span><span class="s">minor</span><span class="sh">'</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">4</span> <span class="nf">else</span><span class="p">(</span>
                                                        <span class="sh">'</span><span class="s">light</span><span class="sh">'</span> <span class="nf">if </span><span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="mi">4</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">x</span><span class="o">&lt;=</span><span class="mi">5</span><span class="p">)</span> <span class="nf">else </span><span class="p">(</span>
                                                        <span class="sh">'</span><span class="s">moderate</span><span class="sh">'</span> <span class="nf">if </span><span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="mi">5</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">x</span><span class="o">&lt;=</span><span class="mi">6</span><span class="p">)</span> <span class="nf">else</span><span class="p">(</span>
                                                        <span class="sh">'</span><span class="s">strong</span><span class="sh">'</span> <span class="nf">if </span><span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="mi">6</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">x</span><span class="o">&lt;=</span><span class="mi">7</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">great</span><span class="sh">'</span><span class="p">))))</span>
<span class="n">magnitude_class_list</span><span class="o">=</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude_classification</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">minor</span><span class="sh">'</span><span class="p">],</span>
                     <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude_classification</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">light</span><span class="sh">'</span><span class="p">],</span>
                     <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude_classification</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">moderate</span><span class="sh">'</span><span class="p">],</span>
                     <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude_classification</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">strong</span><span class="sh">'</span><span class="p">],</span>
                     <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">magnitude_classification</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">great</span><span class="sh">'</span><span class="p">]]</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">classification_histogram</span><span class="p">(</span><span class="n">magnitude_class_list</span><span class="p">,</span><span class="sh">'</span><span class="s">magnitude</span><span class="sh">'</span><span class="p">,</span><span class="mi">2</span> <span class="p">,</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_40_0-480.webp 480w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_40_0-800.webp 800w,/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_40_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Earthquake_Playthrough_01_files/Earthquake_Playthrough_01_40_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 9. Histograms of different earthquake magnitude classification. </div> <p>We can see from the depth histograms that every magnitude group has the same depth distribution pattern which means that our assumption still holds. From the magnitude histograms on the second row, at minor earthquake magnitude distribution, we can see that data are absent at a magnitude around 1 and 2. That is very suspicious and most probably due to incomplete data records. That is probably the reason why we have an unexpected normal distribution of our magnitude data. we can see from another group from light to great earthquake magnitude distribution that the distribution more resembles a power-law distribution. The apparent normal-like distribution that we see from our initial data is most probably due to missing a big chunk of data on the left side of our distribution.</p> <p>I think that is probably all for our today’s playthrough with USGS earthquake data catalog. I believe it is a nice way to exercise Python libraries while acquiring a nice insight into the nature of earthquakes. There is so much that we can still do to our data, a few ideas that I will try for the next few weeks are trying to split our dataset into more detailed categories with multiple Gaussian fit, and calculating energy release in spatial and temporal perspective. And I am pretty sure that there is still so much to explore along the way. I’ll make sure to post my notebook update next week!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Practicing python with earthquake data from USGS libcomcat API]]></summary></entry><entry><title type="html">Quick Soil Sampling Data Summary With Python</title><link href="https://nasirlukman.github.io/blog/2021/SS-data-summary/" rel="alternate" type="text/html" title="Quick Soil Sampling Data Summary With Python"/><published>2021-02-14T23:36:10+00:00</published><updated>2021-02-14T23:36:10+00:00</updated><id>https://nasirlukman.github.io/blog/2021/SS-data-summary</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2021/SS-data-summary/"><![CDATA[<p>Geologists often use soil sampling methods in mineral exploration to gather information about element anomalies in the soil of a certain area. The output of this activity is a database containing coordinates and various element concentrations from the sample taken at that point. Before diving deep into the data and doing any fancy analysis, it is always a good idea to familiarize ourselves with the data by looking into the summary statistics and the general and spatial relationship of the data as a whole. By using Python we can write a simple code to get the summary statistics and some useful graphs to summarize the data in just a few minutes.</p> <p>We will use <code class="language-plaintext highlighter-rouge">pandas</code>, <code class="language-plaintext highlighter-rouge">numpy</code>, and <code class="language-plaintext highlighter-rouge">matplotib</code> libraries for this code, so let’s begin with importing our library</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</code></pre></div></div> <p>We can use <code class="language-plaintext highlighter-rouge">pandas</code> to read our dataset and put it into a variable called <em>data</em>. We can then use <code class="language-plaintext highlighter-rouge">head()</code> function from <code class="language-plaintext highlighter-rouge">pandas</code> to look at the first 5 rows of the data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">soil_data_example.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>EASTING</th> <th>NORTHING</th> <th>Mg</th> <th>Al</th> <th>Si</th> <th>P</th> <th>S</th> <th>Cl</th> <th>Ca</th> <th>Ti</th> <th>...</th> <th>Cd</th> <th>Sn</th> <th>Sb</th> <th>W</th> <th>Hg</th> <th>Pb</th> <th>Bi</th> <th>Th</th> <th>U</th> <th>LE</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>803041</td> <td>9880671</td> <td>0.0</td> <td>0.0</td> <td>53.495</td> <td>86.0</td> <td>686.0</td> <td>149</td> <td>405.0</td> <td>6.244</td> <td>...</td> <td>0</td> <td>35</td> <td>0</td> <td>0</td> <td>0</td> <td>31.0</td> <td>0</td> <td>39</td> <td>0</td> <td>844.453</td> </tr> <tr> <th>1</th> <td>803137</td> <td>9880700</td> <td>0.0</td> <td>0.0</td> <td>53.272</td> <td>84.0</td> <td>660.0</td> <td>0</td> <td>461.0</td> <td>5.452</td> <td>...</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>66.0</td> <td>0</td> <td>41</td> <td>4</td> <td>813.117</td> </tr> <tr> <th>2</th> <td>803055</td> <td>9880624</td> <td>0.0</td> <td>0.0</td> <td>57.548</td> <td>154.0</td> <td>621.0</td> <td>0</td> <td>203.0</td> <td>6.865</td> <td>...</td> <td>0</td> <td>95</td> <td>0</td> <td>0</td> <td>0</td> <td>41.0</td> <td>0</td> <td>37</td> <td>0</td> <td>831.336</td> </tr> <tr> <th>3</th> <td>803150</td> <td>9880652</td> <td>0.0</td> <td>0.0</td> <td>68.581</td> <td>101.0</td> <td>684.0</td> <td>0</td> <td>325.0</td> <td>6.396</td> <td>...</td> <td>0</td> <td>45</td> <td>0</td> <td>0</td> <td>0</td> <td>58.0</td> <td>0</td> <td>38</td> <td>0</td> <td>834.693</td> </tr> <tr> <th>4</th> <td>803070</td> <td>9880576</td> <td>0.0</td> <td>0.0</td> <td>73.638</td> <td>184.0</td> <td>758.0</td> <td>0</td> <td>251.0</td> <td>7.636</td> <td>...</td> <td>26</td> <td>126</td> <td>0</td> <td>0</td> <td>0</td> <td>68.0</td> <td>0</td> <td>31</td> <td>0</td> <td>819.252</td> </tr> </tbody> </table> <p>5 rows × 37 columns</p> </div> <blockquote> <p><em>Note: for this example, we use data with dummy coordinates.</em></p> </blockquote> <h2 id="summary-statistics">Summary statistics</h2> <p>By using <code class="language-plaintext highlighter-rouge">pandas</code>, getting summary statistics is as simple as this:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nf">set_option</span><span class="p">(</span><span class="sh">'</span><span class="s">display.max_columns</span><span class="sh">'</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:].</span><span class="nf">describe</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Mg</th> <th>Al</th> <th>Si</th> <th>P</th> <th>S</th> <th>Cl</th> <th>Ca</th> <th>Ti</th> <th>V</th> <th>Cr</th> <th>Mn</th> <th>Fe</th> <th>Co</th> <th>Ni</th> <th>Cu</th> <th>Zn</th> <th>As</th> <th>Se</th> <th>Rb</th> <th>Sr</th> <th>Y</th> <th>Zr</th> <th>Nb</th> <th>Mo</th> <th>Ag</th> <th>Cd</th> <th>Sn</th> <th>Sb</th> <th>W</th> <th>Hg</th> <th>Pb</th> <th>Bi</th> <th>Th</th> <th>U</th> <th>LE</th> </tr> </thead> <tbody> <tr> <th>count</th> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> <td>483.000000</td> </tr> <tr> <th>mean</th> <td>0.361609</td> <td>37.306886</td> <td>79.901859</td> <td>164.188741</td> <td>635.832406</td> <td>108.314700</td> <td>447.012607</td> <td>4.826319</td> <td>35.511387</td> <td>67.778468</td> <td>75.228035</td> <td>65.516644</td> <td>256.832961</td> <td>14.291925</td> <td>22.339545</td> <td>50.455487</td> <td>43.819876</td> <td>1.204969</td> <td>90.469979</td> <td>19.761905</td> <td>30.440994</td> <td>322.449275</td> <td>25.619048</td> <td>1.917184</td> <td>90.842650</td> <td>5.383023</td> <td>14.844720</td> <td>5.236025</td> <td>0.409938</td> <td>0.300207</td> <td>49.049996</td> <td>0.267081</td> <td>31.828157</td> <td>0.389234</td> <td>799.849393</td> </tr> <tr> <th>std</th> <td>2.524420</td> <td>19.170464</td> <td>21.018874</td> <td>105.011094</td> <td>116.399578</td> <td>166.519336</td> <td>364.993895</td> <td>1.125096</td> <td>27.704977</td> <td>72.420758</td> <td>132.400090</td> <td>48.937698</td> <td>266.687782</td> <td>16.964439</td> <td>21.153868</td> <td>42.358326</td> <td>47.032683</td> <td>1.866225</td> <td>53.418809</td> <td>14.534807</td> <td>7.541458</td> <td>108.510507</td> <td>6.765470</td> <td>5.917603</td> <td>78.306505</td> <td>10.428192</td> <td>67.141786</td> <td>22.061828</td> <td>2.077758</td> <td>1.339993</td> <td>89.163245</td> <td>2.859267</td> <td>13.579391</td> <td>1.446719</td> <td>40.073827</td> </tr> <tr> <th>min</th> <td>0.000000</td> <td>0.000000</td> <td>38.589000</td> <td>0.000000</td> <td>1.004000</td> <td>0.000000</td> <td>1.000000</td> <td>2.137000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>4.597000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>7.000000</td> <td>0.000000</td> <td>0.000000</td> <td>11.000000</td> <td>7.000000</td> <td>13.000000</td> <td>104.000000</td> <td>9.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>631.444000</td> </tr> <tr> <th>25%</th> <td>0.000000</td> <td>40.015500</td> <td>63.242000</td> <td>96.500000</td> <td>565.500000</td> <td>0.000000</td> <td>1.376500</td> <td>3.935000</td> <td>19.000000</td> <td>0.000000</td> <td>0.000000</td> <td>24.906500</td> <td>0.000000</td> <td>0.000000</td> <td>8.000000</td> <td>22.000000</td> <td>16.000000</td> <td>0.000000</td> <td>50.500000</td> <td>12.000000</td> <td>26.000000</td> <td>247.500000</td> <td>21.000000</td> <td>0.000000</td> <td>27.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>21.000000</td> <td>0.000000</td> <td>22.000000</td> <td>0.000000</td> <td>776.857500</td> </tr> <tr> <th>50%</th> <td>0.000000</td> <td>44.624000</td> <td>77.059000</td> <td>154.000000</td> <td>637.000000</td> <td>0.000000</td> <td>536.000000</td> <td>4.613000</td> <td>37.000000</td> <td>42.000000</td> <td>32.000000</td> <td>47.867000</td> <td>159.000000</td> <td>12.000000</td> <td>18.000000</td> <td>37.000000</td> <td>31.000000</td> <td>0.000000</td> <td>76.000000</td> <td>16.000000</td> <td>30.000000</td> <td>313.000000</td> <td>25.000000</td> <td>0.000000</td> <td>65.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>28.000000</td> <td>0.000000</td> <td>30.000000</td> <td>0.000000</td> <td>811.330000</td> </tr> <tr> <th>75%</th> <td>0.000000</td> <td>48.510000</td> <td>95.729000</td> <td>251.000000</td> <td>702.000000</td> <td>191.500000</td> <td>774.000000</td> <td>5.567500</td> <td>50.000000</td> <td>108.000000</td> <td>75.500000</td> <td>101.228000</td> <td>483.000000</td> <td>22.000000</td> <td>30.000000</td> <td>68.000000</td> <td>54.000000</td> <td>2.000000</td> <td>118.000000</td> <td>22.000000</td> <td>34.000000</td> <td>385.500000</td> <td>29.000000</td> <td>0.000000</td> <td>147.500000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>0.000000</td> <td>39.000000</td> <td>0.000000</td> <td>42.000000</td> <td>0.000000</td> <td>829.934000</td> </tr> <tr> <th>max</th> <td>22.825000</td> <td>77.831000</td> <td>150.081000</td> <td>465.000000</td> <td>970.000000</td> <td>830.000000</td> <td>999.000000</td> <td>9.502000</td> <td>337.000000</td> <td>385.000000</td> <td>896.000000</td> <td>243.907000</td> <td>989.000000</td> <td>232.000000</td> <td>145.000000</td> <td>490.000000</td> <td>455.000000</td> <td>12.000000</td> <td>309.000000</td> <td>149.000000</td> <td>59.000000</td> <td>735.000000</td> <td>45.000000</td> <td>96.000000</td> <td>351.000000</td> <td>55.000000</td> <td>827.000000</td> <td>223.000000</td> <td>22.000000</td> <td>12.000000</td> <td>867.000000</td> <td>45.000000</td> <td>66.000000</td> <td>13.000000</td> <td>865.822000</td> </tr> </tbody> </table> </div> <p>For practicality, <code class="language-plaintext highlighter-rouge">pandas</code> by default will not show the full range of rows and columns of our dataset. The first line of the code tells <code class="language-plaintext highlighter-rouge">pandas</code> to show the full range of the columns. In the second line, we use <code class="language-plaintext highlighter-rouge">iloc[:, 2:]</code> attribute to ignore the first two columns of our dataset because we don’t need summary statistics of the x and y coordinate (unless for some reason you do).</p> <h2 id="histograms">Histograms</h2> <p>Next, we will draw the histogram of each element’s concentration in the area. Because of the logarithmic nature of element concentration in the soil, we will plot the log concentration value into the histogram. Since we are dealing with a lot of 0’s, we will add a very small value to all the concentration data to make it easier with the logarithmic transformation. There are various ways to deal with zero values in the dataset, but for this example, let’s just add <code class="language-plaintext highlighter-rouge">0.0001</code> to all concentration data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">+</span><span class="mf">0.0001</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">np.log</code> is a natural logarithm with base <em>e</em> if we want logarithm transformation with base <em>10</em> we can use <code class="language-plaintext highlighter-rouge">np.log10</code>. Now if we call <code class="language-plaintext highlighter-rouge">data.head()</code> we will see that that the concentration of each element already transformed into its logarithmic value.</p> <blockquote> <p><em>Note: code above will return an error if there are still zero values in the datasets. There are various ways to deals with <code class="language-plaintext highlighter-rouge">0</code> and <code class="language-plaintext highlighter-rouge">NaN</code> value in our dataset and it was up to you which method you will use for your case. You can also ignore this line if you don’t want to do any logarithmic transformation for your dataset</em></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>EASTING</th> <th>NORTHING</th> <th>Mg</th> <th>Al</th> <th>Si</th> <th>P</th> <th>S</th> <th>Cl</th> <th>Ca</th> <th>Ti</th> <th>V</th> <th>Cr</th> <th>Mn</th> <th>Fe</th> <th>Co</th> <th>Ni</th> <th>Cu</th> <th>Zn</th> <th>As</th> <th>Se</th> <th>Rb</th> <th>Sr</th> <th>Y</th> <th>Zr</th> <th>Nb</th> <th>Mo</th> <th>Ag</th> <th>Cd</th> <th>Sn</th> <th>Sb</th> <th>W</th> <th>Hg</th> <th>Pb</th> <th>Bi</th> <th>Th</th> <th>U</th> <th>LE</th> </tr> <style type="text/css">table.dataframe{width:100%;height:240px;display:block;overflow:auto;font-family:Arial,sans-serif;font-size:13px;line-height:20px;text-align:center}table.dataframe th{font-weight:bold;padding:4px}table.dataframe td{padding:4px}table.dataframe tr:hover{background:#b8d1f3}</style> </thead> <tbody> <tr> <th>0</th> <td>803041</td> <td>9880671</td> <td>-9.21034</td> <td>-9.21034</td> <td>3.979590</td> <td>4.454348</td> <td>6.530878</td> <td>5.003947</td> <td>6.003887</td> <td>1.831637</td> <td>3.135499</td> <td>3.761202</td> <td>-9.210340</td> <td>3.880823</td> <td>4.543296</td> <td>2.302595</td> <td>2.302595</td> <td>4.219509</td> <td>4.060445</td> <td>-9.21034</td> <td>3.044527</td> <td>2.484915</td> <td>3.555351</td> <td>6.146329</td> <td>3.367299</td> <td>-9.21034</td> <td>3.713575</td> <td>-9.21034</td> <td>3.555351</td> <td>-9.21034</td> <td>-9.21034</td> <td>-9.21034</td> <td>3.433990</td> <td>-9.21034</td> <td>3.663564</td> <td>-9.210340</td> <td>6.738689</td> </tr> <tr> <th>1</th> <td>803137</td> <td>9880700</td> <td>-9.21034</td> <td>-9.21034</td> <td>3.975413</td> <td>4.430818</td> <td>6.492240</td> <td>-9.210340</td> <td>6.133398</td> <td>1.696001</td> <td>3.295841</td> <td>4.812185</td> <td>6.284134</td> <td>4.346828</td> <td>5.752573</td> <td>2.772595</td> <td>-9.210340</td> <td>4.700481</td> <td>4.709531</td> <td>-9.21034</td> <td>3.761202</td> <td>2.833219</td> <td>3.663564</td> <td>5.993962</td> <td>3.367299</td> <td>-9.21034</td> <td>4.174389</td> <td>-9.21034</td> <td>-9.210340</td> <td>-9.21034</td> <td>-9.21034</td> <td>-9.21034</td> <td>4.189656</td> <td>-9.21034</td> <td>3.713575</td> <td>1.386319</td> <td>6.700875</td> </tr> <tr> <th>2</th> <td>803055</td> <td>9880624</td> <td>-9.21034</td> <td>-9.21034</td> <td>4.052621</td> <td>5.036953</td> <td>6.431331</td> <td>-9.210340</td> <td>5.313206</td> <td>1.926451</td> <td>2.995737</td> <td>3.496511</td> <td>3.465739</td> <td>3.970464</td> <td>5.003947</td> <td>3.091047</td> <td>3.091047</td> <td>4.234108</td> <td>4.174389</td> <td>-9.21034</td> <td>2.772595</td> <td>2.564957</td> <td>3.610921</td> <td>6.208590</td> <td>3.496511</td> <td>-9.21034</td> <td>3.931828</td> <td>-9.21034</td> <td>4.553878</td> <td>-9.21034</td> <td>-9.21034</td> <td>-9.21034</td> <td>3.713575</td> <td>-9.21034</td> <td>3.610921</td> <td>-9.210340</td> <td>6.723034</td> </tr> <tr> <th>3</th> <td>803150</td> <td>9880652</td> <td>-9.21034</td> <td>-9.21034</td> <td>4.228017</td> <td>4.615122</td> <td>6.527958</td> <td>-9.210340</td> <td>5.783825</td> <td>1.855688</td> <td>3.178058</td> <td>-9.210340</td> <td>3.295841</td> <td>3.667786</td> <td>-9.210340</td> <td>2.890377</td> <td>-9.210340</td> <td>4.043053</td> <td>4.143136</td> <td>-9.21034</td> <td>3.295841</td> <td>2.833219</td> <td>3.610921</td> <td>6.122493</td> <td>3.367299</td> <td>-9.21034</td> <td>3.555351</td> <td>-9.21034</td> <td>3.806665</td> <td>-9.21034</td> <td>-9.21034</td> <td>-9.21034</td> <td>4.060445</td> <td>-9.21034</td> <td>3.637589</td> <td>-9.210340</td> <td>6.727064</td> </tr> <tr> <th>4</th> <td>803070</td> <td>9880576</td> <td>-9.21034</td> <td>-9.21034</td> <td>4.299163</td> <td>5.214936</td> <td>6.630684</td> <td>-9.210340</td> <td>5.525453</td> <td>2.032887</td> <td>3.806665</td> <td>4.248497</td> <td>-9.210340</td> <td>3.742731</td> <td>4.025353</td> <td>2.890377</td> <td>2.197236</td> <td>4.189656</td> <td>3.988986</td> <td>-9.21034</td> <td>2.890377</td> <td>2.708057</td> <td>3.688882</td> <td>6.272877</td> <td>3.555351</td> <td>-9.21034</td> <td>4.174389</td> <td>3.25810</td> <td>4.836283</td> <td>-9.21034</td> <td>-9.21034</td> <td>-9.21034</td> <td>4.219509</td> <td>-9.21034</td> <td>3.433990</td> <td>-9.210340</td> <td>6.708392</td> </tr> </tbody> </table> </div> <p>Next, we will use <code class="language-plaintext highlighter-rouge">matplotlib</code> to define our canvas and axes and then loop into each element in our dataset to plot each histogram.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>


<span class="n">row</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">col</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:].</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">x</span><span class="o">=</span><span class="nf">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">element</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">35</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">log </span><span class="sh">"</span> <span class="o">+</span> <span class="n">element</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">col</span><span class="o">&lt;</span><span class="mi">4</span><span class="p">:</span>
        <span class="n">col</span><span class="o">+=</span><span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">col</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">row</span><span class="o">+=</span><span class="mi">1</span>
        
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/SS_data_summary_files/SS_data_summary_16_0-480.webp 480w,/img/SS_data_summary_files/SS_data_summary_16_0-800.webp 800w,/img/SS_data_summary_files/SS_data_summary_16_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/SS_data_summary_files/SS_data_summary_16_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 1. Elements concentration (log ppm) </div> <p>The code above can be separated into two sections. The first section of the code will define the figure and axis canvas for our plot. Since we are dealing with 35 variables we will divide our subplots into 7 rows and 5 columns.</p> <p>We can check the length of our variable with:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="sh">'''</span><span class="s">
it is getting annoying to keep typing data.iloc[:,2:] 
to get our elements so let</span><span class="sh">'</span><span class="s">s just put it into a
variable called grade
</span><span class="sh">'''</span>
<span class="n">grade</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
    
<span class="nf">len</span><span class="p">(</span><span class="n">grade</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>35
</code></pre></div></div> <p>The second section of the code defines the loop behavior that will plot each histogram into predefined subplots.</p> <h2 id="correlation-matrix">Correlation Matrix</h2> <p>Our next figure will be a correlation matrix. This is a very useful and neat graph that will tell us the correlation coefficient of one variable with another variable within the dataset. The correlation matrix value ranges from -1 to 1, where:</p> <ul> <li>-1 = perfect negative correlation</li> <li>0 = no correlation</li> <li>1 = perfect positive correlation.</li> </ul> <p><code class="language-plaintext highlighter-rouge">Pandas</code> come in handy with its <code class="language-plaintext highlighter-rouge">corr()</code> function to calculate a correlation matrix of our dataset. Combine it with <code class="language-plaintext highlighter-rouge">matplotlib</code> functions such as: <code class="language-plaintext highlighter-rouge">matshow()</code> to draw the matrix into a figure; <code class="language-plaintext highlighter-rouge">cmap()</code> to denote it with colormap; and <code class="language-plaintext highlighter-rouge">colorbar()</code> to draw the legend, and we can get this informative graph.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cor_matrix</span> <span class="o">=</span> <span class="n">grade</span><span class="p">.</span><span class="nf">corr</span><span class="p">()</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">18</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">matshow</span><span class="p">(</span><span class="n">cor_matrix</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ticks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nf">len</span><span class="p">(</span><span class="n">grade</span><span class="p">.</span><span class="n">columns</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Correlation Matrix</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_yticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xticklabels</span><span class="p">(</span><span class="n">grade</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_yticklabels</span><span class="p">(</span><span class="n">grade</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/SS_data_summary_files/SS_data_summary_22_0-480.webp 480w,/img/SS_data_summary_files/SS_data_summary_22_0-800.webp 800w,/img/SS_data_summary_files/SS_data_summary_22_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/SS_data_summary_files/SS_data_summary_22_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 2. Elements concentration correlation matrix </div> <h2 id="map-plots">Map plots</h2> <p>With the same concept as the histogram plot, we can make quick and dirty map plots of our points to get a glimpse of the spatial correlation of each element. For this purpose, we use <code class="language-plaintext highlighter-rouge">scatter()</code> function with our UTM coordinates as its x and y value and denote the concentration value of each element to a color map using <code class="language-plaintext highlighter-rouge">cmap()</code>. We do this using <code class="language-plaintext highlighter-rouge">for</code> loop so it can loop to each <em>element</em> in our <code class="language-plaintext highlighter-rouge">grade</code> data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">rows</span><span class="o">=</span><span class="mi">0</span>
<span class="n">cols</span><span class="o">=</span><span class="mi">0</span> 
<span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">grade</span><span class="p">:</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span><span class="n">cols</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">EASTING</span><span class="sh">'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">NORTHING</span><span class="sh">'</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">grade</span><span class="p">[</span><span class="n">element</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span><span class="n">cols</span><span class="p">].</span><span class="nf">set_xticklabels</span><span class="p">(</span><span class="sh">''</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span><span class="n">cols</span><span class="p">].</span><span class="nf">set_yticklabels</span><span class="p">(</span><span class="sh">''</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span><span class="n">cols</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="n">element</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span><span class="n">cols</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">equal</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span><span class="n">cols</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">cols</span><span class="o">&lt;</span><span class="mi">2</span><span class="p">:</span>
        <span class="n">cols</span><span class="o">+=</span><span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">rows</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_axis_off</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/SS_data_summary_files/SS_data_summary_25_0-480.webp 480w,/img/SS_data_summary_files/SS_data_summary_25_0-800.webp 800w,/img/SS_data_summary_files/SS_data_summary_25_0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/SS_data_summary_files/SS_data_summary_25_0.png" class="img-fluid rounded" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image 3. Elements concentration map </div> <p>And that’s it. Your soil sampling data summary in just about a minute. You can download the full code on my <a href="https://github.com/nasirlukman/project-dump/tree/main">GitHub page</a> and reuse it for your next project. Hope it can save you the trouble and you can be more focused on your real geologist work. Have fun exploring!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Using pandas, matplotlib, and numpy to create a quick and dirty plot that summarized your data. Just enough to make your job easier.]]></summary></entry><entry><title type="html">Hello World!</title><link href="https://nasirlukman.github.io/blog/2021/Hello-World/" rel="alternate" type="text/html" title="Hello World!"/><published>2021-02-13T00:00:00+00:00</published><updated>2021-02-13T00:00:00+00:00</updated><id>https://nasirlukman.github.io/blog/2021/Hello-World</id><content type="html" xml:base="https://nasirlukman.github.io/blog/2021/Hello-World/"><![CDATA[<p>I’m planning to use this corner of the internet to put some of my side projects that I find interesting or might be useful for someone out there.</p> <h3 id="im-still-learning-for-now-so-please-be-nice">I’m still learning for now so please be nice.</h3> <h2 id="but-ill-get-better-soon">But I’ll get better soon!</h2>]]></content><author><name></name></author><summary type="html"><![CDATA[I'm probably 10 years late to the game but finally I set up my own blog!]]></summary></entry></feed>